{
  "report_timestamp": "2025-10-05T02:26:16.835632",
  "api_url": "https://rickandmortyapi.com/graphql",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.1,
    "simple_detections": 2,
    "llm_detections": 3,
    "consensus_breakdown": {
      "both_detected": 2,
      "no_vulnerabilities": 7,
      "llm_only": 1
    },
    "detection_ratio": 1.5,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 1,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 1,
        "no_potential": 8,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 1.0
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T02:23:38.570096",
      "node_name": "episodesByIds_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": null
        },
        "errors": [
          {
            "message": "500: Internal Server Error",
            "locations": [
              {
                "line": 2,
                "column": 3
              }
            ],
            "path": [
              "episodesByIds"
            ],
            "extensions": {
              "code": "INTERNAL_SERVER_ERROR",
              "response": {
                "url": "http://localhost:8080/api/episode/%27%20UNION%20SELECT%20NULL,CONCAT(username,%27:%27,password)%20FROM%20users--",
                "status": 500,
                "statusText": "Internal Server Error",
                "body": {
                  "error": "Cast to Number failed for value \"NaN\" at path \"id\" for model \"Episode\""
                }
              }
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: sql_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL error response reveals a SQL injection attempt in the underlying API call. The URL path contains a URL-encoded SQL payload (' UNION SELECT NULL,CONCAT(username,':',password) FROM users--) designed to extract sensitive credentials. While the error message ('Cast to Number failed') indicates improper input validation rather than direct SQL syntax leakage, the presence of UNION SELECT and database object references ('users' table) strongly suggests insecure raw SQL query construction with user-controlled input.",
            "evidence": "URL parameter contains '%27%20UNION%20SELECT%20NULL,CONCAT(username,%27:%27,password)%20FROM%20users--' payload attempting to exfiltrate credentials from 'users' table",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "sql_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "URL parameter contains '%27%20UNION%20SELECT%20NULL,CONCAT(username,%27:%27,password)%20FROM%20users--' payload attempting to exfiltrate credentials from 'users' table",
              "explanation": "The GraphQL error response reveals a SQL injection attempt in the underlying API call. The URL path contains a URL-encoded SQL payload (' UNION SELECT NULL,CONCAT(username,':',password) FROM users--) designed to extract sensitive credentials. While the error message ('Cast to Number failed') indicates improper input validation rather than direct SQL syntax leakage, the presence of UNION SELECT and database object references ('users' table) strongly suggests insecure raw SQL query construction with user-controlled input."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:23:46.115679",
      "node_name": "episodesByIds_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": []
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:24:05.181371",
      "node_name": "episodesByIds_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": []
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:24:31.509076",
      "node_name": "episodesByIds_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": []
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:24:43.332135",
      "node_name": "episodesByIds_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": []
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:25:01.361387",
      "node_name": "episodesByIds_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": null
        },
        "errors": [
          {
            "message": "500: Internal Server Error",
            "locations": [
              {
                "line": 2,
                "column": 3
              }
            ],
            "path": [
              "episodesByIds"
            ],
            "extensions": {
              "code": "INTERNAL_SERVER_ERROR",
              "response": {
                "url": "http://localhost:8080/api/episode/%3Ciframe%20src=%27javascript:alert(document.domain)%27%3E",
                "status": 500,
                "statusText": "Internal Server Error",
                "body": {
                  "error": "Hey! you must provide an id"
                }
              }
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The server accepted and processed a URL parameter containing an HTML-encoded iframe payload (<iframe src='javascript:alert(document.domain)'>). While the error response itself doesn't reflect the raw HTML, the server's handling of unsanitized HTML in URL construction demonstrates potential HTML injection risk. If this URL is ever rendered in a browser context without proper encoding, it could execute arbitrary JavaScript. The 500 error suggests improper input handling, though direct confirmation of execution requires further testing.",
            "evidence": "URL in 'extensions.response.url' contains HTML-encoded payload: %3Ciframe%20src=%27javascript:alert(document.domain)%27%3E (decoded: <iframe src='javascript:alert(document.domain)'>)",
            "confidence": 0.7,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "MEDIUM",
              "confidence": 0.7,
              "evidence": "URL in 'extensions.response.url' contains HTML-encoded payload: %3Ciframe%20src=%27javascript:alert(document.domain)%27%3E (decoded: <iframe src='javascript:alert(document.domain)'>)",
              "explanation": "The server accepted and processed a URL parameter containing an HTML-encoded iframe payload (<iframe src='javascript:alert(document.domain)'>). While the error response itself doesn't reflect the raw HTML, the server's handling of unsanitized HTML in URL construction demonstrates potential HTML injection risk. If this URL is ever rendered in a browser context without proper encoding, it could execute arbitrary JavaScript. The 500 error suggests improper input handling, though direct confirmation of execution requires further testing."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:25:18.096399",
      "node_name": "episodesByIds_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:25:45.369862",
      "node_name": "episodesByIds_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:25:55.011714",
      "node_name": "episodesByIds_response_10",
      "response_status": 413,
      "response_body": {
        "errors": [
          {
            "message": "Query depth limit exceeded.",
            "extensions": {
              "code": "GCDN_QUERY_DEPTH_LIMIT",
              "httpStatusCode": 413
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T02:26:16.831392",
      "node_name": "episodesByIds_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"naame\" on type \"Episode\". Did you mean \"name\"?",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"airr_date\" on type \"Episode\". Did you mean \"air_date\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL server discloses schema information via field name suggestions in error messages (\"Did you mean...\"). While not critical, this verbose error handling could help attackers map the API schema and discover hidden fields, violating the security principle of minimal information disclosure. However, this is a common default behavior in GraphQL implementations rather than an inherent vulnerability.",
            "evidence": "Error messages suggest valid fields: \"Did you mean 'name'?\" and \"Did you mean 'air_date'?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.95,
              "evidence": "Error messages suggest valid fields: \"Did you mean 'name'?\" and \"Did you mean 'air_date'?\"",
              "explanation": "The GraphQL server discloses schema information via field name suggestions in error messages (\"Did you mean...\"). While not critical, this verbose error handling could help attackers map the API schema and discover hidden fields, violating the security principle of minimal information disclosure. However, this is a common default behavior in GraphQL implementations rather than an inherent vulnerability."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}