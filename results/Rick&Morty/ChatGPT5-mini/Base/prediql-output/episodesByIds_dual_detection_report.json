{
  "report_timestamp": "2025-10-02T20:41:51.369046",
  "api_url": "https://rickandmortyapi.com/graphql",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.0,
    "simple_detections": 2,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 1,
      "llm_only": 3,
      "no_vulnerabilities": 5,
      "both_detected": 1
    },
    "detection_ratio": 2.0,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 1,
      "llm_potential_detections": 3,
      "potential_consensus_breakdown": {
        "simple_potential_only": 1,
        "no_potential": 6,
        "llm_potential_only": 3
      },
      "potential_detection_ratio": 3.0
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-02T20:39:35.080275",
      "node_name": "episodesByIds_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": null
        },
        "errors": [
          {
            "message": "500: Internal Server Error",
            "locations": [
              {
                "line": 2,
                "column": 3
              }
            ],
            "path": [
              "episodesByIds"
            ],
            "extensions": {
              "code": "INTERNAL_SERVER_ERROR",
              "response": {
                "url": "http://localhost:8080/api/episode/1,2%27,%20%273%27);%20DROP%20TABLE%20users;%20--",
                "status": 500,
                "statusText": "Internal Server Error",
                "body": {
                  "error": "Cast to Number failed for value \"NaN\" at path \"id\" for model \"Episode\""
                }
              }
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:39:49.877419",
      "node_name": "episodesByIds_response_3",
      "response_status": null,
      "response_body": {
        "error": "HTTPSConnectionPool(host='rickandmortyapi.com', port=443): Read timed out. (read timeout=10)"
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns a raw HTTP client exception message that discloses internal runtime behavior: the server attempted an outbound HTTPS request to 'rickandmortyapi.com' and hit a read timeout. This leaks implementation details (HTTP client/library error text, target host, and timeout value). While not directly exploitable like SQLi, XSS, SSRF, or command injection, such information can aid attackers in reconnaissance (identifying internal integrations and dependencies) and may indicate insufficient error handling/exception sanitization. No clear evidence of other vulnerability types (SQLi, XSS, SSRF, path/OS injection, HTML injection, or access control bypass) is present in the provided response.",
            "evidence": "HTTPSConnectionPool(host='rickandmortyapi.com', port=443): Read timed out. (read timeout=10)",
            "confidence": 0.6,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.6,
              "evidence": "HTTPSConnectionPool(host='rickandmortyapi.com', port=443): Read timed out. (read timeout=10)",
              "explanation": "The GraphQL response returns a raw HTTP client exception message that discloses internal runtime behavior: the server attempted an outbound HTTPS request to 'rickandmortyapi.com' and hit a read timeout. This leaks implementation details (HTTP client/library error text, target host, and timeout value). While not directly exploitable like SQLi, XSS, SSRF, or command injection, such information can aid attackers in reconnaissance (identifying internal integrations and dependencies) and may indicate insufficient error handling/exception sanitization. No clear evidence of other vulnerability types (SQLi, XSS, SSRF, path/OS injection, HTML injection, or access control bypass) is present in the provided response."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:40:05.091900",
      "node_name": "episodesByIds_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": []
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:40:15.725916",
      "node_name": "episodesByIds_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": []
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:40:26.962097",
      "node_name": "episodesByIds_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": []
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:40:42.551127",
      "node_name": "episodesByIds_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": null
        },
        "errors": [
          {
            "message": "500: Internal Server Error",
            "locations": [
              {
                "line": 2,
                "column": 3
              }
            ],
            "path": [
              "episodesByIds"
            ],
            "extensions": {
              "code": "INTERNAL_SERVER_ERROR",
              "response": {
                "url": "http://localhost:8080/api/episode/%3Cimg%20src=x%20onerror=%22alert(%27html%27)%22%3E,1",
                "status": 500,
                "statusText": "Internal Server Error",
                "body": {
                  "error": "Cast to Number failed for value \"NaN\" at path \"id\" for model \"Episode\""
                }
              }
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL error response reflects user-supplied input containing an HTML payload (<img ... onerror=...>) inside the extensions.response.url field. Although the payload is percent-encoded in the JSON, the raw HTML characters are present when decoded. This indicates the backend is including unsanitized user input in responses. If a client or UI decodes and injects that URL into a page or HTML context without proper encoding, it could result in XSS via HTML injection. The server also exposes the failing value and type error (Cast to Number failed...), confirming the input was processed and reflected. Recommend treating numeric IDs strictly (validate/deny non-numeric input), avoid reflecting raw user input in error metadata, and ensure proper output encoding/escaping on any UI that displays this field.",
            "evidence": "extensions.response.url contains encoded HTML payload: \"http://localhost:8080/api/episode/%3Cimg%20src=x%20onerror=%22alert(%27html%27)%22%3E,1\" (decoded: \"http://localhost:8080/api/episode/<img src=x onerror=\\\"alert('html')\\\">,1\")",
            "confidence": 0.6,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "MEDIUM",
              "confidence": 0.6,
              "evidence": "extensions.response.url contains encoded HTML payload: \"http://localhost:8080/api/episode/%3Cimg%20src=x%20onerror=%22alert(%27html%27)%22%3E,1\" (decoded: \"http://localhost:8080/api/episode/<img src=x onerror=\\\"alert('html')\\\">,1\")",
              "explanation": "The GraphQL error response reflects user-supplied input containing an HTML payload (<img ... onerror=...>) inside the extensions.response.url field. Although the payload is percent-encoded in the JSON, the raw HTML characters are present when decoded. This indicates the backend is including unsanitized user input in responses. If a client or UI decodes and injects that URL into a page or HTML context without proper encoding, it could result in XSS via HTML injection. The server also exposes the failing value and type error (Cast to Number failed...), confirming the input was processed and reflected. Recommend treating numeric IDs strictly (validate/deny non-numeric input), avoid reflecting raw user input in error metadata, and ensure proper output encoding/escaping on any UI that displays this field."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:40:52.669846",
      "node_name": "episodesByIds_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:41:08.996954",
      "node_name": "episodesByIds_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:41:34.799588",
      "node_name": "episodesByIds_response_10",
      "response_status": 200,
      "response_body": {
        "data": {
          "episodesByIds": [
            {
              "id": "1",
              "name": "Pilot"
            }
          ],
          "__type": {
            "name": "Episode",
            "fields": [
              {
                "name": "id",
                "type": {
                  "name": "ID",
                  "kind": "SCALAR"
                }
              },
              {
                "name": "name",
                "type": {
                  "name": "String",
                  "kind": "SCALAR"
                }
              },
              {
                "name": "air_date",
                "type": {
                  "name": "String",
                  "kind": "SCALAR"
                }
              },
              {
                "name": "episode",
                "type": {
                  "name": "String",
                  "kind": "SCALAR"
                }
              },
              {
                "name": "characters",
                "type": {
                  "name": null,
                  "kind": "NON_NULL"
                }
              },
              {
                "name": "created",
                "type": {
                  "name": "String",
                  "kind": "SCALAR"
                }
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains an __type object describing the 'Episode' type and its fields, which is a direct result of GraphQL introspection being available. This allows an attacker to enumerate the schema (types, fields, and field types) and more easily discover sensitive fields, craft targeted queries or mutations, and plan privilege-escalation or data-exfiltration attacks. While introspection can be useful for development and debugging, it is recommended to disable or restrict introspection in production, require authentication/authorization for schema exposure, and apply additional controls such as query depth/complexity limits and allowlists for operations to reduce attack surface.",
            "evidence": "\"__type\": { \"name\": \"Episode\", \"fields\": [ { \"name\": \"id\", ... }, { \"name\": \"name\", ... }, { \"name\": \"air_date\", ... }, { \"name\": \"episode\", ... }, { \"name\": \"characters\", ... }, { \"name\": \"created\", ... } ] }",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "\"__type\": { \"name\": \"Episode\", \"fields\": [ { \"name\": \"id\", ... }, { \"name\": \"name\", ... }, { \"name\": \"air_date\", ... }, { \"name\": \"episode\", ... }, { \"name\": \"characters\", ... }, { \"name\": \"created\", ... } ] }",
              "explanation": "The GraphQL response contains an __type object describing the 'Episode' type and its fields, which is a direct result of GraphQL introspection being available. This allows an attacker to enumerate the schema (types, fields, and field types) and more easily discover sensitive fields, craft targeted queries or mutations, and plan privilege-escalation or data-exfiltration attacks. While introspection can be useful for development and debugging, it is recommended to disable or restrict introspection in production, require authentication/authorization for schema exposure, and apply additional controls such as query depth/complexity limits and allowlists for operations to reduce attack surface."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:41:51.365114",
      "node_name": "episodesByIds_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"nam\" on type \"Episode\". Did you mean \"name\"?",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"airDate\" on type \"Episode\". Did you mean \"air_date\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL response returns validation errors that include explicit 'Did you mean ...?' suggestions exposing actual field names and schema conventions (e.g., 'name' and 'air_date'). This is an information disclosure vulnerability (field_suggestions) because it leaks schema details that can help an attacker enumerate fields, infer naming conventions, and craft more targeted queries for further probing or exploitation. Impact is contextual but can materially aid reconnaissance and subsequent attacks. Recommended mitigations: disable or sanitize suggestion text in error messages in production, return generic validation errors without revealing schema details, and implement strict logging and monitoring for repeated probing of GraphQL endpoints.",
            "evidence": "GraphQL error messages: \"Cannot query field \\\"nam\\\" on type \\\"Episode\\\". Did you mean \\\"name\\\"?\" and \"Cannot query field \\\"airDate\\\" on type \\\"Episode\\\". Did you mean \\\"air_date\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "GraphQL error messages: \"Cannot query field \\\"nam\\\" on type \\\"Episode\\\". Did you mean \\\"name\\\"?\" and \"Cannot query field \\\"airDate\\\" on type \\\"Episode\\\". Did you mean \\\"air_date\\\"?\"",
              "explanation": "The GraphQL response returns validation errors that include explicit 'Did you mean ...?' suggestions exposing actual field names and schema conventions (e.g., 'name' and 'air_date'). This is an information disclosure vulnerability (field_suggestions) because it leaks schema details that can help an attacker enumerate fields, infer naming conventions, and craft more targeted queries for further probing or exploitation. Impact is contextual but can materially aid reconnaissance and subsequent attacks. Recommended mitigations: disable or sanitize suggestion text in error messages in production, return generic validation errors without revealing schema details, and implement strict logging and monitoring for repeated probing of GraphQL endpoints."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}