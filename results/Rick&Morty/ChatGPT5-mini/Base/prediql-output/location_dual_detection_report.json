{
  "report_timestamp": "2025-10-02T20:21:52.327982",
  "api_url": "https://rickandmortyapi.com/graphql",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.0,
    "simple_detections": 1,
    "llm_detections": 3,
    "consensus_breakdown": {
      "llm_only": 2,
      "no_vulnerabilities": 7,
      "both_detected": 1
    },
    "detection_ratio": 3.0,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 3,
      "potential_consensus_breakdown": {
        "llm_potential_only": 3,
        "no_potential": 7
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-02T20:19:58.418188",
      "node_name": "location_response_1",
      "response_status": 200,
      "response_body": {
        "data": {
          "location": null
        },
        "errors": [
          {
            "message": "500: Internal Server Error",
            "locations": [
              {
                "line": 2,
                "column": 3
              }
            ],
            "path": [
              "location"
            ],
            "extensions": {
              "code": "INTERNAL_SERVER_ERROR",
              "response": {
                "url": "http://localhost:8080/api/location/1%27%20OR%20%271%27=%271",
                "status": 500,
                "statusText": "Internal Server Error",
                "body": {
                  "error": "Cast to Number failed for value \"1\\' OR \\'1\\'=\\'1\" at path \"id\" for model \"Location\""
                }
              }
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: sql_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL error shows a classic SQL injection payload (1' OR '1'='1) encoded in the request URL and reflected in the server-side error: the application attempted to use the raw payload as an id and failed when casting to Number. This indicates user input is being passed into the data-access layer without proper validation or sanitization and is leaking into error messages. Although the attempt resulted in a cast failure (so this specific payload did not execute as a successful SQL injection), the reflection of the raw payload and the DB/model error demonstrates a weakness that could be exploitable (different input formats, other endpoints, or query contexts might succeed). Recommend treating this as a likely SQL injection vulnerability: validate and strictly type-check inputs, use parameterized queries/ORM methods, and avoid leaking internal errors to clients.",
            "evidence": "extensions.response.url = \"http://localhost:8080/api/location/1%27%20OR%20%271%27=%271\" and body.error = \"Cast to Number failed for value \\\"1\\' OR \\'1\\'=\\'1\\\" at path \\\"id\\\" for model \\\"Location\\\"\"",
            "confidence": 0.7,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "sql_injection",
              "severity": "MEDIUM",
              "confidence": 0.7,
              "evidence": "extensions.response.url = \"http://localhost:8080/api/location/1%27%20OR%20%271%27=%271\" and body.error = \"Cast to Number failed for value \\\"1\\' OR \\'1\\'=\\'1\\\" at path \\\"id\\\" for model \\\"Location\\\"\"",
              "explanation": "The GraphQL error shows a classic SQL injection payload (1' OR '1'='1) encoded in the request URL and reflected in the server-side error: the application attempted to use the raw payload as an id and failed when casting to Number. This indicates user input is being passed into the data-access layer without proper validation or sanitization and is leaking into error messages. Although the attempt resulted in a cast failure (so this specific payload did not execute as a successful SQL injection), the reflection of the raw payload and the DB/model error demonstrates a weakness that could be exploitable (different input formats, other endpoints, or query contexts might succeed). Recommend treating this as a likely SQL injection vulnerability: validate and strictly type-check inputs, use parameterized queries/ORM methods, and avoid leaking internal errors to clients."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:20:13.594386",
      "node_name": "location_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "location": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:20:28.884860",
      "node_name": "location_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "location": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:20:39.667188",
      "node_name": "location_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "location": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:20:49.810180",
      "node_name": "location_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "location": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:21:03.415267",
      "node_name": "location_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "location": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:21:12.134740",
      "node_name": "location_response_7",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:21:23.593631",
      "node_name": "location_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:21:39.416355",
      "node_name": "location_response_9",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Unknown argument \"name\" on field \"location\" of type \"Query\".",
            "locations": [
              {
                "line": 2,
                "column": 12
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"fields\" on type \"Location\".",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Field \"location\" argument \"id\" of type \"ID!\" is required, but it was not provided.",
            "locations": [
              {
                "line": 2,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: introspection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL API returns detailed validation errors that reveal schema information (field names, types, and required arguments). Although this is not the formal __schema introspection query, these messages disclose enough structure (e.g., a 'location' field on Query, a 'Location' type, and that 'location' requires an 'id' of type ID!) to allow an attacker to enumerate and map the API. This information disclosure can be used to craft targeted queries and amplify other attacks. Recommend disabling verbose error messages in production or returning generic errors, and restrict or disable introspection/schema exposure where possible.",
            "evidence": "\"Unknown argument \\\"name\\\" on field \\\"location\\\" of type \\\"Query\\\".\", \"Cannot query field \\\"fields\\\" on type \\\"Location\\\".\", \"Field \\\"location\\\" argument \\\"id\\\" of type \\\"ID!\\\" is required, but it was not provided.\"",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "introspection",
              "severity": "MEDIUM",
              "confidence": 0.85,
              "evidence": "\"Unknown argument \\\"name\\\" on field \\\"location\\\" of type \\\"Query\\\".\", \"Cannot query field \\\"fields\\\" on type \\\"Location\\\".\", \"Field \\\"location\\\" argument \\\"id\\\" of type \\\"ID!\\\" is required, but it was not provided.\"",
              "explanation": "The GraphQL API returns detailed validation errors that reveal schema information (field names, types, and required arguments). Although this is not the formal __schema introspection query, these messages disclose enough structure (e.g., a 'location' field on Query, a 'Location' type, and that 'location' requires an 'id' of type ID!) to allow an attacker to enumerate and map the API. This information disclosure can be used to craft targeted queries and amplify other attacks. Recommend disabling verbose error messages in production or returning generic errors, and restrict or disable introspection/schema exposure where possible."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-02T20:21:52.325322",
      "node_name": "location_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"nam\" on type \"Location\". Did you mean \"name\"?",
            "locations": [
              {
                "line": 3,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"typ\" on type \"Location\". Did you mean \"type\"?",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"dimensin\" on type \"Location\". Did you mean \"dimension\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL error responses include \"Did you mean ...\" suggestions that reveal valid field names on the Location type. This leaks schema details (field names) that an attacker can use for reconnaissance and to craft targeted queries even if introspection is restricted. Although this does not directly expose sensitive data, it is an information disclosure that facilitates further probing and potentially other attacks. Recommended mitigations: disable or suppress field-suggestion/auto-correct messages in production, return generic validation errors, turn off detailed debug output, or implement error masking/logging that prevents schema hints from being sent to clients.",
            "evidence": "Error messages: \"Cannot query field \\\"nam\\\" on type \\\"Location\\\". Did you mean \\\"name\\\"?\", \"Cannot query field \\\"typ\\\" on type \\\"Location\\\". Did you mean \\\"type\\\"?\", \"Cannot query field \\\"dimensin\\\" on type \\\"Location\\\". Did you mean \\\"dimension\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "Error messages: \"Cannot query field \\\"nam\\\" on type \\\"Location\\\". Did you mean \\\"name\\\"?\", \"Cannot query field \\\"typ\\\" on type \\\"Location\\\". Did you mean \\\"type\\\"?\", \"Cannot query field \\\"dimensin\\\" on type \\\"Location\\\". Did you mean \\\"dimension\\\"?\"",
              "explanation": "The GraphQL error responses include \"Did you mean ...\" suggestions that reveal valid field names on the Location type. This leaks schema details (field names) that an attacker can use for reconnaissance and to craft targeted queries even if introspection is restricted. Although this does not directly expose sensitive data, it is an information disclosure that facilitates further probing and potentially other attacks. Recommended mitigations: disable or suppress field-suggestion/auto-correct messages in production, return generic validation errors, turn off detailed debug output, or implement error masking/logging that prevents schema hints from being sent to clients."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}