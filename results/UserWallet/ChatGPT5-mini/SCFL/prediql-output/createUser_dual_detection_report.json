{
  "report_timestamp": "2025-10-08T09:34:05.168015",
  "api_url": "http://localhost:4000/graphql",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 6,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 3,
      "both_detected": 3,
      "no_vulnerabilities": 3,
      "llm_only": 1
    },
    "detection_ratio": 0.6666666666666666,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 5,
      "llm_potential_detections": 2,
      "potential_consensus_breakdown": {
        "simple_potential_only": 4,
        "no_potential": 4,
        "both_potential": 1,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 0.4
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-08T09:31:37.197200",
      "node_name": "createUser_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "330e3316-dd85-42b5-bdfa-9e33e6814c49",
            "firstName": "Robert'); DROP TABLE users;--",
            "lastName": "Smith",
            "description": "SQLi probe in firstName"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:31:50.970241",
      "node_name": "createUser_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "945d1df2-92cc-4cf2-a3b1-977bd9c33c03",
            "firstName": "Eve",
            "lastName": "Malory",
            "description": "<script>alert('xss')</script>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains raw script tags in the description field returned by the createUser mutation. This indicates the API accepted and returned HTML/JS payload without escaping or sanitization. If this value is ever rendered in a browser context (e.g., in a web UI) without proper output encoding or sanitization, it would result in reflected or stored XSS, allowing arbitrary JavaScript execution in users' browsers. Recommendation: treat this as untrusted input—validate/strip dangerous markup on input, and always HTML-encode/escape values on output. Implement context-aware encoding, Content-Security-Policy, and input validation to mitigate XSS.",
            "evidence": "data.createUser.description = \"<script>alert('xss')</script>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "data.createUser.description = \"<script>alert('xss')</script>\"",
              "explanation": "The GraphQL response contains raw script tags in the description field returned by the createUser mutation. This indicates the API accepted and returned HTML/JS payload without escaping or sanitization. If this value is ever rendered in a browser context (e.g., in a web UI) without proper output encoding or sanitization, it would result in reflected or stored XSS, allowing arbitrary JavaScript execution in users' browsers. Recommendation: treat this as untrusted input—validate/strip dangerous markup on input, and always HTML-encode/escape values on output. Implement context-aware encoding, Content-Security-Policy, and input validation to mitigate XSS."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:32:14.365651",
      "node_name": "createUser_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "0a5cda23-4657-43da-90cb-abe425267296",
            "firstName": "ServiceProbe",
            "lastName": "Fetcher",
            "description": "http://169.254.169.254/latest/meta-data/iam/security-credentials/"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:32:26.335058",
      "node_name": "createUser_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "646bc206-38b4-4c8c-b6e9-abf6316d937c",
            "firstName": "os_inject; cat /etc/passwd",
            "lastName": "Tester",
            "description": "Attempt to trigger shell execution"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:32:47.786598",
      "node_name": "createUser_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "61a29a68-a0ab-4f1e-a15d-864528d3d360",
            "firstName": "Traversal",
            "lastName": "Probe",
            "description": "../../../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:33:20.398082",
      "node_name": "createUser_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "f3db38a1-082b-4f8d-ab78-ba072dd919ea",
            "firstName": "HtmlProbe",
            "lastName": "Designer",
            "description": "<div><b>Injected HTML</b><a href=\"http://evil.example.com\">link</a></div>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns raw HTML markup in the `description` field (<div>, <b>, <a href=\"http://evil.example.com\">...). This is clear evidence of HTML content being stored/returned by the API. If a client (web page or other HTML-rendering consumer) inserts this value into the DOM without proper output encoding or sanitization, an attacker could supply crafted HTML (including script tags, event handlers, or javascript: links) to achieve XSS or other HTML-based attacks. From the response alone we cannot confirm whether the client escapes or sanitizes this content before rendering, so the finding is classified as a potential HTML injection vulnerability with medium severity. Recommended mitigations: validate and sanitize user-supplied content on input, escape/encode content on output, enforce a strict content policy (e.g., allow-listing safe tags/attributes) or store plain text only, and review all clients that consume this field to ensure safe rendering.",
            "evidence": "\"description\": \"<div><b>Injected HTML</b><a href=\\\"http://evil.example.com\\\">link</a></div>\"",
            "confidence": 0.7,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "MEDIUM",
              "confidence": 0.7,
              "evidence": "\"description\": \"<div><b>Injected HTML</b><a href=\\\"http://evil.example.com\\\">link</a></div>\"",
              "explanation": "The GraphQL response returns raw HTML markup in the `description` field (<div>, <b>, <a href=\"http://evil.example.com\">...). This is clear evidence of HTML content being stored/returned by the API. If a client (web page or other HTML-rendering consumer) inserts this value into the DOM without proper output encoding or sanitization, an attacker could supply crafted HTML (including script tags, event handlers, or javascript: links) to achieve XSS or other HTML-based attacks. From the response alone we cannot confirm whether the client escapes or sanitizes this content before rendering, so the finding is classified as a potential HTML injection vulnerability with medium severity. Recommended mitigations: validate and sanitize user-supplied content on input, escape/encode content on output, enforce a strict content policy (e.g., allow-listing safe tags/attributes) or store plain text only, and review all clients that consume this field to ensure safe rendering."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:33:29.881114",
      "node_name": "createUser_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:33:39.166020",
      "node_name": "createUser_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:33:54.309687",
      "node_name": "createUser_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createUser\" on type \"Query\". Did you mean \"getUser\" or \"getUsers\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED",
              "exception": {
                "stacktrace": [
                  "GraphQLError: Cannot query field \"createUser\" on type \"Query\". Did you mean \"getUser\" or \"getUsers\"?",
                  "    at Object.Field (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/validation/rules/FieldsOnCorrectTypeRule.js:46:31)",
                  "    at Object.enter (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/language/visitor.js:323:29)",
                  "    at Object.enter (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/utilities/TypeInfo.js:370:25)",
                  "    at visit (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/language/visitor.js:243:26)",
                  "    at Object.validate (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/validation/validate.js:69:24)",
                  "    at validate (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/apollo-server-core/dist/requestPipeline.js:221:34)",
                  "    at Object.<anonymous> (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/apollo-server-core/dist/requestPipeline.js:118:42)",
                  "    at Generator.next (<anonymous>)",
                  "    at fulfilled (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/apollo-server-core/dist/requestPipeline.js:5:58)",
                  "    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)"
                ]
              }
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: GraphQL Introspection / Schema Disclosure",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The error response reveals internal schema information by suggesting valid field names (getUser, getUsers) when an invalid field (createUser) is queried. This is effectively schema disclosure — a form of GraphQL introspection leakage — because it lets an attacker enumerate available operations/fields without using explicit introspection queries. Additionally, the response includes a full server stacktrace and internal filesystem paths, which further discloses implementation details. Together, these disclosures make it easier for an attacker to map the API, craft targeted queries, and identify server software/paths. Recommendation: suppress detailed validation/suggestion messages and stacktraces in production (return generic errors), and restrict or protect GraphQL introspection and error verbosity based on authentication/role.",
            "evidence": "\"Cannot query field \\\"createUser\\\" on type \\\"Query\\\". Did you mean \\\"getUser\\\" or \\\"getUsers\\\"?\" and full server stacktrace lines (e.g. /Users/sina/Documents/GraphQLer2022/test_server/node_modules/...) in the response",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "GraphQL Introspection / Schema Disclosure",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "\"Cannot query field \\\"createUser\\\" on type \\\"Query\\\". Did you mean \\\"getUser\\\" or \\\"getUsers\\\"?\" and full server stacktrace lines (e.g. /Users/sina/Documents/GraphQLer2022/test_server/node_modules/...) in the response",
              "explanation": "The error response reveals internal schema information by suggesting valid field names (getUser, getUsers) when an invalid field (createUser) is queried. This is effectively schema disclosure — a form of GraphQL introspection leakage — because it lets an attacker enumerate available operations/fields without using explicit introspection queries. Additionally, the response includes a full server stacktrace and internal filesystem paths, which further discloses implementation details. Together, these disclosures make it easier for an attacker to map the API, craft targeted queries, and identify server software/paths. Recommendation: suppress detailed validation/suggestion messages and stacktraces in production (return generic errors), and restrict or protect GraphQL introspection and error verbosity based on authentication/role."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-08T09:34:05.164033",
      "node_name": "createUser_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"fristName\" on type \"User\". Did you mean \"firstName\" or \"lastName\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED",
              "exception": {
                "stacktrace": [
                  "GraphQLError: Cannot query field \"fristName\" on type \"User\". Did you mean \"firstName\" or \"lastName\"?",
                  "    at Object.Field (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/validation/rules/FieldsOnCorrectTypeRule.js:46:31)",
                  "    at Object.enter (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/language/visitor.js:323:29)",
                  "    at Object.enter (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/utilities/TypeInfo.js:370:25)",
                  "    at visit (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/language/visitor.js:243:26)",
                  "    at Object.validate (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/graphql/validation/validate.js:69:24)",
                  "    at validate (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/apollo-server-core/dist/requestPipeline.js:221:34)",
                  "    at Object.<anonymous> (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/apollo-server-core/dist/requestPipeline.js:118:42)",
                  "    at Generator.next (<anonymous>)",
                  "    at fulfilled (/Users/sina/Documents/GraphQLer2022/test_server/node_modules/apollo-server-core/dist/requestPipeline.js:5:58)",
                  "    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)"
                ]
              }
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "safe",
            "category": "Unknown",
            "description": "The GraphQL server returns a validation error that includes suggested field names (\"Did you mean 'firstName' or 'lastName'?\"). This leaks schema information and helps an attacker enumerate available fields/types. Such field suggestions are a form of information disclosure (field_suggestions) that can be leveraged during reconnaissance to map the API. The response clearly contains the suggestion text, so this is a confirmed instance of the vulnerability. Recommended mitigations: disable detailed suggestion messages in production (e.g., configure GraphQL server to suppress or genericize validation hints), and avoid exposing stack traces or internal paths in errors.",
            "evidence": "Error message: \"Cannot query field \\\"fristName\\\" on type \\\"User\\\". Did you mean \\\"firstName\\\" or \\\"lastName\\\"?\" (returned in response body, status 400)",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "Error message: \"Cannot query field \\\"fristName\\\" on type \\\"User\\\". Did you mean \\\"firstName\\\" or \\\"lastName\\\"?\" (returned in response body, status 400)",
              "explanation": "The GraphQL server returns a validation error that includes suggested field names (\"Did you mean 'firstName' or 'lastName'?\"). This leaks schema information and helps an attacker enumerate available fields/types. Such field suggestions are a form of information disclosure (field_suggestions) that can be leveraged during reconnaissance to map the API. The response clearly contains the suggestion text, so this is a confirmed instance of the vulnerability. Recommended mitigations: disable detailed suggestion messages in production (e.g., configure GraphQL server to suppress or genericize validation hints), and avoid exposing stack traces or internal paths in errors."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Unknown"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}