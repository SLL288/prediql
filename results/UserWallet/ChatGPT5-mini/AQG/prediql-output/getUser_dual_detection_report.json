{
  "report_timestamp": "2025-10-08T19:39:12.778634",
  "api_url": "http://localhost:4000/graphql",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.0,
    "simple_detections": 0,
    "llm_detections": 3,
    "consensus_breakdown": {
      "no_vulnerabilities": 7,
      "llm_only": 3
    },
    "detection_ratio": Infinity,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 3,
      "potential_consensus_breakdown": {
        "no_potential": 7,
        "llm_potential_only": 3
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-08T19:36:47.686912",
      "node_name": "getUser_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "getUser": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:37:16.023177",
      "node_name": "getUser_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "getUser": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:37:32.305961",
      "node_name": "getUser_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "getUser": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:37:46.715463",
      "node_name": "getUser_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "getUser": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:38:03.690398",
      "node_name": "getUser_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "getUser": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:38:16.712340",
      "node_name": "getUser_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "getUser": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:38:29.000926",
      "node_name": "getUser_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:38:40.684278",
      "node_name": "getUser_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: unknown",
            "detection": "potential",
            "category": "Unknown",
            "description": "{\n    \"is_vulnerable\": false,\n    \"vulnerability_type\": \"query_deny_bypass\",\n    \"severity\": \"LOW\",\n    \"confidence\": 0.90,\n    \"evidence\": \"Non-aliased response: HTTP 200, response_body.data.getUser == null; Aliased response: HTTP 200, response_body.data.s == null; no errors or 'access denied' messages in either response.\",\n    \"explanation\": \"The detection criteria for a query deny bypass are not met. The non-aliased query was not blocked (it returned HTTP 200 and no errors), and the aliased query did not return data — it also returned null. There is no case where the non-aliased query returns an error/denial while the aliased query succeeds with data. Both responses are identical in effect (null result) and contain no access-denied or forbidden error messages, so there is no clear evidence that access control can be bypassed using query aliases. Recommendation: if you expect data but receive null, investigate whether the null indicates 'not found' vs. 'access denied' on the server; rerun tests with a query known to be denied (should return explicit error) to validate bypass testing.\"",
            "evidence": "Found vulnerability indicators in response",
            "confidence": 0.3,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "unknown",
              "severity": "MEDIUM",
              "confidence": 0.3,
              "evidence": "Found vulnerability indicators in response",
              "explanation": "{\n    \"is_vulnerable\": false,\n    \"vulnerability_type\": \"query_deny_bypass\",\n    \"severity\": \"LOW\",\n    \"confidence\": 0.90,\n    \"evidence\": \"Non-aliased response: HTTP 200, response_body.data.getUser == null; Aliased response: HTTP 200, response_body.data.s == null; no errors or 'access denied' messages in either response.\",\n    \"explanation\": \"The detection criteria for a query deny bypass are not met. The non-aliased query was not blocked (it returned HTTP 200 and no errors), and the aliased query did not return data — it also returned null. There is no case where the non-aliased query returns an error/denial while the aliased query succeeds with data. Both responses are identical in effect (null result) and contain no access-denied or forbidden error messages, so there is no clear evidence that access control can be bypassed using query aliases. Recommendation: if you expect data but receive null, investigate whether the null indicates 'not found' vs. 'access denied' on the server; rerun tests with a query known to be denied (should return explicit error) to validate bypass testing.\""
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:38:54.817812",
      "node_name": "getUser_response_10",
      "response_status": 200,
      "response_body": {
        "data": {
          "getUser": null,
          "__type": {
            "name": "User",
            "fields": [
              {
                "name": "id"
              },
              {
                "name": "firstName"
              },
              {
                "name": "lastName"
              },
              {
                "name": "description"
              },
              {
                "name": "wallets"
              },
              {
                "name": "friends"
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: GraphQL Introspection Disclosure",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The response contains a GraphQL introspection field (__type) returning the User type name and its fields. This is clear evidence that GraphQL introspection is enabled/accessible. Introspection exposes the schema and available fields (here: id, firstName, lastName, description, wallets, friends), which can help an attacker enumerate types, discover sensitive fields or mutations, and craft targeted queries for data extraction or privilege escalation. While introspection alone is not direct data exfiltration, it significantly reduces attack effort and increases the risk surface. Recommended mitigations: disable introspection in production or restrict it to authenticated/authorized users, enforce query depth/complexity limits, and apply strong authz checks and rate limiting.",
            "evidence": "\"__type\": { \"name\": \"User\", \"fields\": [ { \"name\": \"id\" }, { \"name\": \"firstName\" }, { \"name\": \"lastName\" }, { \"name\": \"description\" }, { \"name\": \"wallets\" }, { \"name\": \"friends\" } ] }",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "GraphQL Introspection Disclosure",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "\"__type\": { \"name\": \"User\", \"fields\": [ { \"name\": \"id\" }, { \"name\": \"firstName\" }, { \"name\": \"lastName\" }, { \"name\": \"description\" }, { \"name\": \"wallets\" }, { \"name\": \"friends\" } ] }",
              "explanation": "The response contains a GraphQL introspection field (__type) returning the User type name and its fields. This is clear evidence that GraphQL introspection is enabled/accessible. Introspection exposes the schema and available fields (here: id, firstName, lastName, description, wallets, friends), which can help an attacker enumerate types, discover sensitive fields or mutations, and craft targeted queries for data extraction or privilege escalation. While introspection alone is not direct data exfiltration, it significantly reduces attack effort and increases the risk surface. Recommended mitigations: disable introspection in production or restrict it to authenticated/authorized users, enforce query depth/complexity limits, and apply strong authz checks and rate limiting."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-08T19:39:12.772859",
      "node_name": "getUser_response_11",
      "response_status": 200,
      "response_body": {
        "data": {
          "getUser": null,
          "__type": {
            "fields": [
              {
                "name": "id"
              },
              {
                "name": "firstName"
              },
              {
                "name": "lastName"
              },
              {
                "name": "description"
              },
              {
                "name": "wallets"
              },
              {
                "name": "friends"
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL response includes a __type object listing available field names (id, firstName, lastName, description, wallets, friends). This is explicit schema/field disclosure (field suggestions), which enables an attacker to enumerate the API schema and discover available fields to query for sensitive data. No other exploitation (SQLi, XSS, SSRF, etc.) is evident in the provided response, but disclosure of schema information increases attack surface and should be restricted (e.g., disable introspection in production or enforce authorization on schema access).",
            "evidence": "\"__type\": { \"fields\": [ { \"name\": \"id\" }, { \"name\": \"firstName\" }, { \"name\": \"lastName\" }, { \"name\": \"description\" }, { \"name\": \"wallets\" }, { \"name\": \"friends\" } ] }",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "\"__type\": { \"fields\": [ { \"name\": \"id\" }, { \"name\": \"firstName\" }, { \"name\": \"lastName\" }, { \"name\": \"description\" }, { \"name\": \"wallets\" }, { \"name\": \"friends\" } ] }",
              "explanation": "The GraphQL response includes a __type object listing available field names (id, firstName, lastName, description, wallets, friends). This is explicit schema/field disclosure (field suggestions), which enables an attacker to enumerate the API schema and discover available fields to query for sensitive data. No other exploitation (SQLi, XSS, SSRF, etc.) is evident in the provided response, but disclosure of schema information increases attack surface and should be restricted (e.g., disable introspection in production or enforce authorization on schema access)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}