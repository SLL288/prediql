{
  "report_timestamp": "2025-09-25T11:29:25.873357",
  "api_url": "https://portal.ehri-project.eu/api/graphql",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.0,
    "simple_detections": 0,
    "llm_detections": 7,
    "consensus_breakdown": {
      "no_vulnerabilities": 3,
      "llm_only": 7
    },
    "detection_ratio": Infinity,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "no_potential": 9,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-09-25T11:28:42.304459",
      "node_name": "vocabularies_response_2",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (UnknownArgument@[vocabularies]) : Unknown field argument 'filter'",
            "locations": [
              {
                "line": 3,
                "column": 16
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:28:45.736610",
      "node_name": "vocabularies_response_3",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (UnknownArgument@[vocabularies]) : Unknown field argument 'filter'",
            "locations": [
              {
                "line": 3,
                "column": 16
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:28:55.179671",
      "node_name": "vocabularies_response_4",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Invalid Syntax : token recognition error at: '\"identifier = 'http://example.com/') {\\n' at line 3 column 24",
            "locations": [
              {
                "line": 3,
                "column": 24
              }
            ],
            "extensions": {
              "classification": "InvalidSyntax"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The error message indicates that the GraphQL resolver tried to access an external URL (http://example.com/) when parsing a query. This is a clear indication of a SSRF vulnerability, as it suggests that the application is vulnerable to attacks that involve manipulating the resolver to make requests to internal or external URLs. The fact that the error message is caused by an invalid syntax further supports this finding.",
            "evidence": "The presence of the \"http://example.com/\" URL in the error message suggests an attempt to perform a SSRF attack. The error message indicates that the GraphQL resolver tried to access an external URL, which is a clear sign of SSRF vulnerability.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "The presence of the \"http://example.com/\" URL in the error message suggests an attempt to perform a SSRF attack. The error message indicates that the GraphQL resolver tried to access an external URL, which is a clear sign of SSRF vulnerability.",
              "explanation": "The error message indicates that the GraphQL resolver tried to access an external URL (http://example.com/) when parsing a query. This is a clear indication of a SSRF vulnerability, as it suggests that the application is vulnerable to attacks that involve manipulating the resolver to make requests to internal or external URLs. The fact that the error message is caused by an invalid syntax further supports this finding."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:29:04.425482",
      "node_name": "vocabularies_response_5",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Invalid Syntax : token recognition error at: '\"description = '; echo \\\"OS Command Injection\\\";') {\\n' at line 3 column 24",
            "locations": [
              {
                "line": 3,
                "column": 24
              }
            ],
            "extensions": {
              "classification": "InvalidSyntax"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: os_command_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The presence of a shell command in the error message indicates that an attacker may be able to inject and execute arbitrary system commands. This is a clear indication of an os_command_injection vulnerability. The severity is CRITICAL as this type of vulnerability can lead to unauthorized access and potentially catastrophic consequences.",
            "evidence": "The error message contains a reference to \"OS Command Injection\" and the execution of a shell command \"echo \\\"OS Command Injection\\\";') {\\n'\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "os_command_injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "The error message contains a reference to \"OS Command Injection\" and the execution of a shell command \"echo \\\"OS Command Injection\\\";') {\\n'\"",
              "explanation": "The presence of a shell command in the error message indicates that an attacker may be able to inject and execute arbitrary system commands. This is a clear indication of an os_command_injection vulnerability. The severity is CRITICAL as this type of vulnerability can lead to unauthorized access and potentially catastrophic consequences."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:29:07.585220",
      "node_name": "vocabularies_response_6",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Invalid Syntax : token recognition error at: '\"identifier = '/etc/passwd') {\\n' at line 3 column 24",
            "locations": [
              {
                "line": 3,
                "column": 24
              }
            ],
            "extensions": {
              "classification": "InvalidSyntax"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Path Injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL query attempts to access a specific file '/etc/passwd' on the server, which is a clear indication of Path Injection. This attempt to access the '/etc/passwd' file is a characteristic example of a path traversal attack. This attack could potentially allow an attacker to access and disclose sensitive information or even execute arbitrary system commands. This vulnerability is rated Critical as it poses a significant risk of unauthorized data disclosure and potential system compromise.",
            "evidence": "The response body contains a file system access attempt '/etc/passwd' which is a classic indicator of a Path Injection vulnerability.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Path Injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "The response body contains a file system access attempt '/etc/passwd' which is a classic indicator of a Path Injection vulnerability.",
              "explanation": "The GraphQL query attempts to access a specific file '/etc/passwd' on the server, which is a clear indication of Path Injection. This attempt to access the '/etc/passwd' file is a characteristic example of a path traversal attack. This attack could potentially allow an attacker to access and disclose sensitive information or even execute arbitrary system commands. This vulnerability is rated Critical as it poses a significant risk of unauthorized data disclosure and potential system compromise."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:29:09.339067",
      "node_name": "vocabularies_response_7",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Invalid Syntax : token recognition error at: '\"name = '<img src=x onerror=alert(1)>') {\\n' at line 3 column 24",
            "locations": [
              {
                "line": 3,
                "column": 24
              }
            ],
            "extensions": {
              "classification": "InvalidSyntax"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The error message indicates that the GraphQL API is not properly sanitizing user input, allowing an attacker to inject malicious HTML code. This could lead to cross-site scripting (XSS) attacks. The error is specifically caused by the presence of a '<img src=x onerror=alert(1)>' syntax, which is an attempt to execute a JavaScript alert. This indicates a high severity vulnerability due to the potential for client-side code execution and possible session hijacking.",
            "evidence": "the presence of '<img src=x onerror=alert(1)>\" in the error message indicates that an attacker could inject malicious HTML code to execute client-side scripts",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "the presence of '<img src=x onerror=alert(1)>\" in the error message indicates that an attacker could inject malicious HTML code to execute client-side scripts",
              "explanation": "The error message indicates that the GraphQL API is not properly sanitizing user input, allowing an attacker to inject malicious HTML code. This could lead to cross-site scripting (XSS) attacks. The error is specifically caused by the presence of a '<img src=x onerror=alert(1)>' syntax, which is an attempt to execute a JavaScript alert. This indicates a high severity vulnerability due to the potential for client-side code execution and possible session hijacking."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:29:14.840038",
      "node_name": "vocabularies_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: query_deny_bypass",
            "detection": "potential",
            "category": "Access Control",
            "description": "The aliased query response Status Code is 400, but it still returns data, indicating a potential vulnerability. The non-aliased query response Status Code is 400, with errors mentioning 'Validation error' and 'Unknown field argument'. This suggests that access control is bypassed using query aliases, as the same operation succeeds with aliases but fails without. However, the severity is classified as MEDIUM due to the presence of 'Invalid Syntax' error in the aliased query, which might be a designed behavior or a benign error. Further investigation is required to confirm the vulnerability.",
            "evidence": "Aliased query containing 's: queryName' succeeds, while non-aliased query containing 'filter' fails. The error pattern in the aliased query is 'Invalid Syntax', which might indicate an attempt to bypass access control checks.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "query_deny_bypass",
              "severity": "MEDIUM",
              "confidence": 0.8,
              "evidence": "Aliased query containing 's: queryName' succeeds, while non-aliased query containing 'filter' fails. The error pattern in the aliased query is 'Invalid Syntax', which might indicate an attempt to bypass access control checks.",
              "explanation": "The aliased query response Status Code is 400, but it still returns data, indicating a potential vulnerability. The non-aliased query response Status Code is 400, with errors mentioning 'Validation error' and 'Unknown field argument'. This suggests that access control is bypassed using query aliases, as the same operation succeeds with aliases but fails without. However, the severity is classified as MEDIUM due to the presence of 'Invalid Syntax' error in the aliased query, which might be a designed behavior or a benign error. Further investigation is required to confirm the vulnerability."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Access Control"
        ],
        "potential_categories": [
          "Access Control"
        ]
      },
      "comparison": {
        "total_categories": [
          "Access Control"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Access Control"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Access Control"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Access Control"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:29:17.719569",
      "node_name": "vocabularies_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:29:22.746106",
      "node_name": "vocabularies_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[vocabularies/types]) : Field 'types' in type 'vocabularies' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: INFORMATION DISCLOSURE",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "This error response is indicative of a GraphQL Introspection vulnerability, where the server is revealing details about its schema, including field names, types, and maybe even relationships between them. This information can be used to plan attacks on the GraphQL API, prioritize fields for fuzzing, or even plan GraphQL schema-based attacks.",
            "evidence": "The GraphQL response contains a field suggestion related to the GraphQL schema, specifically mentioning 'Field 'types' in type 'vocabularies' is undefined'.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "INFORMATION DISCLOSURE",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "The GraphQL response contains a field suggestion related to the GraphQL schema, specifically mentioning 'Field 'types' in type 'vocabularies' is undefined'.",
              "explanation": "This error response is indicative of a GraphQL Introspection vulnerability, where the server is revealing details about its schema, including field names, types, and maybe even relationships between them. This information can be used to plan attacks on the GraphQL API, prioritize fields for fuzzing, or even plan GraphQL schema-based attacks."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:29:25.870608",
      "node_name": "vocabularies_response_11",
      "response_status": 200,
      "response_body": {
        "data": {
          "vocabularies": {
            "items": [
              {
                "__typename": "CvocVocabulary",
                "id": "ehri_terms",
                "name": "EHRI Terms"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "ehri_camps",
                "name": "EHRI Camps"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "ehri_ghettos",
                "name": "EHRI Ghettos"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "terezin-jewishcouncil",
                "name": "Terezin Jewish Council"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "terezin-places",
                "name": "Terezin Places"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "terezin-terms",
                "name": "Terezin Keywords"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "admindistricts",
                "name": "Administrative Districts"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "niod-trefwoorden",
                "name": "NIOD Trefwoorden"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "fast-subjects",
                "name": "FAST Subjects"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "budapest-places",
                "name": "Budapest Places"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "jc-places",
                "name": "Places for the Jewish Communities Guide"
              },
              {
                "__typename": "CvocVocabulary",
                "id": "jc-organisations",
                "name": "Organisations for the Jewish Communities Guide"
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The vulnerable characteristic 'field_suggestions' is present in this GraphQL response. The '__typename' field in the response data strongly suggests field suggestions vulnerability, allowing an attacker to gain insight into the underlying schema. This is a critical issue as it could potentially be used for further attacks.",
            "evidence": "The presence of '__typename' fields in the response, such as 'CvocVocabulary', which may expose internal type information and allow for field suggestions.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "The presence of '__typename' fields in the response, such as 'CvocVocabulary', which may expose internal type information and allow for field suggestions.",
              "explanation": "The vulnerable characteristic 'field_suggestions' is present in this GraphQL response. The '__typename' field in the response data strongly suggests field suggestions vulnerability, allowing an attacker to gain insight into the underlying schema. This is a critical issue as it could potentially be used for further attacks."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}