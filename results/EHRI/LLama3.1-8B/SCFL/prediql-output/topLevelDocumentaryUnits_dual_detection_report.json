{
  "report_timestamp": "2025-09-25T11:17:31.671070",
  "api_url": "https://portal.ehri-project.eu/api/graphql",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.0,
    "simple_detections": 0,
    "llm_detections": 4,
    "consensus_breakdown": {
      "no_vulnerabilities": 6,
      "llm_only": 4
    },
    "detection_ratio": Infinity,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 0,
      "potential_consensus_breakdown": {
        "no_potential": 10
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-09-25T11:17:03.504877",
      "node_name": "topLevelDocumentaryUnits_response_1",
      "response_status": 200,
      "response_body": {
        "data": {
          "topLevelDocumentaryUnits": {
            "items": [
              {
                "id": "at-006597-01",
                "type": "DocumentaryUnit"
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:05.928120",
      "node_name": "topLevelDocumentaryUnits_response_2",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (UnknownArgument@[topLevelDocumentaryUnits]) : Unknown field argument 'term'",
            "locations": [
              {
                "line": 3,
                "column": 28
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[topLevelDocumentaryUnits/results]) : Field 'results' in type 'documentaryUnits' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:07.879104",
      "node_name": "topLevelDocumentaryUnits_response_3",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[f]) : Field 'f' in type 'Root' is undefined",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:09.523411",
      "node_name": "topLevelDocumentaryUnits_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "topLevelDocumentaryUnits": {
            "items": [
              {
                "id": "at-006597-01",
                "type": "DocumentaryUnit"
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:13.200836",
      "node_name": "topLevelDocumentaryUnits_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "topLevelDocumentaryUnits": {
            "items": [
              {
                "id": "at-006597-01",
                "type": "DocumentaryUnit"
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: path_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The response body contains a field 'id' with a value 'at-006597-01' which seems to be a base64-encoded string. Although this might be a legitimate ID in the context of the API, it's worth noting that base64-encoded strings can be used to conceal malicious payloads, including path injection attacks. An attacker could potentially inject malicious path traversal characters to access sensitive files or directories on the server-side. This is a critical vulnerability as it could lead to unauthorized access to sensitive data or system resources.",
            "evidence": "The 'id' field in the response body contains a base64-encoded string that could potentially be used to access arbitrary file paths if not properly sanitized.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "path_injection",
              "severity": "CRITICAL",
              "confidence": 0.8,
              "evidence": "The 'id' field in the response body contains a base64-encoded string that could potentially be used to access arbitrary file paths if not properly sanitized.",
              "explanation": "The response body contains a field 'id' with a value 'at-006597-01' which seems to be a base64-encoded string. Although this might be a legitimate ID in the context of the API, it's worth noting that base64-encoded strings can be used to conceal malicious payloads, including path injection attacks. An attacker could potentially inject malicious path traversal characters to access sensitive files or directories on the server-side. This is a critical vulnerability as it could lead to unauthorized access to sensitive data or system resources."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:20.201584",
      "node_name": "topLevelDocumentaryUnits_response_6",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (UnknownArgument@[topLevelDocumentaryUnits]) : Unknown field argument 'term'",
            "locations": [
              {
                "line": 3,
                "column": 28
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[topLevelDocumentaryUnits/results]) : Field 'results' in type 'documentaryUnits' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The error message contains HTML tags '<' and '>' which could be used to inject malicious content. This could allow an attacker to execute arbitrary JavaScript code or inject other malicious content into the response, potentially leading to Cross-Site Scripting (XSS) attacks. While the error message itself is not directly executable, an attacker could potentially craft a malicious query that would result in a similar error message with injected content. This vulnerability is considered HIGH severity because it could potentially lead to a significant security risk if exploited.",
            "evidence": "The presence of HTML tags in the error message suggests that an attacker could inject malicious HTML content into the response.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "The presence of HTML tags in the error message suggests that an attacker could inject malicious HTML content into the response.",
              "explanation": "The error message contains HTML tags '<' and '>' which could be used to inject malicious content. This could allow an attacker to execute arbitrary JavaScript code or inject other malicious content into the response, potentially leading to Cross-Site Scripting (XSS) attacks. While the error message itself is not directly executable, an attacker could potentially craft a malicious query that would result in a similar error message with injected content. This vulnerability is considered HIGH severity because it could potentially lead to a significant security risk if exploited."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:22.892455",
      "node_name": "topLevelDocumentaryUnits_response_7",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: query_deny_bypass",
            "detection": "vulnerable",
            "category": "Access Control",
            "description": "The scenario indicates a weak validation for malicious query aliases. An attacker could potentially exploit this by crafting alias queries to access restricted data without being detected. Additional analysis or tests should be conducted to verify this hypothesis.",
            "evidence": "Non-aliased query returns a syntax error (400) with 'Invalid Syntax' due to token 'chuck', while the aliased query returns a syntax error (400) without providing actual data, but close enough to indicate potential access control bypass. Similarly, aliased query tries to access invalid token ':' at line 2 column 8, showing that invalid syntax may bypass GraphQL validation.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "query_deny_bypass",
              "severity": "CRITICAL",
              "confidence": 0.8,
              "evidence": "Non-aliased query returns a syntax error (400) with 'Invalid Syntax' due to token 'chuck', while the aliased query returns a syntax error (400) without providing actual data, but close enough to indicate potential access control bypass. Similarly, aliased query tries to access invalid token ':' at line 2 column 8, showing that invalid syntax may bypass GraphQL validation.",
              "explanation": "The scenario indicates a weak validation for malicious query aliases. An attacker could potentially exploit this by crafting alias queries to access restricted data without being detected. Additional analysis or tests should be conducted to verify this hypothesis."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Access Control"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Access Control"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Access Control"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:23.632421",
      "node_name": "topLevelDocumentaryUnits_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:29.327416",
      "node_name": "topLevelDocumentaryUnits_response_9",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[topLevelDocumentaryUnits/query]) : Field 'query' in type 'documentaryUnits' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T11:17:31.669889",
      "node_name": "topLevelDocumentaryUnits_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[topLevelDocumentaryUnits/items/edges]) : Field 'edges' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 6,
                "column": 7
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "This is a critical vulnerability as it allows an attacker to gather information about the structure of the GraphQL schema, which can be used to craft more targeted and effective attacks in the future. The 'FieldUndefined' error message is a clear indication of a field suggestion, which can potentially allow an attacker to gather information about the structure of the GraphQL schema.",
            "evidence": "The presence of the 'Field 'edges' in type 'DocumentaryUnit' is undefined' message in the GraphQL error response suggests that a field suggestion vulnerability exists in the API. The error message explicitly states that the 'edges' field in the 'DocumentaryUnit' type is not defined, which is a clear indication of an information disclosure vulnerability.",
            "confidence": 1.0,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "CRITICAL",
              "confidence": 1.0,
              "evidence": "The presence of the 'Field 'edges' in type 'DocumentaryUnit' is undefined' message in the GraphQL error response suggests that a field suggestion vulnerability exists in the API. The error message explicitly states that the 'edges' field in the 'DocumentaryUnit' type is not defined, which is a clear indication of an information disclosure vulnerability.",
              "explanation": "This is a critical vulnerability as it allows an attacker to gather information about the structure of the GraphQL schema, which can be used to craft more targeted and effective attacks in the future. The 'FieldUndefined' error message is a clear indication of a field suggestion, which can potentially allow an attacker to gather information about the structure of the GraphQL schema."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}