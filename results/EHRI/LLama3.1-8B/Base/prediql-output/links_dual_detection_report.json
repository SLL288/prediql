{
  "report_timestamp": "2025-09-25T06:03:20.336505",
  "api_url": "https://portal.ehri-project.eu/api/graphql",
  "summary": {
    "total_comparisons": 11,
    "agreement_rate": 0.0,
    "simple_detections": 0,
    "llm_detections": 7,
    "consensus_breakdown": {
      "llm_only": 7,
      "no_vulnerabilities": 4
    },
    "detection_ratio": Infinity,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "no_potential": 10,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-09-25T06:02:44.299359",
      "node_name": "links_response_1",
      "response_status": null,
      "response_body": {
        "error": "HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Max retries exceeded with url: /api/graphql (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x16efb3910>, 'Connection to portal.ehri-project.eu timed out. (connect timeout=10)'))"
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: SSRF (Server-Side Request Forgery)",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "This vulnerability occurs because the GraphQL API is making an internal request to 'portal.ehri-project.eu' but did not properly handle the connection timeout. This exposes the internal IP and port of the target server, allowing potential SSRF attacks.",
            "evidence": "The response indicates a timeout when connecting to 'portal.ehri-project.eu' which suggests an internal request, but it also includes the URL in the error message. This could allow an attacker to manipulate the request to make arbitrary internal requests on behalf of the server.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "SSRF (Server-Side Request Forgery)",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "The response indicates a timeout when connecting to 'portal.ehri-project.eu' which suggests an internal request, but it also includes the URL in the error message. This could allow an attacker to manipulate the request to make arbitrary internal requests on behalf of the server.",
              "explanation": "This vulnerability occurs because the GraphQL API is making an internal request to 'portal.ehri-project.eu' but did not properly handle the connection timeout. This exposes the internal IP and port of the target server, allowing potential SSRF attacks."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:02:47.686898",
      "node_name": "links_response_2",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[links/links]) : Field 'links' in type 'links' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: SQL Injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The error message suggests that SQL code is executing, which may indicate a SQL injection vulnerability. The presence of the word 'FieldUndefined' and the specific field 'links' being undefined implies that a database query is failing due to an undefined or non-existent field. This could potentially be exploited by manipulating the GraphQL query to inject malicious SQL code.",
            "evidence": "Field 'links' in type 'links' is undefined (error response message)",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "SQL Injection",
              "severity": "CRITICAL",
              "confidence": 0.8,
              "evidence": "Field 'links' in type 'links' is undefined (error response message)",
              "explanation": "The error message suggests that SQL code is executing, which may indicate a SQL injection vulnerability. The presence of the word 'FieldUndefined' and the specific field 'links' being undefined implies that a database query is failing due to an undefined or non-existent field. This could potentially be exploited by manipulating the GraphQL query to inject malicious SQL code."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:02:51.034467",
      "node_name": "links_response_3",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (UnknownArgument@[links]) : Unknown field argument 'term'",
            "locations": [
              {
                "line": 3,
                "column": 9
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[links/links]) : Field 'links' in type 'links' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:02:56.596402",
      "node_name": "links_response_4",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[links/links]) : Field 'links' in type 'links' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response indicates an error in resolving the field 'links' on the 'links' type, pointing to a SSRF vulnerability. This could indicate that the API is vulnerable to server-side request forgery attacks, which could be exploited to send malicious requests to internal resources.",
            "evidence": "The GraphQL API reveals internal network access through the `Validation error` message which suggests a SSRF vulnerability.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "CRITICAL",
              "confidence": 0.8,
              "evidence": "The GraphQL API reveals internal network access through the `Validation error` message which suggests a SSRF vulnerability.",
              "explanation": "The GraphQL response indicates an error in resolving the field 'links' on the 'links' type, pointing to a SSRF vulnerability. This could indicate that the API is vulnerable to server-side request forgery attacks, which could be exploited to send malicious requests to internal resources."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:02:59.565817",
      "node_name": "links_response_5",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Invalid Syntax : token recognition error at: ''' at line 3 column 26",
            "locations": [
              {
                "line": 3,
                "column": 26
              }
            ],
            "extensions": {
              "classification": "InvalidSyntax"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: os_command_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL server responded with an error message that indicates it attempted to execute a command that was not recognized, possibly due to malicious input. This behavior is indicative of an OS Command Injection vulnerability, where an attacker could manipulate the input to execute arbitrary commands on the server. The lack of proper escaping or sanitization of user input could allow an attacker to inject system commands, leading to potential privilege escalation or system compromise.",
            "evidence": "The error message 'token recognition error at: '' at line 3 column 26' suggests that an invalid command was executed on the server, potentially due to input injection.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "os_command_injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "The error message 'token recognition error at: '' at line 3 column 26' suggests that an invalid command was executed on the server, potentially due to input injection.",
              "explanation": "The GraphQL server responded with an error message that indicates it attempted to execute a command that was not recognized, possibly due to malicious input. This behavior is indicative of an OS Command Injection vulnerability, where an attacker could manipulate the input to execute arbitrary commands on the server. The lack of proper escaping or sanitization of user input could allow an attacker to inject system commands, leading to potential privilege escalation or system compromise."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:03:02.259405",
      "node_name": "links_response_6",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[links/links]) : Field 'links' in type 'links' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Path Injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The error message indicates that a path traversal occurred in the 'links' field, which is a characteristic of path injection vulnerabilities. This could potentially allow an attacker to access or manipulate files outside of the intended filesystem, or perform directory traversal attacks.",
            "evidence": "The error message '_links/links' indicates a path traversed in the 'links' field, suggesting a path injection vulnerability.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Path Injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "The error message '_links/links' indicates a path traversed in the 'links' field, suggesting a path injection vulnerability.",
              "explanation": "The error message indicates that a path traversal occurred in the 'links' field, which is a characteristic of path injection vulnerabilities. This could potentially allow an attacker to access or manipulate files outside of the intended filesystem, or perform directory traversal attacks."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:03:03.174072",
      "node_name": "links_response_7",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[links/links]) : Field 'links' in type 'links' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:03:09.493492",
      "node_name": "links_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:03:12.674751",
      "node_name": "links_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:03:16.982119",
      "node_name": "links_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Invalid Syntax : offending token 'links' at line 3 column 3",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "classification": "InvalidSyntax"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL API appears to be configured with a security feature called 'Schema Validation' or 'Syntax Validation', which is intended to prevent errors from occurring when a user submits a malicious input. However, the presence of this feature does not entirely eliminate the possibility of an Introspection vulnerability. An indirect revelation of the schema can still occur when the server produces structured error messages, such as the one contained in this response, that expose information about the underlying schema. To illustrate further, Introspection is possible when a GraphQL API server incorrectly permits schema interpretation revealing hidden structural information. GraphQL Resolution APIs are known to be vulnerable to this type of attack, and the response we have here, with its precise error description, gives an insight into the server's setup without revealing specific data.",
            "evidence": "The error message 'Invalid Syntax' and the 'classification' extension 'InvalidSyntax' in the response indicate an indirect revelation of the schema's vulnerability to Introspection.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "The error message 'Invalid Syntax' and the 'classification' extension 'InvalidSyntax' in the response indicate an indirect revelation of the schema's vulnerability to Introspection.",
              "explanation": "The GraphQL API appears to be configured with a security feature called 'Schema Validation' or 'Syntax Validation', which is intended to prevent errors from occurring when a user submits a malicious input. However, the presence of this feature does not entirely eliminate the possibility of an Introspection vulnerability. An indirect revelation of the schema can still occur when the server produces structured error messages, such as the one contained in this response, that expose information about the underlying schema. To illustrate further, Introspection is possible when a GraphQL API server incorrectly permits schema interpretation revealing hidden structural information. GraphQL Resolution APIs are known to be vulnerable to this type of attack, and the response we have here, with its precise error description, gives an insight into the server's setup without revealing specific data."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-25T06:03:20.333751",
      "node_name": "links_response_11",
      "response_status": 200,
      "response_body": {
        "data": {
          "links": {
            "edges": [
              {
                "node": {
                  "id": "28539296-c897-11e4-840b-132830f5faa0"
                }
              },
              {
                "node": {
                  "id": "718313b3-c897-11e4-840b-132830f5faa0"
                }
              },
              {
                "node": {
                  "id": "bdef4940-c897-11e4-840b-132830f5faa0"
                }
              },
              {
                "node": {
                  "id": "0025aa2d-c898-11e4-840b-132830f5faa0"
                }
              },
              {
                "node": {
                  "id": "40388eda-c898-11e4-840b-132830f5faa0"
                }
              },
              {
                "node": {
                  "id": "9fa552fc-c8c2-11e4-b7bf-4dff20362a6d"
                }
              },
              {
                "node": {
                  "id": "9fa5c82e-c8c2-11e4-b7bf-4dff20362a6d"
                }
              },
              {
                "node": {
                  "id": "9fa9bfd0-c8c2-11e4-b7bf-4dff20362a6d"
                }
              },
              {
                "node": {
                  "id": "9fb335b2-c8c2-11e4-b7bf-4dff20362a6d"
                }
              },
              {
                "node": {
                  "id": "9fb9ec74-c8c2-11e4-b7bf-4dff20362a6d"
                }
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL API is returning a list of links with unique IDs, which can be used to infer the structure of the underlying database or schema. This could potentially be used by an attacker to map out the database layout, leading to further attacks or information disclosure. To mitigate this, the API should limit the number of links returned or remove sensitive information from the response.",
            "evidence": "The GraphQL response contains a field_suggestions vulnerability. The response includes a large number of link IDs, potentially exposing the schema structure or database layout to an unauthorized user.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "MEDIUM",
              "confidence": 0.8,
              "evidence": "The GraphQL response contains a field_suggestions vulnerability. The response includes a large number of link IDs, potentially exposing the schema structure or database layout to an unauthorized user.",
              "explanation": "The GraphQL API is returning a list of links with unique IDs, which can be used to infer the structure of the underlying database or schema. This could potentially be used by an attacker to map out the database layout, leading to further attacks or information disclosure. To mitigate this, the API should limit the number of links returned or remove sensitive information from the response."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}