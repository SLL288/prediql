{
  "report_timestamp": "2025-10-02T23:05:21.540810",
  "api_url": "https://portal.ehri-project.eu/api/graphql",
  "summary": {
    "total_comparisons": 30,
    "agreement_rate": 0.0,
    "simple_detections": 0,
    "llm_detections": 7,
    "consensus_breakdown": {
      "no_vulnerabilities": 23,
      "llm_only": 7
    },
    "detection_ratio": Infinity,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 4,
      "potential_consensus_breakdown": {
        "no_potential": 26,
        "llm_potential_only": 4
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-02T22:51:10.292848",
      "node_name": "DocumentaryUnit_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:51:24.168666",
      "node_name": "DocumentaryUnit_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:51:33.976652",
      "node_name": "DocumentaryUnit_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:51:44.884706",
      "node_name": "DocumentaryUnit_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:51:56.832260",
      "node_name": "DocumentaryUnit_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:52:13.580667",
      "node_name": "DocumentaryUnit_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:52:24.786411",
      "node_name": "DocumentaryUnit_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:52:41.740493",
      "node_name": "DocumentaryUnit_response_9",
      "response_status": null,
      "response_body": {
        "error": "HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)"
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns an internal HTTP client exception message (from the requests library) including the target host, port and timeout. This leaks implementation details about the backend (HTTP client behavior, host being contacted, and timeout configuration). There is no evidence in the response of SQL injection, XSS, SSRF, path/OS command injection, or access control bypass. The exposed information is primarily useful for fingerprinting, troubleshooting, or aiding an attacker in reconnaissance; it does not by itself demonstrate remote code execution or direct data exposure. Recommend sanitizing error messages returned to clients (log full details server-side, return generic errors to clients) to reduce information leakage.",
            "evidence": "Response Body: { \"error\": \"HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)\" }",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.8,
              "evidence": "Response Body: { \"error\": \"HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)\" }",
              "explanation": "The GraphQL response returns an internal HTTP client exception message (from the requests library) including the target host, port and timeout. This leaks implementation details about the backend (HTTP client behavior, host being contacted, and timeout configuration). There is no evidence in the response of SQL injection, XSS, SSRF, path/OS command injection, or access control bypass. The exposed information is primarily useful for fingerprinting, troubleshooting, or aiding an attacker in reconnaissance; it does not by itself demonstrate remote code execution or direct data exposure. Recommend sanitizing error messages returned to clients (log full details server-side, return generic errors to clients) to reduce information leakage."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:52:58.257123",
      "node_name": "DocumentaryUnit_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (MissingFieldArgument@[DocumentaryUnit]) : Missing field argument 'id'",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (UnknownArgument@[DocumentaryUnit]) : Unknown field argument 'name'",
            "locations": [
              {
                "line": 3,
                "column": 19
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/name]) : Field 'name' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/fields]) : Field 'fields' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldsConflict) : 'DocumentaryUnit' : fields have different arguments",
            "locations": [
              {
                "line": 3,
                "column": 3
              },
              {
                "line": 13,
                "column": 3
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL API is leaking schema and type-level information in validation error messages. The response explicitly identifies a type name (DocumentaryUnit), required arguments (id), and field-level details (name, fields) and argument conflicts. Although this is not an explicit __schema/__type introspection query, the detailed validation errors effectively disclose internal schema structure to unauthenticated or probing clients. This information can be used by attackers to craft targeted queries or discover sensitive fields and arguments. Recommendation: suppress detailed schema validation errors in production, return generic error messages, restrict introspection (or require authentication/role checks), and configure the GraphQL server to avoid leaking type/argument names in responses.",
            "evidence": "Error messages reveal schema details: \"Missing field argument 'id'\" (DocumentaryUnit), \"Unknown field argument 'name'\", \"Field 'name' in type 'DocumentaryUnit' is undefined\", and \"FieldsConflict : 'DocumentaryUnit' : fields have different arguments\".",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "Error messages reveal schema details: \"Missing field argument 'id'\" (DocumentaryUnit), \"Unknown field argument 'name'\", \"Field 'name' in type 'DocumentaryUnit' is undefined\", and \"FieldsConflict : 'DocumentaryUnit' : fields have different arguments\".",
              "explanation": "The GraphQL API is leaking schema and type-level information in validation error messages. The response explicitly identifies a type name (DocumentaryUnit), required arguments (id), and field-level details (name, fields) and argument conflicts. Although this is not an explicit __schema/__type introspection query, the detailed validation errors effectively disclose internal schema structure to unauthenticated or probing clients. This information can be used by attackers to craft targeted queries or discover sensitive fields and arguments. Recommendation: suppress detailed schema validation errors in production, return generic error messages, restrict introspection (or require authentication/role checks), and configure the GraphQL server to avoid leaking type/argument names in responses."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:53:11.448736",
      "node_name": "DocumentaryUnit_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/typ]) : Field 'typ' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/identifer]) : Field 'identifer' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 6,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:57:20.946401",
      "node_name": "DocumentaryUnit_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:58:25.296256",
      "node_name": "DocumentaryUnit_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:58:43.618351",
      "node_name": "DocumentaryUnit_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:59:12.925918",
      "node_name": "DocumentaryUnit_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T22:59:25.860326",
      "node_name": "DocumentaryUnit_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:00:12.103248",
      "node_name": "DocumentaryUnit_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:00:28.677386",
      "node_name": "DocumentaryUnit_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:00:37.705343",
      "node_name": "DocumentaryUnit_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:00:59.182848",
      "node_name": "DocumentaryUnit_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (MissingFieldArgument@[DocumentaryUnit]) : Missing field argument 'id'",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (UnknownArgument@[DocumentaryUnit]) : Unknown field argument 'name'",
            "locations": [
              {
                "line": 3,
                "column": 19
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/name]) : Field 'name' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/fields]) : Field 'fields' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldsConflict) : 'DocumentaryUnit' : fields have different arguments",
            "locations": [
              {
                "line": 3,
                "column": 3
              },
              {
                "line": 13,
                "column": 3
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: GraphQL introspection via error messages",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL error responses disclose internal schema information (type name 'DocumentaryUnit', field names 'name' and 'fields', and required argument 'id' and argument validation behavior). This is effectively schema introspection via verbose error messages and can be used by an attacker to enumerate types, fields, and required arguments to craft targeted queries or further attacks. Although not an active injection or execution vulnerability by itself, this information disclosure increases risk surface. Recommended mitigations: suppress or sanitize detailed GraphQL validation errors in production, avoid returning schema-specific messages to unauthenticated callers, consider disabling introspection or restricting it to authorized users, and implement proper error handling and rate-limiting.",
            "evidence": "Error messages revealing schema details: \"Missing field argument 'id'\", \"Unknown field argument 'name'\", \"Field 'name' in type 'DocumentaryUnit' is undefined\", \"Field 'fields' in type 'DocumentaryUnit' is undefined\", \"FieldsConflict : 'DocumentaryUnit' : fields have different arguments\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "GraphQL introspection via error messages",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "Error messages revealing schema details: \"Missing field argument 'id'\", \"Unknown field argument 'name'\", \"Field 'name' in type 'DocumentaryUnit' is undefined\", \"Field 'fields' in type 'DocumentaryUnit' is undefined\", \"FieldsConflict : 'DocumentaryUnit' : fields have different arguments\"",
              "explanation": "The GraphQL error responses disclose internal schema information (type name 'DocumentaryUnit', field names 'name' and 'fields', and required argument 'id' and argument validation behavior). This is effectively schema introspection via verbose error messages and can be used by an attacker to enumerate types, fields, and required arguments to craft targeted queries or further attacks. Although not an active injection or execution vulnerability by itself, this information disclosure increases risk surface. Recommended mitigations: suppress or sanitize detailed GraphQL validation errors in production, avoid returning schema-specific messages to unauthenticated callers, consider disabling introspection or restricting it to authorized users, and implement proper error handling and rate-limiting."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:01:18.843432",
      "node_name": "DocumentaryUnit_response_11",
      "response_status": null,
      "response_body": {
        "error": "HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)"
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns a library/stack error message that reveals internal request behavior and the target hostname. This is not evidence of SQLi, XSS, SSRF, path or OS command injection, nor an access-control bypass, but it does leak implementation details (external host, transport port and client-side timeout) which can aid reconnaissance by an attacker. Recommend returning generic error messages to clients, logging detailed errors server-side only, and avoiding exposure of internal hostnames or stack traces in API responses.",
            "evidence": "HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.8,
              "evidence": "HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)",
              "explanation": "The GraphQL response returns a library/stack error message that reveals internal request behavior and the target hostname. This is not evidence of SQLi, XSS, SSRF, path or OS command injection, nor an access-control bypass, but it does leak implementation details (external host, transport port and client-side timeout) which can aid reconnaissance by an attacker. Recommend returning generic error messages to clients, logging detailed errors server-side only, and avoiding exposure of internal hostnames or stack traces in API responses."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:02:56.092082",
      "node_name": "DocumentaryUnit_response_1",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:03:08.995414",
      "node_name": "DocumentaryUnit_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:03:27.039754",
      "node_name": "DocumentaryUnit_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:03:45.242331",
      "node_name": "DocumentaryUnit_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:03:59.928861",
      "node_name": "DocumentaryUnit_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:04:16.818109",
      "node_name": "DocumentaryUnit_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:04:25.292709",
      "node_name": "DocumentaryUnit_response_7",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:04:50.461590",
      "node_name": "DocumentaryUnit_response_8",
      "response_status": null,
      "response_body": {
        "error": "HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)"
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns an internal exception message produced by an HTTP client (likely Python requests) showing the target host, port and timeout. This leaks implementation and runtime details (host being contacted and that the backend performs outbound HTTPS requests) which can be useful for fingerprinting, reconnaissance, or crafting further attacks. There is no evidence of SQLi, XSS, SSRF, path/OS command injection, or access control bypass in the response. Recommended mitigation: suppress internal error messages in API responses, return a generic error to clients, log full details only server-side, and ensure error paths do not expose internal hostnames, stack traces or libraries.",
            "evidence": "HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.8,
              "evidence": "HTTPSConnectionPool(host='portal.ehri-project.eu', port=443): Read timed out. (read timeout=10)",
              "explanation": "The GraphQL response returns an internal exception message produced by an HTTP client (likely Python requests) showing the target host, port and timeout. This leaks implementation and runtime details (host being contacted and that the backend performs outbound HTTPS requests) which can be useful for fingerprinting, reconnaissance, or crafting further attacks. There is no evidence of SQLi, XSS, SSRF, path/OS command injection, or access control bypass in the response. Recommended mitigation: suppress internal error messages in API responses, return a generic error to clients, log full details only server-side, and ensure error paths do not expose internal hostnames, stack traces or libraries."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:05:08.649014",
      "node_name": "DocumentaryUnit_response_9",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Validation error (MissingFieldArgument@[DocumentaryUnit]) : Missing field argument 'id'",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (UnknownArgument@[DocumentaryUnit]) : Unknown field argument 'name'",
            "locations": [
              {
                "line": 3,
                "column": 19
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/name]) : Field 'name' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/kind]) : Field 'kind' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          },
          {
            "message": "Validation error (FieldUndefined@[DocumentaryUnit/fields]) : Field 'fields' in type 'DocumentaryUnit' is undefined",
            "locations": [
              {
                "line": 6,
                "column": 5
              }
            ],
            "extensions": {
              "classification": "ValidationError"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL endpoint returns detailed validation errors that disclose schema structure and field/argument names. The responses explicitly mention a type name (DocumentaryUnit), required arguments (id), and field names (name, kind, fields). This is effectively schema introspection via error messages: an attacker can iteratively craft queries to map types, fields and arguments even if standard introspection queries are disabled. Exposure of schema metadata lowers the effort for targeted attacks (e.g., finding sensitive fields to query, constructing mutations) and should be considered an information disclosure risk. Mitigations: suppress or genericize GraphQL error messages in production, avoid returning schema/type details to unauthenticated users, enforce authorization on introspection, and validate/normalize errors server-side so they do not leak schema internals.",
            "evidence": "Error messages reveal schema details: 'Missing field argument 'id'', 'Unknown field argument 'name'', 'Field 'name' in type 'DocumentaryUnit' is undefined', 'Field 'kind' in type 'DocumentaryUnit' is undefined', 'Field 'fields' in type 'DocumentaryUnit' is undefined'.",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection",
              "severity": "MEDIUM",
              "confidence": 0.85,
              "evidence": "Error messages reveal schema details: 'Missing field argument 'id'', 'Unknown field argument 'name'', 'Field 'name' in type 'DocumentaryUnit' is undefined', 'Field 'kind' in type 'DocumentaryUnit' is undefined', 'Field 'fields' in type 'DocumentaryUnit' is undefined'.",
              "explanation": "The GraphQL endpoint returns detailed validation errors that disclose schema structure and field/argument names. The responses explicitly mention a type name (DocumentaryUnit), required arguments (id), and field names (name, kind, fields). This is effectively schema introspection via error messages: an attacker can iteratively craft queries to map types, fields and arguments even if standard introspection queries are disabled. Exposure of schema metadata lowers the effort for targeted attacks (e.g., finding sensitive fields to query, constructing mutations) and should be considered an information disclosure risk. Mitigations: suppress or genericize GraphQL error messages in production, avoid returning schema/type details to unauthenticated users, enforce authorization on introspection, and validate/normalize errors server-side so they do not leak schema internals."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-02T23:05:21.532908",
      "node_name": "DocumentaryUnit_response_10",
      "response_status": 200,
      "response_body": {
        "data": {
          "DocumentaryUnit": null,
          "__type": {
            "fields": [
              {
                "name": "id"
              },
              {
                "name": "type"
              },
              {
                "name": "identifier"
              },
              {
                "name": "otherIdentifiers"
              },
              {
                "name": "descriptions"
              },
              {
                "name": "description"
              },
              {
                "name": "repository"
              },
              {
                "name": "itemCount"
              },
              {
                "name": "children"
              },
              {
                "name": "parent"
              },
              {
                "name": "ancestors"
              },
              {
                "name": "links"
              },
              {
                "name": "annotations"
              },
              {
                "name": "connected"
              },
              {
                "name": "systemEvents"
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL response includes an introspection result: the __type field returned a full list of type fields. This indicates schema introspection is available and the API is revealing field names (field suggestions). Exposing schema details can help an attacker craft more targeted queries and discover functionality or sensitive fields. Depending on the environment, this is an information disclosure risk and should be limited (disable introspection in production or restrict it via access control).",
            "evidence": "\"__type\": { \"fields\": [ { \"name\": \"id\" }, { \"name\": \"type\" }, { \"name\": \"identifier\" }, { \"name\": \"otherIdentifiers\" }, { \"name\": \"descriptions\" }, { \"name\": \"description\" }, { \"name\": \"repository\" }, { \"name\": \"itemCount\" }, { \"name\": \"children\" }, { \"name\": \"parent\" }, { \"name\": \"ancestors\" }, { \"name\": \"links\" }, { \"name\": \"annotations\" }, { \"name\": \"connected\" }, { \"name\": \"systemEvents\" } ] }",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "\"__type\": { \"fields\": [ { \"name\": \"id\" }, { \"name\": \"type\" }, { \"name\": \"identifier\" }, { \"name\": \"otherIdentifiers\" }, { \"name\": \"descriptions\" }, { \"name\": \"description\" }, { \"name\": \"repository\" }, { \"name\": \"itemCount\" }, { \"name\": \"children\" }, { \"name\": \"parent\" }, { \"name\": \"ancestors\" }, { \"name\": \"links\" }, { \"name\": \"annotations\" }, { \"name\": \"connected\" }, { \"name\": \"systemEvents\" } ] }",
              "explanation": "The GraphQL response includes an introspection result: the __type field returned a full list of type fields. This indicates schema introspection is available and the API is revealing field names (field suggestions). Exposing schema details can help an attacker craft more targeted queries and discover functionality or sensitive fields. Depending on the environment, this is an information disclosure risk and should be limited (disable introspection in production or restrict it via access control)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}