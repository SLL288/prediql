{
  "report_timestamp": "2025-10-05T16:19:43.912812",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.4,
    "simple_detections": 6,
    "llm_detections": 7,
    "consensus_breakdown": {
      "simple_only": 1,
      "both_detected": 5,
      "llm_only": 2,
      "no_vulnerabilities": 2
    },
    "detection_ratio": 1.1666666666666667,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 5,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 4,
        "no_potential": 5,
        "both_potential": 1
      },
      "potential_detection_ratio": 0.2
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T16:19:26.273853",
      "node_name": "createComment_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "SQL Injector",
            "body": "'; DROP TABLE Comments; --"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:28.221758",
      "node_name": "createComment_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "XSS Attacker",
            "body": "<script>alert('XSS Vulnerability!');</script>This comment contains malicious script."
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response clearly shows the injected script tag `<script>alert('XSS Vulnerability!');</script>` being reflected directly within the `body` field of the `createComment` object. This indicates that the server is not properly sanitizing or encoding user-supplied input before returning it in the API response. If this content is rendered directly in a web browser without proper escaping, it would execute the injected JavaScript, leading to a Cross-Site Scripting (XSS) vulnerability. The 'alert' function is a classic proof-of-concept for XSS.",
            "evidence": "'<script>alert('XSS Vulnerability!');</script>This comment contains malicious script.' in the 'body' field of the 'createComment' object.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "'<script>alert('XSS Vulnerability!');</script>This comment contains malicious script.' in the 'body' field of the 'createComment' object.",
              "explanation": "The GraphQL response clearly shows the injected script tag `<script>alert('XSS Vulnerability!');</script>` being reflected directly within the `body` field of the `createComment` object. This indicates that the server is not properly sanitizing or encoding user-supplied input before returning it in the API response. If this content is rendered directly in a web browser without proper escaping, it would execute the injected JavaScript, leading to a Cross-Site Scripting (XSS) vulnerability. The 'alert' function is a classic proof-of-concept for XSS."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:30.133461",
      "node_name": "createComment_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "SSRF Tester",
            "body": "Check out this image: http://169.254.169.254/latest/meta-data/"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The 'body' field in the 'createComment' mutation response contains a URL pointing to 'http://169.254.169.254/latest/meta-data/'. The IP address 169.254.169.254 is a well-known IPv4 link-local address commonly used for accessing cloud instance metadata services (e.g., AWS EC2 metadata). If this URL is processed by the server-side application without proper validation, it could lead to Server-Side Request Forgery (SSRF), allowing an attacker to compel the server to make requests to internal resources, potentially exfiltrating sensitive information or interacting with internal services. The presence of this specific URL pattern is a strong indicator of an SSRF attempt that might have been successfully reflected in the output.",
            "evidence": "http://169.254.169.254/latest/meta-data/",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "http://169.254.169.254/latest/meta-data/",
              "explanation": "The 'body' field in the 'createComment' mutation response contains a URL pointing to 'http://169.254.169.254/latest/meta-data/'. The IP address 169.254.169.254 is a well-known IPv4 link-local address commonly used for accessing cloud instance metadata services (e.g., AWS EC2 metadata). If this URL is processed by the server-side application without proper validation, it could lead to Server-Side Request Forgery (SSRF), allowing an attacker to compel the server to make requests to internal resources, potentially exfiltrating sensitive information or interacting with internal services. The presence of this specific URL pattern is a strong indicator of an SSRF attempt that might have been successfully reflected in the output."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:32.928697",
      "node_name": "createComment_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "Command Injector",
            "body": "'; rm -rf /; echo 'executed' #"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: os_command_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The 'body' field in the GraphQL response contains the string \"'; rm -rf /; echo 'executed' #\". This payload is a classic example of OS command injection. The single quote attempts to break out of a string context, followed by the 'rm -rf /' command which is a highly destructive command to recursively delete everything from the root directory. The 'echo 'executed' #' attempts to comment out the remainder of the original command. Although the response only shows the payload reflected, the fact that such a malicious command can be submitted and reflected in a 'createComment' operation is a strong indicator that the backend might be executing this input without proper sanitization or validation if it's being passed to a shell function or similar system call. The severity is critical due to the potential for complete system compromise and data loss.",
            "evidence": "'rm -rf /; echo 'executed' #",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "os_command_injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "'rm -rf /; echo 'executed' #",
              "explanation": "The 'body' field in the GraphQL response contains the string \"'; rm -rf /; echo 'executed' #\". This payload is a classic example of OS command injection. The single quote attempts to break out of a string context, followed by the 'rm -rf /' command which is a highly destructive command to recursively delete everything from the root directory. The 'echo 'executed' #' attempts to comment out the remainder of the original command. Although the response only shows the payload reflected, the fact that such a malicious command can be submitted and reflected in a 'createComment' operation is a strong indicator that the backend might be executing this input without proper sanitization or validation if it's being passed to a shell function or similar system call. The severity is critical due to the potential for complete system compromise and data loss."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:34.662004",
      "node_name": "createComment_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "Path Traversal",
            "body": "Accessing sensitive file: ../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Path Injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The 'body' field in the 'createComment' response explicitly contains 'Accessing sensitive file: ../../../etc/passwd'. This strongly indicates a successful path traversal attempt or at least an attempt that is being reflected in the response. The presence of 'file: ../../../etc/passwd' suggests that the GraphQL API or an underlying system it interacts with processed a path containing directory traversal sequences ('../') and is reflecting the outcome, which in this case points to potential access of a critical system file like '/etc/passwd'. This is a clear indicator of a Path Injection vulnerability.",
            "evidence": "The 'body' field contains the string 'Accessing sensitive file: ../../../etc/passwd'.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Path Injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "The 'body' field contains the string 'Accessing sensitive file: ../../../etc/passwd'.",
              "explanation": "The 'body' field in the 'createComment' response explicitly contains 'Accessing sensitive file: ../../../etc/passwd'. This strongly indicates a successful path traversal attempt or at least an attempt that is being reflected in the response. The presence of 'file: ../../../etc/passwd' suggests that the GraphQL API or an underlying system it interacts with processed a path containing directory traversal sequences ('../') and is reflecting the outcome, which in this case points to potential access of a critical system file like '/etc/passwd'. This is a clear indicator of a Path Injection vulnerability."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:36.357255",
      "node_name": "createComment_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "HTML Injector",
            "body": "<h1>Important Announcement!</h1><p>Please click <a href='http://malicious.com'>here</a>.</p>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The 'body' field in the 'createComment' response contains un-sanitized HTML tags (<h1>, <p>, <a>). This indicates that the input provided for the comment body is being directly reflected in the response without proper validation or encoding. If this content is subsequently rendered in a web browser without proper sanitization on the client-side, it could lead to HTML Injection. An attacker could inject malicious HTML, including links to phishing sites or other harmful content, affecting users who view this comment.",
            "evidence": "'body': '<h1>Important Announcement!</h1><p>Please click <a href=\\'http://malicious.com\\'>here</a>.</p>'",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "HTML Injection",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "'body': '<h1>Important Announcement!</h1><p>Please click <a href=\\'http://malicious.com\\'>here</a>.</p>'",
              "explanation": "The 'body' field in the 'createComment' response contains un-sanitized HTML tags (<h1>, <p>, <a>). This indicates that the input provided for the comment body is being directly reflected in the response without proper validation or encoding. If this content is subsequently rendered in a web browser without proper sanitization on the client-side, it could lead to HTML Injection. An attacker could inject malicious HTML, including links to phishing sites or other harmful content, affecting users who view this comment."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:38.084601",
      "node_name": "createComment_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:40.158412",
      "node_name": "createComment_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:41.848525",
      "node_name": "createComment_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createComment\" on type \"Query\". Did you mean \"comment\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL error message 'Cannot query field \"createComment\" on type \"Query\". Did you mean \"comment\"?' indicates that the server is suggesting a valid field ('comment') that exists in the schema. This behavior is a characteristic of GraphQL's introspection capabilities, which, while often enabled for development convenience, can lead to information disclosure. An attacker can use these suggestions to progressively build knowledge of the API's schema without explicit introspection queries. While not a direct exploit, it simplifies schema mapping for potential attackers.",
            "evidence": "'Did you mean \"comment\"?' in the error message suggests schema awareness.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.8,
              "evidence": "'Did you mean \"comment\"?' in the error message suggests schema awareness.",
              "explanation": "The GraphQL error message 'Cannot query field \"createComment\" on type \"Query\". Did you mean \"comment\"?' indicates that the server is suggesting a valid field ('comment') that exists in the schema. This behavior is a characteristic of GraphQL's introspection capabilities, which, while often enabled for development convenience, can lead to information disclosure. An attacker can use these suggestions to progressively build knowledge of the API's schema without explicit introspection queries. While not a direct exploit, it simplifies schema mapping for potential attackers."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:19:43.906804",
      "node_name": "createComment_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createComment\" on type \"Query\". Did you mean \"comment\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL response explicitly suggests a correct field name 'comment' when an invalid field 'createComment' was provided. This behavior, known as field suggestion, is a form of information disclosure. While not a direct exploit, it can aid attackers in mapping out the API's schema by systematically trying invalid field names and observing the suggestions, thus making it easier to craft malicious queries or understand the underlying data structure without proper authorization.",
            "evidence": "\"message\": \"Cannot query field \"createComment\" on type \"Query\". Did you mean \"comment\"?\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "\"message\": \"Cannot query field \"createComment\" on type \"Query\". Did you mean \"comment\"?\"",
              "explanation": "The GraphQL response explicitly suggests a correct field name 'comment' when an invalid field 'createComment' was provided. This behavior, known as field suggestion, is a form of information disclosure. While not a direct exploit, it can aid attackers in mapping out the API's schema by systematically trying invalid field names and observing the suggestions, thus making it easier to craft malicious queries or understand the underlying data structure without proper authorization."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}