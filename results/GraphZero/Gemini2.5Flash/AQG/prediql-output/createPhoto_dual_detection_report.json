{
  "report_timestamp": "2025-10-05T16:30:47.895211",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.3,
    "simple_detections": 4,
    "llm_detections": 4,
    "consensus_breakdown": {
      "both_detected": 4,
      "no_vulnerabilities": 6
    },
    "detection_ratio": 1.0,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 3,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 2,
        "no_potential": 7,
        "both_potential": 1
      },
      "potential_detection_ratio": 0.3333333333333333
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T16:30:30.688922",
      "node_name": "createPhoto_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPhoto": {
            "id": "5001",
            "title": "SQL Injection Test'; DROP TABLE Photos;--"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: sql_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response reflects the exact SQL injection payload ' DROP TABLE Photos;-- within the 'title' field of the created photo. This indicates that the input was likely directly inserted into a SQL query without proper sanitization or parameterization. While the response doesn't show an immediate SQL error or confirmation of table dropping, the successful reflection of a syntactically valid SQL injection payload strongly suggests an underlying SQL Injection vulnerability. If this payload were executed, it could lead to severe data loss or manipulation of the database.",
            "evidence": "' DROP TABLE Photos;--",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "sql_injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "' DROP TABLE Photos;--",
              "explanation": "The GraphQL response reflects the exact SQL injection payload ' DROP TABLE Photos;-- within the 'title' field of the created photo. This indicates that the input was likely directly inserted into a SQL query without proper sanitization or parameterization. While the response doesn't show an immediate SQL error or confirmation of table dropping, the successful reflection of a syntactically valid SQL injection payload strongly suggests an underlying SQL Injection vulnerability. If this payload were executed, it could lead to severe data loss or manipulation of the database."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:32.637539",
      "node_name": "createPhoto_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPhoto": {
            "id": "5001",
            "title": "XSS <script>alert('Vulnerable!');</script> Photo"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response reflects user-controlled input, specifically the 'title' field, which contains an executable JavaScript payload: <script>alert('Vulnerable!');</script>. If this title is rendered directly on a web page without proper (or any) output encoding, it would result in a Cross-Site Scripting (XSS) vulnerability. An attacker could inject malicious scripts that execute in the user's browser, leading to session hijacking, data theft, or defacement.",
            "evidence": "The 'title' field in the response contains '<script>alert('Vulnerable!');</script>'",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "The 'title' field in the response contains '<script>alert('Vulnerable!');</script>'",
              "explanation": "The GraphQL response reflects user-controlled input, specifically the 'title' field, which contains an executable JavaScript payload: <script>alert('Vulnerable!');</script>. If this title is rendered directly on a web page without proper (or any) output encoding, it would result in a Cross-Site Scripting (XSS) vulnerability. An attacker could inject malicious scripts that execute in the user's browser, leading to session hijacking, data theft, or defacement."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:35.005604",
      "node_name": "createPhoto_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPhoto": {
            "id": "5001",
            "title": "SSRF Test Photo"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:36.427652",
      "node_name": "createPhoto_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPhoto": {
            "id": "5001",
            "title": "Command Injeciton Test Photo"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:37.929160",
      "node_name": "createPhoto_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPhoto": {
            "id": "5001",
            "title": "Path Injection Test Photo"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:39.688641",
      "node_name": "createPhoto_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPhoto": {
            "id": "5001",
            "title": "HTML <h1>Injection Test</h1> Photo"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The 'title' field in the 'createPhoto' response body contains unescaped HTML tags (<h1>). This indicates that the input provided for the photo title was rendered directly without proper sanitization. If this title is subsequently displayed in a web browser without encoding, it could lead to HTML Injection, allowing an attacker to manipulate the webpage's structure and content, or potentially inject client-side scripts (XSS) if more complex payloads are allowed.",
            "evidence": "title: \"HTML <h1>Injection Test</h1> Photo\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "HTML Injection",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "title: \"HTML <h1>Injection Test</h1> Photo\"",
              "explanation": "The 'title' field in the 'createPhoto' response body contains unescaped HTML tags (<h1>). This indicates that the input provided for the photo title was rendered directly without proper sanitization. If this title is subsequently displayed in a web browser without encoding, it could lead to HTML Injection, allowing an attacker to manipulate the webpage's structure and content, or potentially inject client-side scripts (XSS) if more complex payloads are allowed."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:41.332965",
      "node_name": "createPhoto_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:43.629028",
      "node_name": "createPhoto_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:45.845510",
      "node_name": "createPhoto_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createPhoto\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T16:30:47.892729",
      "node_name": "createPhoto_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"tiitle\" on type \"Photo\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL response explicitly suggests a correct field name ('title') after an incorrect one ('tiitle') was provided. This behavior, known as field_suggestions, is a form of information disclosure. While not directly exploitable for data manipulation or system access, it can assist attackers in mapping out the API's schema through trial and error, making it easier to discover valid fields and potentially sensitive data points that might otherwise be hidden. This reduces the effort an attacker would need for schema introspection.",
            "evidence": "Cannot query field \"tiitle\" on type \"Photo\". Did you mean \"title\"?",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "Cannot query field \"tiitle\" on type \"Photo\". Did you mean \"title\"?",
              "explanation": "The GraphQL response explicitly suggests a correct field name ('title') after an incorrect one ('tiitle') was provided. This behavior, known as field_suggestions, is a form of information disclosure. While not directly exploitable for data manipulation or system access, it can assist attackers in mapping out the API's schema through trial and error, making it easier to discover valid fields and potentially sensitive data points that might otherwise be hidden. This reduces the effort an attacker would need for schema introspection."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}