{
  "report_timestamp": "2025-10-05T20:16:50.544516",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 3,
    "llm_detections": 3,
    "consensus_breakdown": {
      "no_vulnerabilities": 7,
      "both_detected": 3
    },
    "detection_ratio": 1.0,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 2,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "no_potential": 8,
        "simple_potential_only": 1,
        "both_potential": 1
      },
      "potential_detection_ratio": 0.5
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T20:16:31.651901",
      "node_name": "updatePost_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePost": {
            "id": null,
            "title": "SQL Injection Test"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:33.714403",
      "node_name": "updatePost_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePost": {
            "id": "2",
            "title": "XSS Injection <script>alert('Vulnerable!')</script>",
            "body": "This body has <img src=x onerror=alert('XSS')> an XSS payload."
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response explicitly includes JavaScript code within the 'title' field (<script>alert('Vulnerable!')</script>) and an XSS payload within an HTML image tag in the 'body' field (<img src=x onerror=alert('XSS')>). If this content is rendered directly in a web browser without proper sanitization or encoding, it will execute the embedded script, indicating a clear Cross-Site Scripting (XSS) vulnerability. This is a direct reflection of user-supplied input containing active content.",
            "evidence": "'title': 'XSS Injection <script>alert(\\'Vulnerable!\\')</script>', 'body': 'This body has <img src=x onerror=alert(\\'XSS\\')> an XSS payload.'",
            "confidence": 1.0,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 1.0,
              "evidence": "'title': 'XSS Injection <script>alert(\\'Vulnerable!\\')</script>', 'body': 'This body has <img src=x onerror=alert(\\'XSS\\')> an XSS payload.'",
              "explanation": "The GraphQL response explicitly includes JavaScript code within the 'title' field (<script>alert('Vulnerable!')</script>) and an XSS payload within an HTML image tag in the 'body' field (<img src=x onerror=alert('XSS')>). If this content is rendered directly in a web browser without proper sanitization or encoding, it will execute the embedded script, indicating a clear Cross-Site Scripting (XSS) vulnerability. This is a direct reflection of user-supplied input containing active content."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:35.390498",
      "node_name": "updatePost_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePost": {
            "id": "3",
            "title": "SSRF Test"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:37.114265",
      "node_name": "updatePost_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePost": {
            "id": "4",
            "title": "Command Injection Test"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:38.726672",
      "node_name": "updatePost_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePost": {
            "id": "5",
            "title": "Path Injection Test"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:41.018637",
      "node_name": "updatePost_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePost": {
            "id": "6",
            "title": "HTML Injection Test",
            "body": "<h1>This is injected HTML</h1><p>And a paragraph with <b>bold</b> text.</p>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The 'body' field in the 'updatePost' response directly reflects user-supplied HTML content without proper sanitization. The presence of HTML tags like <h1>, <p>, and <b> within the 'body' field indicates that the application is vulnerable to HTML Injection. If this content is rendered in a web browser without proper encoding or sanitization, an attacker could manipulate the structure and appearance of the web page, embed malicious scripts (leading to XSS), or deface content. This specific response clearly shows HTML markup being successfully injected and returned by the API.",
            "evidence": "<h1>This is injected HTML</h1><p>And a paragraph with <b>bold</b> text.</p>",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "HTML Injection",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "<h1>This is injected HTML</h1><p>And a paragraph with <b>bold</b> text.</p>",
              "explanation": "The 'body' field in the 'updatePost' response directly reflects user-supplied HTML content without proper sanitization. The presence of HTML tags like <h1>, <p>, and <b> within the 'body' field indicates that the application is vulnerable to HTML Injection. If this content is rendered in a web browser without proper encoding or sanitization, an attacker could manipulate the structure and appearance of the web page, embed malicious scripts (leading to XSS), or deface content. This specific response clearly shows HTML markup being successfully injected and returned by the API."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:43.529339",
      "node_name": "updatePost_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:46.019844",
      "node_name": "updatePost_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:48.445682",
      "node_name": "updatePost_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updatePost\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:16:50.543711",
      "node_name": "updatePost_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"boddy\" is not defined by type \"UpdatePostInput\". Did you mean \"body\"?",
            "locations": [
              {
                "line": 3,
                "column": 58
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL API response explicitly suggests a valid field name ('body') when an incorrect field name ('boddy') is provided. This behavior, known as 'field suggestion' or 'type introspection feedback,' is a form of information disclosure. While not a direct exploit, it helps an attacker enumerate valid fields and understand the API's schema, which can aid in crafting further malicious queries or understanding the underlying data model. This reduces the effort required for an attacker to map out the API's structure.",
            "evidence": "Field \\\"boddy\\\" is not defined by type \\\"UpdatePostInput\\\". Did you mean \\\"body\\\"?",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "Field \\\"boddy\\\" is not defined by type \\\"UpdatePostInput\\\". Did you mean \\\"body\\\"?",
              "explanation": "The GraphQL API response explicitly suggests a valid field name ('body') when an incorrect field name ('boddy') is provided. This behavior, known as 'field suggestion' or 'type introspection feedback,' is a form of information disclosure. While not a direct exploit, it helps an attacker enumerate valid fields and understand the API's schema, which can aid in crafting further malicious queries or understanding the underlying data model. This reduces the effort required for an attacker to map out the API's structure."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}