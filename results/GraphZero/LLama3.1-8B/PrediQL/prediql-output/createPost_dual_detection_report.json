{
  "report_timestamp": "2025-10-05T20:15:45.639603",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.3,
    "simple_detections": 5,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 2,
      "both_detected": 3,
      "llm_only": 1,
      "no_vulnerabilities": 4
    },
    "detection_ratio": 0.8,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 5,
      "llm_potential_detections": 0,
      "potential_consensus_breakdown": {
        "simple_potential_only": 5,
        "no_potential": 5
      },
      "potential_detection_ratio": 0.0
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T20:15:28.009232",
      "node_name": "createPost_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPost": {
            "id": "101",
            "title": "SQL Injection Test'; DROP TABLE posts; --",
            "body": "This post attempts to inject SQL."
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:29.956841",
      "node_name": "createPost_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPost": {
            "id": "101",
            "title": "XSS Test <script>alert('XSSed!')</script>",
            "body": "This post contains an XSS payload in the title."
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response clearly shows that the input provided for the 'title' field, which included a '<script>alert('XSSed!')</script>' payload, was reflected directly into the response body without proper sanitization or encoding. This indicates a reflected XSS vulnerability where a malicious script could be injected and executed in a user's browser if this title is rendered on a web page without proper escaping. The presence of the script tag in the response is direct evidence of the injection.",
            "evidence": "\"title\": \"XSS Test <script>alert('XSSed!')</script>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"title\": \"XSS Test <script>alert('XSSed!')</script>\"",
              "explanation": "The GraphQL response clearly shows that the input provided for the 'title' field, which included a '<script>alert('XSSed!')</script>' payload, was reflected directly into the response body without proper sanitization or encoding. This indicates a reflected XSS vulnerability where a malicious script could be injected and executed in a user's browser if this title is rendered on a web page without proper escaping. The presence of the script tag in the response is direct evidence of the injection."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:32.121494",
      "node_name": "createPost_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPost": {
            "id": "101",
            "title": "SSRF Test",
            "body": "This post attempts SSRF: http://localhost:8080/admin"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The 'body' field in the GraphQL response contains a URL pointing to 'http://localhost:8080/admin'. Although this specific response only reflects the input, the fact that a seemingly user-controlled field accepts and reflects an internal network address (localhost) suggests that an underlying server-side component might be attempting to process or request this URL. If the server application is designed to fetch content from URLs provided in user input, this could lead to Server-Side Request Forgery (SSRF), allowing an attacker to interact with internal services or external systems the server has access to. The 'attempts SSRF' text strongly implies this is an intended test or a clear indicator of a potential vulnerability.",
            "evidence": "\"body\": \"This post attempts SSRF: http://localhost:8080/admin\"",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "\"body\": \"This post attempts SSRF: http://localhost:8080/admin\"",
              "explanation": "The 'body' field in the GraphQL response contains a URL pointing to 'http://localhost:8080/admin'. Although this specific response only reflects the input, the fact that a seemingly user-controlled field accepts and reflects an internal network address (localhost) suggests that an underlying server-side component might be attempting to process or request this URL. If the server application is designed to fetch content from URLs provided in user input, this could lead to Server-Side Request Forgery (SSRF), allowing an attacker to interact with internal services or external systems the server has access to. The 'attempts SSRF' text strongly implies this is an intended test or a clear indicator of a potential vulnerability."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:34.182112",
      "node_name": "createPost_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPost": {
            "id": "101",
            "title": "Command Injection Test",
            "body": "This body tries to execute a command; ls -la; #"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: os_command_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The presence of 'ls -la; #' within the 'body' field of the response strongly suggests an attempt at OS command injection. If this value is being processed by a backend system executing shell commands, the attacker is trying to inject and execute the 'ls -la' command. The '#' character might be an attempt to comment out the rest of the original command. The fact that this 'payload' is reflected in the response indicates that the system received and likely processed this input. While direct command execution is not confirmed by this response alone, the pattern points to a high probability of an OS Command Injection vulnerability if the 'body' content is used in a shell context without proper sanitization or escaping.",
            "evidence": "The 'body' field within the 'createPost' mutation response contains the string 'ls -la; #'.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "os_command_injection",
              "severity": "CRITICAL",
              "confidence": 0.8,
              "evidence": "The 'body' field within the 'createPost' mutation response contains the string 'ls -la; #'.",
              "explanation": "The presence of 'ls -la; #' within the 'body' field of the response strongly suggests an attempt at OS command injection. If this value is being processed by a backend system executing shell commands, the attacker is trying to inject and execute the 'ls -la' command. The '#' character might be an attempt to comment out the rest of the original command. The fact that this 'payload' is reflected in the response indicates that the system received and likely processed this input. While direct command execution is not confirmed by this response alone, the pattern points to a high probability of an OS Command Injection vulnerability if the 'body' content is used in a shell context without proper sanitization or escaping."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:36.385905",
      "node_name": "createPost_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPost": {
            "id": "101",
            "title": "Path Injection Test",
            "body": "Attempting path traversal: ../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:38.207270",
      "node_name": "createPost_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createPost": {
            "id": "101",
            "title": "HTML Injection Test",
            "body": "<h1>Malicious HTML Content</h1><p>Click <a href='javascript:alert(\"Malicious link!\")'>here</a></p>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: HTML Injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The 'body' field in the 'createPost' mutation response directly reflects user-supplied HTML content, including an H1 tag and an anchor tag with a 'javascript:alert' payload. This indicates a clear HTML injection vulnerability. If this content is rendered unsanitized in a web browser, it could lead to Cross-Site Scripting (XSS) attacks, allowing an attacker to execute arbitrary JavaScript code in the user's browser, steal cookies, deface the website, or redirect users to malicious sites.",
            "evidence": "'body' field contains: \"<h1>Malicious HTML Content</h1><p>Click <a href='javascript:alert(\"Malicious link!\")'>here</a></p>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "HTML Injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "'body' field contains: \"<h1>Malicious HTML Content</h1><p>Click <a href='javascript:alert(\"Malicious link!\")'>here</a></p>\"",
              "explanation": "The 'body' field in the 'createPost' mutation response directly reflects user-supplied HTML content, including an H1 tag and an anchor tag with a 'javascript:alert' payload. This indicates a clear HTML injection vulnerability. If this content is rendered unsanitized in a web browser, it could lead to Cross-Site Scripting (XSS) attacks, allowing an attacker to execute arbitrary JavaScript code in the user's browser, steal cookies, deface the website, or redirect users to malicious sites."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:40.589787",
      "node_name": "createPost_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:42.266238",
      "node_name": "createPost_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:44.206537",
      "node_name": "createPost_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createPost\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:15:45.637066",
      "node_name": "createPost_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createPost\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}