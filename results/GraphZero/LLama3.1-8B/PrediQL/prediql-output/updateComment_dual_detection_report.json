{
  "report_timestamp": "2025-10-05T20:08:25.331401",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.4,
    "simple_detections": 5,
    "llm_detections": 6,
    "consensus_breakdown": {
      "simple_only": 1,
      "both_detected": 4,
      "no_vulnerabilities": 3,
      "llm_only": 2
    },
    "detection_ratio": 1.2,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 5,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 4,
        "no_potential": 5,
        "both_potential": 1
      },
      "potential_detection_ratio": 0.2
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T20:08:05.037489",
      "node_name": "updateComment_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "1",
            "name": "SQL' OR 1=1 --",
            "email": "sql@example.com",
            "body": "This comment is vulnerable to SQLi."
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:07.252157",
      "node_name": "updateComment_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "2",
            "name": "<script>alert('XSS')</script>",
            "email": "xss@example.com",
            "body": "This comment contains XSS payload."
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The 'name' field in the GraphQL response clearly reflects the input '<script>alert('XSS')</script>'. This indicates that the server is not properly sanitizing or encoding user-supplied input before returning it in the API response. If this 'name' field is subsequently rendered in a web browser without proper client-side sanitization, it will execute the embedded JavaScript, leading to a Cross-Site Scripting (XSS) vulnerability. This could allow an attacker to steal cookies, manipulate the DOM, or redirect users.",
            "evidence": "\"name\": \"<script>alert('XSS')</script>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"name\": \"<script>alert('XSS')</script>\"",
              "explanation": "The 'name' field in the GraphQL response clearly reflects the input '<script>alert('XSS')</script>'. This indicates that the server is not properly sanitizing or encoding user-supplied input before returning it in the API response. If this 'name' field is subsequently rendered in a web browser without proper client-side sanitization, it will execute the embedded JavaScript, leading to a Cross-Site Scripting (XSS) vulnerability. This could allow an attacker to steal cookies, manipulate the DOM, or redirect users."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:09.358073",
      "node_name": "updateComment_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "3",
            "name": "SSRF Test",
            "email": "ssrf@example.com",
            "body": "Could this load a remote image? e.g., <img src='http://169.254.169.254/latest/meta-data/'/>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The 'body' field in the GraphQL response contains an HTML 'img' tag with a 'src' attribute pointing to 'http://169.254.169.254/latest/meta-data/'. The IP address 169.254.169.254 is a well-known address for accessing AWS EC2 instance metadata. If this content is processed by a server-side component that renders or parses HTML (e.g., for generating a PDF, thumbnail, or email), it could lead to an SSRF vulnerability, allowing the attacker to make requests to internal resources and potentially exfiltrate sensitive data like cloud instance metadata.",
            "evidence": "body: \"Could this load a remote image? e.g., <img src='http://169.254.169.254/latest/meta-data/'/>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "body: \"Could this load a remote image? e.g., <img src='http://169.254.169.254/latest/meta-data/'/>\"",
              "explanation": "The 'body' field in the GraphQL response contains an HTML 'img' tag with a 'src' attribute pointing to 'http://169.254.169.254/latest/meta-data/'. The IP address 169.254.169.254 is a well-known address for accessing AWS EC2 instance metadata. If this content is processed by a server-side component that renders or parses HTML (e.g., for generating a PDF, thumbnail, or email), it could lead to an SSRF vulnerability, allowing the attacker to make requests to internal resources and potentially exfiltrate sensitive data like cloud instance metadata."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:11.632832",
      "node_name": "updateComment_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "4",
            "name": "Command Injection",
            "email": "cmd@example.com",
            "body": "This comment might execute: `rm -rf /`"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:14.114553",
      "node_name": "updateComment_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "5",
            "name": "Path Injection",
            "email": "path@example.com",
            "body": "Could this lead to directory traversal? ../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Path Injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The 'body' field in the 'updateComment' response explicitly returns the string '../../../../etc/passwd'. While this alone doesn't confirm a successful directory traversal on the server, its presence in a user-provided input field (like a 'body' of a comment) strongly suggests that the application is either accepting unsanitized path traversal sequences or is reflecting such inputs directly. If this 'body' content is subsequently used in a file system operation on the server (e.g., storing the comment in a file, logging, or referencing a template based on comment content), it could lead to directory traversal, allowing an attacker to access or manipulate files outside the intended directory. This represents a significant risk for path injection.",
            "evidence": "The 'body' field contains the string '../../../../etc/passwd', which is a common payload for directory traversal attacks.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Path Injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "The 'body' field contains the string '../../../../etc/passwd', which is a common payload for directory traversal attacks.",
              "explanation": "The 'body' field in the 'updateComment' response explicitly returns the string '../../../../etc/passwd'. While this alone doesn't confirm a successful directory traversal on the server, its presence in a user-provided input field (like a 'body' of a comment) strongly suggests that the application is either accepting unsanitized path traversal sequences or is reflecting such inputs directly. If this 'body' content is subsequently used in a file system operation on the server (e.g., storing the comment in a file, logging, or referencing a template based on comment content), it could lead to directory traversal, allowing an attacker to access or manipulate files outside the intended directory. This represents a significant risk for path injection."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:16.815385",
      "node_name": "updateComment_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "6",
            "name": "HTML Injection",
            "email": "html@example.com",
            "body": "This comment contains <h1>injected HTML</h1>."
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL response explicitly includes unescaped HTML tags (<h1>) within the 'body' field of the updated comment. This indicates that the server processed and stored user-supplied input containing HTML without proper sanitization or encoding. If this content is rendered directly in a web browser without further escaping, it will lead to HTML Injection, allowing an attacker to manipulate the page's structure and content, or potentially lead to Cross-Site Scripting (XSS) if script tags were also allowed.",
            "evidence": "The 'body' field in the response contains unescaped HTML content: '<h1>injected HTML</h1>'.",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "HTML Injection",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "The 'body' field in the response contains unescaped HTML content: '<h1>injected HTML</h1>'.",
              "explanation": "The GraphQL response explicitly includes unescaped HTML tags (<h1>) within the 'body' field of the updated comment. This indicates that the server processed and stored user-supplied input containing HTML without proper sanitization or encoding. If this content is rendered directly in a web browser without further escaping, it will lead to HTML Injection, allowing an attacker to manipulate the page's structure and content, or potentially lead to Cross-Site Scripting (XSS) if script tags were also allowed."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:18.612126",
      "node_name": "updateComment_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:20.812717",
      "node_name": "updateComment_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:23.237318",
      "node_name": "updateComment_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updateComment\" on type \"Query\". Did you mean \"comment\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL error message 'Cannot query field \"updateComment\" on type \"Query\". Did you mean \"comment\"?' indicates an information disclosure vulnerability. This type of error message, specifically the 'Did you mean \"<suggestion>\"?', is generated when the GraphQL server attempts to be helpful by suggesting a valid field based on typos or non-existent fields in a query. This behavior reveals parts of the GraphQL schema, in this case, the existence of a 'comment' field on the Query type. While not directly an introspection query, the server is inadvertently providing schema information that could be used by an attacker to build out their understanding of the API's structure without explicitly requesting schema details. This is considered a form of information disclosure, albeit a minor one, as it's leaking valid field names.",
            "evidence": "message: \"Cannot query field \"updateComment\" on type \"Query\". Did you mean \"comment\"?\"",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.8,
              "evidence": "message: \"Cannot query field \"updateComment\" on type \"Query\". Did you mean \"comment\"?\"",
              "explanation": "The GraphQL error message 'Cannot query field \"updateComment\" on type \"Query\". Did you mean \"comment\"?' indicates an information disclosure vulnerability. This type of error message, specifically the 'Did you mean \"<suggestion>\"?', is generated when the GraphQL server attempts to be helpful by suggesting a valid field based on typos or non-existent fields in a query. This behavior reveals parts of the GraphQL schema, in this case, the existence of a 'comment' field on the Query type. While not directly an introspection query, the server is inadvertently providing schema information that could be used by an attacker to build out their understanding of the API's structure without explicitly requesting schema details. This is considered a form of information disclosure, albeit a minor one, as it's leaking valid field names."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T20:08:25.327929",
      "node_name": "updateComment_response_11",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "8",
            "name": "Suggestion Test",
            "email": "suggest@example.com",
            "body": "This payload might trigger field suggestions for 'id', 'name', 'emial' (typo) or 'bodyy' (typo)."
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The 'body' field in the response explicitly mentions potential field suggestions due to typos ('emial' and 'bodyy'). While this specific response doesn't *show* the suggestions themselves, the content strongly indicates the presence of a 'field_suggestions' feature within the API. This feature, if enabled and improperly configured, can be exploited by attackers to discover valid field names through trial and error (e.g., fuzzing with common typos), leading to information disclosure about the schema or internal data structures, which aids in further exploitation. The mention of these typos directly alludes to the existence and potential use of such a feature.",
            "evidence": "'emial' (typo) or 'bodyy' (typo) in the 'body' field",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.8,
              "evidence": "'emial' (typo) or 'bodyy' (typo) in the 'body' field",
              "explanation": "The 'body' field in the response explicitly mentions potential field suggestions due to typos ('emial' and 'bodyy'). While this specific response doesn't *show* the suggestions themselves, the content strongly indicates the presence of a 'field_suggestions' feature within the API. This feature, if enabled and improperly configured, can be exploited by attackers to discover valid field names through trial and error (e.g., fuzzing with common typos), leading to information disclosure about the schema or internal data structures, which aids in further exploitation. The mention of these typos directly alludes to the existence and potential use of such a feature."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}