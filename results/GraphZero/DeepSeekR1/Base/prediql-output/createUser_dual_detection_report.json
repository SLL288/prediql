{
  "report_timestamp": "2025-10-05T15:52:44.605582",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.4,
    "simple_detections": 4,
    "llm_detections": 6,
    "consensus_breakdown": {
      "both_detected": 4,
      "llm_only": 2,
      "no_vulnerabilities": 4
    },
    "detection_ratio": 1.5,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 4,
      "llm_potential_detections": 0,
      "potential_consensus_breakdown": {
        "simple_potential_only": 4,
        "no_potential": 6
      },
      "potential_detection_ratio": 0.0
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T15:50:55.787310",
      "node_name": "createUser_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "name": "Robert'); DROP TABLE Users;--"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: sql_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The response includes a user name containing a classic SQL injection payload ('DROP TABLE Users'). This suggests unsanitized user input may be passed directly to a SQL query. While the 200 status code indicates the request succeeded, the presence of this payload in stored data implies insufficient input validation/sanitization, creating a potential SQLi risk if this value is used in raw SQL operations elsewhere.",
            "evidence": "User name contains 'Robert'); DROP TABLE Users;--'",
            "confidence": 0.7,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "sql_injection",
              "severity": "HIGH",
              "confidence": 0.7,
              "evidence": "User name contains 'Robert'); DROP TABLE Users;--'",
              "explanation": "The response includes a user name containing a classic SQL injection payload ('DROP TABLE Users'). This suggests unsanitized user input may be passed directly to a SQL query. While the 200 status code indicates the request succeeded, the presence of this payload in stored data implies insufficient input validation/sanitization, creating a potential SQLi risk if this value is used in raw SQL operations elsewhere."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:51:03.450818",
      "node_name": "createUser_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "name": "<img src=x onerror=alert(1)>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The response reflects unsanitized user input containing an HTML `<img>` tag with an `onerror` event handler (`alert(1)`), which is a classic XSS payload. If this value is rendered directly in a browser context without proper escaping/sanitization, it would execute arbitrary JavaScript. While GraphQL itself does not inherently cause XSS, the server's reflection of untrusted input in the response (and potential client-side rendering of this data) creates a clear XSS risk.",
            "evidence": "User input reflected as '<img src=x onerror=alert(1)>' in the 'name' field",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.95,
              "evidence": "User input reflected as '<img src=x onerror=alert(1)>' in the 'name' field",
              "explanation": "The response reflects unsanitized user input containing an HTML `<img>` tag with an `onerror` event handler (`alert(1)`), which is a classic XSS payload. If this value is rendered directly in a browser context without proper escaping/sanitization, it would execute arbitrary JavaScript. While GraphQL itself does not inherently cause XSS, the server's reflection of untrusted input in the response (and potential client-side rendering of this data) creates a clear XSS risk."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:51:13.547970",
      "node_name": "createUser_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "website": "http://169.254.169.254/latest/meta-data"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The response includes a reference to '169.254.169.254', a well-known AWS metadata endpoint. This IP address is reserved for cloud instance metadata services and is only accessible internally. If the server processed this URL (e.g., fetched it during user creation), it indicates successful SSRF exploitation, allowing attackers to access sensitive internal services or credentials. The presence of this URL in the response strongly suggests the server accepted and processed a user-controlled internal network path.",
            "evidence": "website: 'http://169.254.169.254/latest/meta-data'",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "website: 'http://169.254.169.254/latest/meta-data'",
              "explanation": "The response includes a reference to '169.254.169.254', a well-known AWS metadata endpoint. This IP address is reserved for cloud instance metadata services and is only accessible internally. If the server processed this URL (e.g., fetched it during user creation), it indicates successful SSRF exploitation, allowing attackers to access sensitive internal services or credentials. The presence of this URL in the response strongly suggests the server accepted and processed a user-controlled internal network path."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:51:28.908868",
      "node_name": "createUser_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "username": "user$(nc -nv 127.0.0.1 4444)"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: os_command_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The username field contains a shell command substitution payload ($(nc -nv 127.0.0.1 4444)). This syntax is commonly used in Unix shells to execute arbitrary commands. The presence of netcat (nc) attempting to connect to localhost port 4444 strongly suggests an attempt to establish a reverse shell or execute remote commands. The server accepted and reflected this payload in the response, indicating insufficient input sanitization and potential command execution capability.",
            "evidence": "username: 'user$(nc -nv 127.0.0.1 4444)'",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "os_command_injection",
              "severity": "CRITICAL",
              "confidence": 0.95,
              "evidence": "username: 'user$(nc -nv 127.0.0.1 4444)'",
              "explanation": "The username field contains a shell command substitution payload ($(nc -nv 127.0.0.1 4444)). This syntax is commonly used in Unix shells to execute arbitrary commands. The presence of netcat (nc) attempting to connect to localhost port 4444 strongly suggests an attempt to establish a reverse shell or execute remote commands. The server accepted and reflected this payload in the response, indicating insufficient input sanitization and potential command execution capability."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:51:45.767429",
      "node_name": "createUser_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "username": "../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: path_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The server accepted and returned a username with directory traversal sequence '.../.../.../.../etc/passwd', indicating unsanitized path handling. This could allow attackers to manipulate file paths in user-related operations (e.g., profile photo storage, configuration files) to access or overwrite sensitive system files if used in path construction.",
            "evidence": "Username value contains directory traversal payload '../../../../etc/passwd' in mutation response",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "path_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "Username value contains directory traversal payload '../../../../etc/passwd' in mutation response",
              "explanation": "The server accepted and returned a username with directory traversal sequence '.../.../.../.../etc/passwd', indicating unsanitized path handling. This could allow attackers to manipulate file paths in user-related operations (e.g., profile photo storage, configuration files) to access or overwrite sensitive system files if used in path construction."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:52:07.408639",
      "node_name": "createUser_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "name": "<iframe src='javascript:alert(1)'>"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The response returns a user-controllable 'name' field containing raw HTML/JS payload (<iframe src='javascript:alert(1)'>), indicating un-sanitized user input stored/reflected in the application. While this could also enable XSS attacks when rendered in a browser, HTML injection is confirmed by the direct inclusion of arbitrary markup. Contextual sanitization would be required in the client application to mitigate this risk.",
            "evidence": "<iframe src='javascript:alert(1)'> in 'name' field",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "<iframe src='javascript:alert(1)'> in 'name' field",
              "explanation": "The response returns a user-controllable 'name' field containing raw HTML/JS payload (<iframe src='javascript:alert(1)'>), indicating un-sanitized user input stored/reflected in the application. While this could also enable XSS attacks when rendered in a browser, HTML injection is confirmed by the direct inclusion of arbitrary markup. Contextual sanitization would be required in the client application to mitigate this risk."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:52:20.832149",
      "node_name": "createUser_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:52:31.026403",
      "node_name": "createUser_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:52:39.032414",
      "node_name": "createUser_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createUser\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T15:52:44.602101",
      "node_name": "createUser_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createUser\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}