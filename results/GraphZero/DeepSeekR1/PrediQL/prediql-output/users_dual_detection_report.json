{
  "report_timestamp": "2025-09-27T11:20:41.514553",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.0,
    "simple_detections": 1,
    "llm_detections": 3,
    "consensus_breakdown": {
      "no_vulnerabilities": 7,
      "llm_only": 2,
      "both_detected": 1
    },
    "detection_ratio": 3.0,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "no_potential": 9,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-09-27T11:10:00.632779",
      "node_name": "users_response_2",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"filter\" is not defined by type \"PageQueryOptions\".",
            "locations": [
              {
                "line": 3,
                "column": 20
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:10:15.803911",
      "node_name": "users_response_3",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Expected value of type \"SearchOptions\", found \"<script>alert('XSS')</script>\".",
            "locations": [
              {
                "line": 3,
                "column": 28
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The server reflects unescaped user input containing a JavaScript payload (<script>alert('XSS')</script>) in the GraphQL error message. This indicates improper sanitization of user-supplied data. While the response is JSON-formatted, the reflection of raw HTML/JS payloads creates a potential XSS vector if this error message is rendered in a web context without proper output encoding.",
            "evidence": "Reflected user input: <script>alert('XSS')</script> in error message",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "Reflected user input: <script>alert('XSS')</script> in error message",
              "explanation": "The server reflects unescaped user input containing a JavaScript payload (<script>alert('XSS')</script>) in the GraphQL error message. This indicates improper sanitization of user-supplied data. While the response is JSON-formatted, the reflection of raw HTML/JS payloads creates a potential XSS vector if this error message is rendered in a web context without proper output encoding."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:10:30.822863",
      "node_name": "users_response_4",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"filter\" is not defined by type \"PageQueryOptions\".",
            "locations": [
              {
                "line": 3,
                "column": 20
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:10:46.347514",
      "node_name": "users_response_5",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"filter\" is not defined by type \"PageQueryOptions\".",
            "locations": [
              {
                "line": 3,
                "column": 20
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:10:55.093161",
      "node_name": "users_response_6",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"filter\" is not defined by type \"PageQueryOptions\".",
            "locations": [
              {
                "line": 3,
                "column": 20
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:11:16.120265",
      "node_name": "users_response_7",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Expected value of type \"SearchOptions\", found \"<h1>HTML Injection</h1><img src=x onerror=alert(123)>\".",
            "locations": [
              {
                "line": 3,
                "column": 28
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL API reflects unsanitized user input containing HTML tags and JavaScript in its error message. Specifically, the payload '<h1>HTML Injection</h1><img src=x onerror=alert(123)>' is directly mirrored in the response. This indicates insufficient input sanitization and creates a potential HTML injection vector. While the immediate response is JSON-formatted, client applications might render these error messages in HTML contexts without proper escaping, enabling XSS attacks. The vulnerability is indirect but demonstrably present in the API's error handling.",
            "evidence": "Reflection of unsanitized HTML payload '<h1>HTML Injection</h1><img src=x onerror=alert(123)>' in GraphQL error message",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "MEDIUM",
              "confidence": 0.8,
              "evidence": "Reflection of unsanitized HTML payload '<h1>HTML Injection</h1><img src=x onerror=alert(123)>' in GraphQL error message",
              "explanation": "The GraphQL API reflects unsanitized user input containing HTML tags and JavaScript in its error message. Specifically, the payload '<h1>HTML Injection</h1><img src=x onerror=alert(123)>' is directly mirrored in the response. This indicates insufficient input sanitization and creates a potential HTML injection vector. While the immediate response is JSON-formatted, client applications might render these error messages in HTML contexts without proper escaping, enabling XSS attacks. The vulnerability is indirect but demonstrably present in the API's error handling."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:14:04.032512",
      "node_name": "users_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:15:18.911590",
      "node_name": "users_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:17:52.342857",
      "node_name": "users_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"queryType\" on type \"UsersPage\".",
            "locations": [
              {
                "line": 4,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"mutationType\" on type \"UsersPage\".",
            "locations": [
              {
                "line": 7,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"types\" on type \"UsersPage\".",
            "locations": [
              {
                "line": 10,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T11:20:41.511469",
      "node_name": "users_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"idd\" on type \"User\". Did you mean \"id\"?",
            "locations": [
              {
                "line": 5,
                "column": 7
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"namm\" on type \"User\". Did you mean \"name\"?",
            "locations": [
              {
                "line": 6,
                "column": 7
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The error responses explicitly suggest valid field names (e.g., 'id' and 'name') when invalid fields (e.g., 'idd', 'namm') are queried. This reveals active field_suggestions behavior in the GraphQL API, which publicly discloses schema structure. While not a direct exploitation risk, it aids attackers in reconnaissance by enumerating valid fields, potentially facilitating more targeted attacks. This falls under Information Disclosure as defined in the criteria, with low severity since it enables attack refinement but doesn't directly compromise data.",
            "evidence": "Error messages: 'Cannot query field \"idd\" on type \"User\". Did you mean \"id\"?' and 'Cannot query field \"namm\" on type \"User\". Did you mean \"name\"?'",
            "confidence": 1.0,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 1.0,
              "evidence": "Error messages: 'Cannot query field \"idd\" on type \"User\". Did you mean \"id\"?' and 'Cannot query field \"namm\" on type \"User\". Did you mean \"name\"?'",
              "explanation": "The error responses explicitly suggest valid field names (e.g., 'id' and 'name') when invalid fields (e.g., 'idd', 'namm') are queried. This reveals active field_suggestions behavior in the GraphQL API, which publicly discloses schema structure. While not a direct exploitation risk, it aids attackers in reconnaissance by enumerating valid fields, potentially facilitating more targeted attacks. This falls under Information Disclosure as defined in the criteria, with low severity since it enables attack refinement but doesn't directly compromise data."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}