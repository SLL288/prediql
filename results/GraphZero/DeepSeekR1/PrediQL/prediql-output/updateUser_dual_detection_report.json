{
  "report_timestamp": "2025-09-27T17:48:32.196793",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.3,
    "simple_detections": 5,
    "llm_detections": 5,
    "consensus_breakdown": {
      "no_vulnerabilities": 4,
      "both_detected": 4,
      "simple_only": 1,
      "llm_only": 1
    },
    "detection_ratio": 1.0,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 4,
      "llm_potential_detections": 0,
      "potential_consensus_breakdown": {
        "no_potential": 6,
        "simple_potential_only": 4
      },
      "potential_detection_ratio": 0.0
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-09-27T17:41:47.316493",
      "node_name": "updateUser_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "1",
            "email": "injected@sql.test"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:42:40.507834",
      "node_name": "updateUser_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "1",
            "website": "javascript:alert('XSS')"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The response includes a JavaScript URI scheme 'javascript:alert('XSS')' in the 'website' field. If this value is rendered without sanitization in a web context (e.g., within an <a href> attribute), it could execute arbitrary JavaScript. This constitutes a stored/persistent XSS vector as the payload appears in an API mutation response ('updateUser'), indicating it is server-stored and likely to be served to other users.",
            "evidence": "'website' field contains \"javascript:alert('XSS')\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "'website' field contains \"javascript:alert('XSS')\"",
              "explanation": "The response includes a JavaScript URI scheme 'javascript:alert('XSS')' in the 'website' field. If this value is rendered without sanitization in a web context (e.g., within an <a href> attribute), it could execute arbitrary JavaScript. This constitutes a stored/persistent XSS vector as the payload appears in an API mutation response ('updateUser'), indicating it is server-stored and likely to be served to other users."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:43:17.548164",
      "node_name": "updateUser_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "1",
            "website": "https://192.168.1.1/internal"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:44:02.448549",
      "node_name": "updateUser_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "1",
            "email": "user@test.com; ping -c 5 attacker.com;"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: os_command_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The response shows a user-supplied input field (email) containing a shell command payload ('ping -c 5 attacker.com') separated by semicolons. This is a classic OS command injection pattern where semicolons allow chaining arbitrary system commands. The 200 status confirms the input was accepted without rejection or sanitization, indicating the backend may execute unsanitized user input in a shell context. The payload suggests an attacker could execute unauthorized commands on the server.",
            "evidence": "email field contains: 'user@test.com; ping -c 5 attacker.com;'",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "os_command_injection",
              "severity": "CRITICAL",
              "confidence": 0.9,
              "evidence": "email field contains: 'user@test.com; ping -c 5 attacker.com;'",
              "explanation": "The response shows a user-supplied input field (email) containing a shell command payload ('ping -c 5 attacker.com') separated by semicolons. This is a classic OS command injection pattern where semicolons allow chaining arbitrary system commands. The 200 status confirms the input was accepted without rejection or sanitization, indicating the backend may execute unsanitized user input in a shell context. The payload suggests an attacker could execute unauthorized commands on the server."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:44:09.346559",
      "node_name": "updateUser_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "1",
            "username": "../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: path_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL mutation 'updateUser' accepted a username with the payload '../../../../etc/passwd' and returned it in the response. This payload is a classic directory traversal signature targeting critical system files. The successful 200 response indicates the application processed this input without adequate path sanitization, creating a high risk of unauthorized file access if this input is used in filesystem operations (e.g., file reads/writes, resource loading). Contextual clues suggest path handling in user operations, though full exploit confirmation would require observing actual file access behavior.",
            "evidence": "username field contains '../../../../etc/passwd' payload in mutation response",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "path_injection",
              "severity": "CRITICAL",
              "confidence": 0.8,
              "evidence": "username field contains '../../../../etc/passwd' payload in mutation response",
              "explanation": "The GraphQL mutation 'updateUser' accepted a username with the payload '../../../../etc/passwd' and returned it in the response. This payload is a classic directory traversal signature targeting critical system files. The successful 200 response indicates the application processed this input without adequate path sanitization, creating a high risk of unauthorized file access if this input is used in filesystem operations (e.g., file reads/writes, resource loading). Contextual clues suggest path handling in user operations, though full exploit confirmation would require observing actual file access behavior."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:44:37.621478",
      "node_name": "updateUser_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "1",
            "name": "<img src=x onerror=alert(1)>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns unsanitized user input containing an HTML payload (<img> tag with JavaScript event handler). This indicates the server isn't properly sanitizing output before returning it in the API response. When rendered in a browser, this payload would execute arbitrary JavaScript (alert(1)), demonstrating a clear HTML injection vulnerability that could lead to XSS attacks.",
            "evidence": "The 'name' field contains: \"<img src=x onerror=alert(1)>\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.95,
              "evidence": "The 'name' field contains: \"<img src=x onerror=alert(1)>\"",
              "explanation": "The GraphQL response returns unsanitized user input containing an HTML payload (<img> tag with JavaScript event handler). This indicates the server isn't properly sanitizing output before returning it in the API response. When rendered in a browser, this payload would execute arbitrary JavaScript (alert(1)), demonstrating a clear HTML injection vulnerability that could lead to XSS attacks."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:45:55.122470",
      "node_name": "updateUser_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:46:34.228989",
      "node_name": "updateUser_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:48:01.265188",
      "node_name": "updateUser_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updateUser\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-27T17:48:32.195281",
      "node_name": "updateUser_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"nmame\" on type \"User\". Did you mean \"name\" or \"email\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "safe",
            "category": "Unknown",
            "description": "The response discloses valid schema fields ('name', 'email') through field name suggestions when an invalid field ('nmame') is queried. This falls under Information Disclosure, potentially helping attackers map the API schema for reconnaissance. While not directly exploitable, it reveals structural details that could aid in crafting further attacks. No data exposure or execution risks are present.",
            "evidence": "The error message contains: 'Did you mean \"name\" or \"email\"?'",
            "confidence": 1.0,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "LOW",
              "confidence": 1.0,
              "evidence": "The error message contains: 'Did you mean \"name\" or \"email\"?'",
              "explanation": "The response discloses valid schema fields ('name', 'email') through field name suggestions when an invalid field ('nmame') is queried. This falls under Information Disclosure, potentially helping attackers map the API schema for reconnaissance. While not directly exploitable, it reveals structural details that could aid in crafting further attacks. No data exposure or execution risks are present."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Unknown"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}