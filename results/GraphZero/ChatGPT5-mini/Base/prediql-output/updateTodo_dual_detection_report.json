{
  "report_timestamp": "2025-10-03T09:06:17.146319",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.1,
    "simple_detections": 4,
    "llm_detections": 3,
    "consensus_breakdown": {
      "no_vulnerabilities": 5,
      "both_detected": 2,
      "simple_only": 2,
      "llm_only": 1
    },
    "detection_ratio": 0.75,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 3,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "no_potential": 6,
        "simple_potential_only": 3,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 0.3333333333333333
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-03T09:04:47.984398",
      "node_name": "updateTodo_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": null,
            "title": "Standard title",
            "completed": false
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:04:58.674807",
      "node_name": "updateTodo_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "2",
            "title": "<script>alert('xss-test')</script>",
            "user": {
              "id": "1",
              "name": "Leanne Graham"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns the 'title' field containing an unescaped <script> tag. This is a clear indicator of reflected/stored HTML/script injection: if a client (web page) renders this value into the DOM without proper encoding or sanitization, it will execute arbitrary JavaScript (demonstrated by the alert payload). The operation is an updateTodo, suggesting user-supplied content may be persisted and later served to other users (stored XSS). Whether it is exploitable depends on how the front-end consumes and renders this field, but returning raw script tags from the API is insecure. Recommended mitigations: validate and sanitize inputs on the server, escape/encode output when inserting into HTML, and apply strong Content Security Policy (CSP).",
            "evidence": "\"title\": \"<script>alert('xss-test')</script>\"",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "\"title\": \"<script>alert('xss-test')</script>\"",
              "explanation": "The GraphQL response returns the 'title' field containing an unescaped <script> tag. This is a clear indicator of reflected/stored HTML/script injection: if a client (web page) renders this value into the DOM without proper encoding or sanitization, it will execute arbitrary JavaScript (demonstrated by the alert payload). The operation is an updateTodo, suggesting user-supplied content may be persisted and later served to other users (stored XSS). Whether it is exploitable depends on how the front-end consumes and renders this field, but returning raw script tags from the API is insecure. Recommended mitigations: validate and sanitize inputs on the server, escape/encode output when inserting into HTML, and apply strong Content Security Policy (CSP)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:05:12.651049",
      "node_name": "updateTodo_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "3",
            "title": "Fetch metadata: http://169.254.169.254/latest/meta-data/iam/security-credentials/"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:05:19.048078",
      "node_name": "updateTodo_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "4",
            "title": "backup; cat /etc/passwd || true",
            "completed": false
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:05:31.128141",
      "node_name": "updateTodo_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "5",
            "title": "../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:05:38.558704",
      "node_name": "updateTodo_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "6",
            "title": "<div class=\"injected\">Malicious <b>HTML</b></div>",
            "user": {
              "id": "1",
              "username": "Bret"
            }
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns raw HTML markup in the 'title' field (a stored value returned by updateTodo). This indicates user-supplied content is being stored and reflected back without sanitization or encoding. If a web or mobile client renders this title into the DOM without proper escaping, it will result in HTML injection and likely stored XSS. Although the response alone does not prove the client renders the field unsafely, the presence of injected tags in persisted API output is a clear security risk and should be treated as a vulnerability. Recommended mitigations: validate/sanitize input on write, HTML-encode output before rendering in browsers, apply a strict Content Security Policy, and use context-aware encoding in the client.",
            "evidence": "\"title\": \"<div class=\\\"injected\\\">Malicious <b>HTML</b></div>\"",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "\"title\": \"<div class=\\\"injected\\\">Malicious <b>HTML</b></div>\"",
              "explanation": "The GraphQL response returns raw HTML markup in the 'title' field (a stored value returned by updateTodo). This indicates user-supplied content is being stored and reflected back without sanitization or encoding. If a web or mobile client renders this title into the DOM without proper escaping, it will result in HTML injection and likely stored XSS. Although the response alone does not prove the client renders the field unsafely, the presence of injected tags in persisted API output is a clear security risk and should be treated as a vulnerability. Recommended mitigations: validate/sanitize input on write, HTML-encode output before rendering in browsers, apply a strict Content Security Policy, and use context-aware encoding in the client."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:05:46.014877",
      "node_name": "updateTodo_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:05:52.396031",
      "node_name": "updateTodo_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:06:04.863323",
      "node_name": "updateTodo_response_10",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateTodo": {
            "id": "7",
            "title": "Probe types and names",
            "__typename": "Todo",
            "user": {
              "id": "1",
              "name": "Leanne Graham",
              "__typename": "User"
            }
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:06:17.143556",
      "node_name": "updateTodo_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"titel\" on type \"Todo\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL response contains an automatic field suggestion ('Did you mean \"title\"?') which discloses schema information (valid field names). This behavior assists an attacker in enumerating the API schema and discovering correct field names, increasing the attack surface (making targeted queries, scraping, or further probing easier). While this does not itself execute commands or expose data directly, it is an information disclosure that can facilitate subsequent attacks. Recommended mitigations: disable or suppress auto-suggestions in error messages in production, return generic validation errors, restrict introspection in production, and use logging/monitoring for suspicious query patterns.",
            "evidence": "GraphQL error: \"Cannot query field \\\"titel\\\" on type \\\"Todo\\\". Did you mean \\\"title\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "GraphQL error: \"Cannot query field \\\"titel\\\" on type \\\"Todo\\\". Did you mean \\\"title\\\"?\"",
              "explanation": "The GraphQL response contains an automatic field suggestion ('Did you mean \"title\"?') which discloses schema information (valid field names). This behavior assists an attacker in enumerating the API schema and discovering correct field names, increasing the attack surface (making targeted queries, scraping, or further probing easier). While this does not itself execute commands or expose data directly, it is an information disclosure that can facilitate subsequent attacks. Recommended mitigations: disable or suppress auto-suggestions in error messages in production, return generic validation errors, restrict introspection in production, and use logging/monitoring for suspicious query patterns."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}