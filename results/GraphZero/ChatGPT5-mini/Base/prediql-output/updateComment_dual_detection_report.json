{
  "report_timestamp": "2025-10-03T06:14:34.570696",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 6,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 3,
      "both_detected": 3,
      "no_vulnerabilities": 3,
      "llm_only": 1
    },
    "detection_ratio": 0.6666666666666666,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 5,
      "llm_potential_detections": 0,
      "potential_consensus_breakdown": {
        "simple_potential_only": 5,
        "no_potential": 5
      },
      "potential_detection_ratio": 0.0
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-03T06:12:38.301565",
      "node_name": "updateComment_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "1",
            "name": "Robert'); DROP TABLE comments;--",
            "email": "robert@example.com",
            "body": "Attempt SQL injection in name"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:12:50.658944",
      "node_name": "updateComment_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "3",
            "name": "Mallory",
            "email": "mallory@example.com",
            "body": "<script>alert('xss')</script><img src=x onerror=\"alert('imgxss')\">Comment body"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns the 'body' field containing raw HTML and JavaScript: a <script> tag and an <img> tag with an onerror handler. This indicates the API is reflecting/storing unescaped HTML/JS. If a web client inserts this value into the DOM without proper encoding (for example via innerHTML), the script and image onerror will execute, resulting in cross-site scripting. The presence of both a <script> element and an event handler attribute is strong evidence of an XSS vulnerability. Exploitability depends on how clients render this field, but the server-side lack of sanitization/encoding makes XSS likely and should be remediated (escape or sanitize output, or restrict allowed HTML).",
            "evidence": "\"body\": \"<script>alert('xss')</script><img src=x onerror=\\\"alert('imgxss')\\\">Comment body\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"body\": \"<script>alert('xss')</script><img src=x onerror=\\\"alert('imgxss')\\\">Comment body\"",
              "explanation": "The GraphQL response returns the 'body' field containing raw HTML and JavaScript: a <script> tag and an <img> tag with an onerror handler. This indicates the API is reflecting/storing unescaped HTML/JS. If a web client inserts this value into the DOM without proper encoding (for example via innerHTML), the script and image onerror will execute, resulting in cross-site scripting. The presence of both a <script> element and an event handler attribute is strong evidence of an XSS vulnerability. Exploitability depends on how clients render this field, but the server-side lack of sanitization/encoding makes XSS likely and should be remediated (escape or sanitize output, or restrict allowed HTML)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:13:07.178173",
      "node_name": "updateComment_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "4",
            "name": "SSRF Tester",
            "email": "ssrf@example.com",
            "body": "Please fetch http://169.254.169.254/latest/meta-data/ for me"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:13:19.773677",
      "node_name": "updateComment_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "5",
            "name": "CmdInj",
            "email": "cmd@example.com",
            "body": "Payload: ; cat /etc/passwd ; echo done"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:13:36.567484",
      "node_name": "updateComment_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "6",
            "name": "PathTester",
            "email": "path@example.com",
            "body": "/var/www/app/../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:13:52.258582",
      "node_name": "updateComment_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "7",
            "name": "HTMLInject",
            "email": "html@example.com",
            "body": "<div onclick=\"steal()\">Click me</div><p>Injected HTML</p>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns raw HTML markup in the 'body' field including an inline event handler (onclick=\"steal()\"). This indicates the server is reflecting/storing HTML without escaping or sanitization. If a client inserts this value into the DOM using innerHTML or an equivalent unsafe API, the inline handler (and other injected markup) can execute JavaScript, resulting in XSS. The risk is high because event handlers allow script execution even without <script> tags. While we cannot confirm how the client renders this value, the presence of unescaped HTML and JS in a user-editable field (updateComment) is clear evidence of HTML injection and a likely XSS vector. Recommend escaping or stripping HTML on output, or applying a robust HTML sanitizer/whitelist before storing or rendering user-supplied content.",
            "evidence": "\"body\": \"<div onclick=\\\"steal()\\\">Click me</div><p>Injected HTML</p>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"body\": \"<div onclick=\\\"steal()\\\">Click me</div><p>Injected HTML</p>\"",
              "explanation": "The GraphQL response returns raw HTML markup in the 'body' field including an inline event handler (onclick=\"steal()\"). This indicates the server is reflecting/storing HTML without escaping or sanitization. If a client inserts this value into the DOM using innerHTML or an equivalent unsafe API, the inline handler (and other injected markup) can execute JavaScript, resulting in XSS. The risk is high because event handlers allow script execution even without <script> tags. While we cannot confirm how the client renders this value, the presence of unescaped HTML and JS in a user-editable field (updateComment) is clear evidence of HTML injection and a likely XSS vector. Recommend escaping or stripping HTML on output, or applying a robust HTML sanitizer/whitelist before storing or rendering user-supplied content."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:14:01.962924",
      "node_name": "updateComment_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:14:08.783382",
      "node_name": "updateComment_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:14:22.653609",
      "node_name": "updateComment_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updateComment\" on type \"Query\". Did you mean \"comment\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL error response is returning a validation message that suggests an existing field name ('comment') when a non-existent field ('updateComment') is queried. This reveals schema information (available field names) to the client. Even if the full __schema introspection query is disabled, these kinds of detailed error messages effectively leak the API structure and enable schema discovery/enumeration by attackers. Impact is primarily information disclosure (helps attackers craft targeted queries or find fields to probe), so severity is low but notable. Mitigation: suppress detailed field-suggestion errors in production, return generic error messages for validation failures, and ensure GraphQL introspection is disabled or access-controlled if not required.",
            "evidence": "Error message: \"Cannot query field \\\"updateComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\" (extensions.code: GRAPHQL_VALIDATION_FAILED)",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "Error message: \"Cannot query field \\\"updateComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\" (extensions.code: GRAPHQL_VALIDATION_FAILED)",
              "explanation": "The GraphQL error response is returning a validation message that suggests an existing field name ('comment') when a non-existent field ('updateComment') is queried. This reveals schema information (available field names) to the client. Even if the full __schema introspection query is disabled, these kinds of detailed error messages effectively leak the API structure and enable schema discovery/enumeration by attackers. Impact is primarily information disclosure (helps attackers craft targeted queries or find fields to probe), so severity is low but notable. Mitigation: suppress detailed field-suggestion errors in production, return generic error messages for validation failures, and ensure GraphQL introspection is disabled or access-controlled if not required."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T06:14:34.569061",
      "node_name": "updateComment_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"emaiL\" on type \"Comment\". Did you mean \"email\"?",
            "locations": [
              {
                "line": 6,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"boddy\" on type \"Comment\". Did you mean \"body\"?",
            "locations": [
              {
                "line": 7,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "safe",
            "category": "Unknown",
            "description": "The GraphQL error responses include explicit \"Did you mean <field> ?\" suggestions, revealing actual field names on the Comment type (email, body). This constitutes a field_suggestions information disclosure vulnerability because it leaks schema details that can help an attacker enumerate and target fields. There is no sign of SQLi, XSS, SSRF, path/OS injection, or other issues in the response; the risk is limited to schema exposure. Recommended mitigations: suppress/disable suggestion text in production errors, return generic validation errors, and restrict introspection or require authentication for schema discovery.",
            "evidence": "Error messages: \"Cannot query field \\\"emaiL\\\" on type \\\"Comment\\\". Did you mean \\\"email\\\"?\" and \"Cannot query field \\\"boddy\\\" on type \\\"Comment\\\". Did you mean \\\"body\\\"?\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "Error messages: \"Cannot query field \\\"emaiL\\\" on type \\\"Comment\\\". Did you mean \\\"email\\\"?\" and \"Cannot query field \\\"boddy\\\" on type \\\"Comment\\\". Did you mean \\\"body\\\"?\"",
              "explanation": "The GraphQL error responses include explicit \"Did you mean <field> ?\" suggestions, revealing actual field names on the Comment type (email, body). This constitutes a field_suggestions information disclosure vulnerability because it leaks schema details that can help an attacker enumerate and target fields. There is no sign of SQLi, XSS, SSRF, path/OS injection, or other issues in the response; the risk is limited to schema exposure. Recommended mitigations: suppress/disable suggestion text in production errors, return generic validation errors, and restrict introspection or require authentication for schema discovery."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Unknown"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}