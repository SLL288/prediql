{
  "report_timestamp": "2025-10-03T04:34:01.097437",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.0,
    "simple_detections": 2,
    "llm_detections": 5,
    "consensus_breakdown": {
      "no_vulnerabilities": 5,
      "llm_only": 3,
      "both_detected": 2
    },
    "detection_ratio": 2.5,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 5,
      "potential_consensus_breakdown": {
        "no_potential": 5,
        "llm_potential_only": 5
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-03T04:31:58.014771",
      "node_name": "comments_response_1",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Expected value of type \"SearchOptions\", found \"1' OR '1'='1'; DROP TABLE comments; --\".",
            "locations": [
              {
                "line": 3,
                "column": 64
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:32:11.688883",
      "node_name": "comments_response_2",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Expected value of type \"SearchOptions\", found \"<script>fetch('/exfil?c='+document.cookie)</script>\".",
            "locations": [
              {
                "line": 3,
                "column": 64
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL error message reflects the exact user-supplied payload including a <script> tag into the JSON response: the payload \"<script>fetch('/exfil?c='+document.cookie)</script>\" appears verbatim. This is a reflected output of unescaped user input. If any client or web UI renders this error message into an HTML context without proper encoding (for example in GraphiQL, a custom frontend error panel, or server-generated error pages), the script would execute in the victim's browser, enabling XSS and cookie/exfiltration attacks. The response itself being JSON does not automatically execute script, so exploitation requires a vulnerable rendering context. Remediation: ensure user input is never reflected into HTML without proper escaping/encoding, sanitize/validate inputs, and avoid returning raw user content in error messages (or ensure the client safely encodes it).",
            "evidence": "\"message\": \"Expected value of type \\\"SearchOptions\\\", found \\\"<script>fetch('/exfil?c='+document.cookie)</script>\\\".\"",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "MEDIUM",
              "confidence": 0.8,
              "evidence": "\"message\": \"Expected value of type \\\"SearchOptions\\\", found \\\"<script>fetch('/exfil?c='+document.cookie)</script>\\\".\"",
              "explanation": "The GraphQL error message reflects the exact user-supplied payload including a <script> tag into the JSON response: the payload \"<script>fetch('/exfil?c='+document.cookie)</script>\" appears verbatim. This is a reflected output of unescaped user input. If any client or web UI renders this error message into an HTML context without proper encoding (for example in GraphiQL, a custom frontend error panel, or server-generated error pages), the script would execute in the victim's browser, enabling XSS and cookie/exfiltration attacks. The response itself being JSON does not automatically execute script, so exploitation requires a vulnerable rendering context. Remediation: ensure user input is never reflected into HTML without proper escaping/encoding, sanitize/validate inputs, and avoid returning raw user content in error messages (or ensure the client safely encodes it)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:32:32.141554",
      "node_name": "comments_response_3",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Expected value of type \"SearchOptions\", found \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\".",
            "locations": [
              {
                "line": 3,
                "column": 64
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:32:47.701884",
      "node_name": "comments_response_4",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Expected value of type \"SearchOptions\", found \"$(cat /etc/passwd)\".",
            "locations": [
              {
                "line": 3,
                "column": 64
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: unknown",
            "detection": "potential",
            "category": "Unknown",
            "description": "{\n    \"is_vulnerable\": false,\n    \"vulnerability_type\": \"\",\n    \"severity\": \"LOW\",\n    \"confidence\": 0.9,\n    \"evidence\": \"Error message: \\\"Expected value of type \\\\\\\"SearchOptions\\\\\\\", found \\\\\\\"$(cat /etc/passwd)\\\\\\\".\\\"\",\n    \"explanation\": \"The response simply reflects the submitted string '$(cat /etc/passwd)' in a GraphQL validation error indicating a type mismatch (expected SearchOptions). There is no evidence that the payload was executed on the server (no file contents from /etc/passwd or other command output are returned), only that user input was echoed back for validation. This is not sufficient to conclude an OS command injection vulnerability. Reflection of input can be a warning sign, but without execution results or side effects there is no clear proof of command execution. Recommend further testing in a safe, authorized environment (e.g., controlled probes that look for execution effects) if you need to fully assess injection risk.\"",
            "evidence": "Found vulnerability indicators in response",
            "confidence": 0.3,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "unknown",
              "severity": "MEDIUM",
              "confidence": 0.3,
              "evidence": "Found vulnerability indicators in response",
              "explanation": "{\n    \"is_vulnerable\": false,\n    \"vulnerability_type\": \"\",\n    \"severity\": \"LOW\",\n    \"confidence\": 0.9,\n    \"evidence\": \"Error message: \\\"Expected value of type \\\\\\\"SearchOptions\\\\\\\", found \\\\\\\"$(cat /etc/passwd)\\\\\\\".\\\"\",\n    \"explanation\": \"The response simply reflects the submitted string '$(cat /etc/passwd)' in a GraphQL validation error indicating a type mismatch (expected SearchOptions). There is no evidence that the payload was executed on the server (no file contents from /etc/passwd or other command output are returned), only that user input was echoed back for validation. This is not sufficient to conclude an OS command injection vulnerability. Reflection of input can be a warning sign, but without execution results or side effects there is no clear proof of command execution. Recommend further testing in a safe, authorized environment (e.g., controlled probes that look for execution effects) if you need to fully assess injection risk.\""
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:33:01.272738",
      "node_name": "comments_response_5",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Expected value of type \"SearchOptions\", found \"../../../../../etc/passwd\".",
            "locations": [
              {
                "line": 3,
                "column": 64
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:33:17.426940",
      "node_name": "comments_response_6",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Expected value of type \"SearchOptions\", found \"<div><img src=x onerror=\\\"this.src='x';alert('injected')\\\"></div>\".",
            "locations": [
              {
                "line": 3,
                "column": 64
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL error message reflects the exact attacker-supplied HTML string back in the response: <div><img src=x onerror=\"this.src='x';alert('injected')\"></div>. Although the response is JSON, the server is returning raw markup inside the error message. If a client application takes that error text and injects it into the DOM without proper escaping (e.g., using innerHTML), the embedded onerror JavaScript would execute, resulting in a reflected XSS/HTML injection. This is a server-side reflection of user input and thus creates a realistic injection vector dependent on client-side rendering. Recommended mitigations: do not include raw user-supplied HTML in error messages, HTML-encode/escape error content, or ensure clients render error strings as plain text rather than HTML.",
            "evidence": "Expected value of type \"SearchOptions\", found \"<div><img src=x onerror=\\\"this.src='x';alert('injected')\\\"></div>\".",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "MEDIUM",
              "confidence": 0.85,
              "evidence": "Expected value of type \"SearchOptions\", found \"<div><img src=x onerror=\\\"this.src='x';alert('injected')\\\"></div>\".",
              "explanation": "The GraphQL error message reflects the exact attacker-supplied HTML string back in the response: <div><img src=x onerror=\"this.src='x';alert('injected')\"></div>. Although the response is JSON, the server is returning raw markup inside the error message. If a client application takes that error text and injects it into the DOM without proper escaping (e.g., using innerHTML), the embedded onerror JavaScript would execute, resulting in a reflected XSS/HTML injection. This is a server-side reflection of user input and thus creates a realistic injection vector dependent on client-side rendering. Recommended mitigations: do not include raw user-supplied HTML in error messages, HTML-encode/escape error content, or ensure clients render error strings as plain text rather than HTML."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:33:25.391509",
      "node_name": "comments_response_7",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:33:33.478524",
      "node_name": "comments_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:33:48.543353",
      "node_name": "comments_response_9",
      "response_status": 200,
      "response_body": {
        "data": {
          "comments": {
            "data": [
              {
                "id": "1"
              }
            ],
            "meta": {
              "totalCount": 500
            }
          },
          "__schema": {
            "types": [
              {
                "name": "Query",
                "kind": "OBJECT"
              },
              {
                "name": "Int",
                "kind": "SCALAR"
              },
              {
                "name": "ID",
                "kind": "SCALAR"
              },
              {
                "name": "Mutation",
                "kind": "OBJECT"
              },
              {
                "name": "Boolean",
                "kind": "SCALAR"
              },
              {
                "name": "Album",
                "kind": "OBJECT"
              },
              {
                "name": "String",
                "kind": "SCALAR"
              },
              {
                "name": "CreateAlbumInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "UpdateAlbumInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "Comment",
                "kind": "OBJECT"
              },
              {
                "name": "CreateCommentInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "UpdateCommentInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "PageQueryOptions",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "PaginateOptions",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "SliceOptions",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "SortOptions",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "SortOrderEnum",
                "kind": "ENUM"
              },
              {
                "name": "OperatorOptions",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "OperatorKindEnum",
                "kind": "ENUM"
              },
              {
                "name": "SearchOptions",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "PostsPage",
                "kind": "OBJECT"
              },
              {
                "name": "CommentsPage",
                "kind": "OBJECT"
              },
              {
                "name": "AlbumsPage",
                "kind": "OBJECT"
              },
              {
                "name": "PhotosPage",
                "kind": "OBJECT"
              },
              {
                "name": "TodosPage",
                "kind": "OBJECT"
              },
              {
                "name": "UsersPage",
                "kind": "OBJECT"
              },
              {
                "name": "PaginationLinks",
                "kind": "OBJECT"
              },
              {
                "name": "PageLimitPair",
                "kind": "OBJECT"
              },
              {
                "name": "PageMetadata",
                "kind": "OBJECT"
              },
              {
                "name": "Photo",
                "kind": "OBJECT"
              },
              {
                "name": "CreatePhotoInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "UpdatePhotoInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "Post",
                "kind": "OBJECT"
              },
              {
                "name": "CreatePostInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "UpdatePostInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "Todo",
                "kind": "OBJECT"
              },
              {
                "name": "CreateTodoInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "UpdateTodoInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "User",
                "kind": "OBJECT"
              },
              {
                "name": "Address",
                "kind": "OBJECT"
              },
              {
                "name": "Geo",
                "kind": "OBJECT"
              },
              {
                "name": "Float",
                "kind": "SCALAR"
              },
              {
                "name": "Company",
                "kind": "OBJECT"
              },
              {
                "name": "CreateUserInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "UpdateUserInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "AddressInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "GeoInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "CompanyInput",
                "kind": "INPUT_OBJECT"
              },
              {
                "name": "__Schema",
                "kind": "OBJECT"
              },
              {
                "name": "__Type",
                "kind": "OBJECT"
              },
              {
                "name": "__TypeKind",
                "kind": "ENUM"
              },
              {
                "name": "__Field",
                "kind": "OBJECT"
              },
              {
                "name": "__InputValue",
                "kind": "OBJECT"
              },
              {
                "name": "__EnumValue",
                "kind": "OBJECT"
              },
              {
                "name": "__Directive",
                "kind": "OBJECT"
              },
              {
                "name": "__DirectiveLocation",
                "kind": "ENUM"
              }
            ]
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Introspection Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "GraphQL introspection enabled - potential information disclosure",
            "evidence": "Found __schema in response data - introspection queries are allowed"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The response contains a top-level __schema object with a complete types list, which indicates GraphQL introspection is enabled and returning schema metadata. This exposes the API shape (queries, mutations, object types, input types and enums) such as Query, Mutation, User, CreateUserInput, UpdateUserInput, etc. Exposed schema information increases attack surface by allowing an attacker to discover available operations and fields (including potentially sensitive fields or mutation inputs), enabling more targeted queries, enumeration, and automated tooling to find further vulnerabilities or bypass protections. Recommend disabling GraphQL introspection in production or restricting it to authenticated/authorized users, removing or protecting sensitive fields, implementing rate-limiting and monitoring, and applying least-privilege access controls for schema discovery.",
            "evidence": "\"__schema\": { \"types\": [ { \"name\": \"Query\", \"kind\": \"OBJECT\" }, { \"name\": \"Mutation\", \"kind\": \"OBJECT\" }, { \"name\": \"User\", \"kind\": \"OBJECT\" }, { \"name\": \"CreateUserInput\", \"kind\": \"INPUT_OBJECT\" }, ... ] }",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "\"__schema\": { \"types\": [ { \"name\": \"Query\", \"kind\": \"OBJECT\" }, { \"name\": \"Mutation\", \"kind\": \"OBJECT\" }, { \"name\": \"User\", \"kind\": \"OBJECT\" }, { \"name\": \"CreateUserInput\", \"kind\": \"INPUT_OBJECT\" }, ... ] }",
              "explanation": "The response contains a top-level __schema object with a complete types list, which indicates GraphQL introspection is enabled and returning schema metadata. This exposes the API shape (queries, mutations, object types, input types and enums) such as Query, Mutation, User, CreateUserInput, UpdateUserInput, etc. Exposed schema information increases attack surface by allowing an attacker to discover available operations and fields (including potentially sensitive fields or mutation inputs), enabling more targeted queries, enumeration, and automated tooling to find further vulnerabilities or bypass protections. Recommend disabling GraphQL introspection in production or restricting it to authenticated/authorized users, removing or protecting sensitive fields, implementing rate-limiting and monitoring, and applying least-privilege access controls for schema discovery."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T04:34:01.093243",
      "node_name": "comments_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"nam\" on type \"Comment\". Did you mean \"name\"?",
            "locations": [
              {
                "line": 6,
                "column": 7
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"emal\" on type \"Comment\". Did you mean \"email\"?",
            "locations": [
              {
                "line": 7,
                "column": 7
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL error responses include \"Did you mean ...?\" suggestions that reveal valid field names on the Comment type (name, email). This is a field_suggestions information disclosure vulnerability: it leaks schema details which can be used to enumerate fields and craft targeted queries or further attacks. Impact is information disclosure that can aid an attacker in recon profiling; severity set to MEDIUM because while this does not directly expose data, it lowers the effort for further exploitation. Remediation: suppress or genericize validation error messages, disable suggestion feature in the GraphQL server, or return generic error payloads that do not reveal schema details.",
            "evidence": "\"Cannot query field \\\"nam\\\" on type \\\"Comment\\\". Did you mean \\\"name\\\"?\" and \"Cannot query field \\\"emal\\\" on type \\\"Comment\\\". Did you mean \\\"email\\\"?\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "\"Cannot query field \\\"nam\\\" on type \\\"Comment\\\". Did you mean \\\"name\\\"?\" and \"Cannot query field \\\"emal\\\" on type \\\"Comment\\\". Did you mean \\\"email\\\"?\"",
              "explanation": "The GraphQL error responses include \"Did you mean ...?\" suggestions that reveal valid field names on the Comment type (name, email). This is a field_suggestions information disclosure vulnerability: it leaks schema details which can be used to enumerate fields and craft targeted queries or further attacks. Impact is information disclosure that can aid an attacker in recon profiling; severity set to MEDIUM because while this does not directly expose data, it lowers the effort for further exploitation. Remediation: suppress or genericize validation error messages, disable suggestion feature in the GraphQL server, or return generic error payloads that do not reveal schema details."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}