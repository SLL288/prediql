{
  "report_timestamp": "2025-10-03T09:03:40.710574",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 6,
    "llm_detections": 3,
    "consensus_breakdown": {
      "simple_only": 3,
      "both_detected": 3,
      "no_vulnerabilities": 4
    },
    "detection_ratio": 0.5,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 5,
      "llm_potential_detections": 0,
      "potential_consensus_breakdown": {
        "simple_potential_only": 5,
        "no_potential": 5
      },
      "potential_detection_ratio": 0.0
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-03T09:02:09.044330",
      "node_name": "createTodo_response_1",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "Robert'); DROP TABLE users; -- SQLi test",
            "completed": false,
            "user": {
              "id": null,
              "name": null,
              "email": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:02:15.869546",
      "node_name": "createTodo_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "<script>alert('xss-from-graphql')</script> Search",
            "user": {
              "id": null,
              "name": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains a raw <script> tag in the returned 'title' field. The createTodo operation returns the exact string \"<script>alert('xss-from-graphql')</script> Search\", which indicates the API accepts and returns markup/script content without encoding or sanitization. If a web client inserts this value into the DOM without proper output encoding/sanitization, it will execute as JavaScript (stored/reflected XSS). This is a high-risk issue because stored XSS can be leveraged to run arbitrary scripts in other users' browsers. Recommended mitigations: perform input validation and server-side sanitization, apply proper output encoding/escaping in the client when inserting data into HTML contexts, use a robust HTML sanitizer for allowed markup, and enforce a Content Security Policy (CSP).",
            "evidence": "\"title\": \"<script>alert('xss-from-graphql')</script> Search\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"title\": \"<script>alert('xss-from-graphql')</script> Search\"",
              "explanation": "The GraphQL response contains a raw <script> tag in the returned 'title' field. The createTodo operation returns the exact string \"<script>alert('xss-from-graphql')</script> Search\", which indicates the API accepts and returns markup/script content without encoding or sanitization. If a web client inserts this value into the DOM without proper output encoding/sanitization, it will execute as JavaScript (stored/reflected XSS). This is a high-risk issue because stored XSS can be leveraged to run arbitrary scripts in other users' browsers. Recommended mitigations: perform input validation and server-side sanitization, apply proper output encoding/escaping in the client when inserting data into HTML contexts, use a robust HTML sanitizer for allowed markup, and enforce a Content Security Policy (CSP)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:02:28.086975",
      "node_name": "createTodo_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "Fetch me: http://169.254.169.254/latest/meta-data/iam/security-credentials/",
            "user": {
              "id": null,
              "email": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:02:42.974887",
      "node_name": "createTodo_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "cmd_inject; $(touch /tmp/graphq1_inject) || true",
            "completed": false
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:02:50.837049",
      "node_name": "createTodo_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "../../../../etc/passwd traversal test",
            "user": {
              "id": null,
              "name": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:02:59.059165",
      "node_name": "createTodo_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "<div><img src=x onerror=\"this.dataset.e=1\">InjectedHTML</div>",
            "user": {
              "id": null,
              "name": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns raw HTML in the 'title' field: a <div> containing an <img> tag with an onerror JavaScript handler. If a client (web application) inserts this value into the DOM without HTML-encoding or sanitization, the onerror handler can execute, resulting in XSS (HTML injection). The mutation name (createTodo) indicates this value is likely persisted and then rendered by clients (stored XSS risk). Mitigations: properly HTML-encode or sanitize output before inserting into the DOM, use safe client-side APIs (textContent), implement input validation/whitelisting, and employ a CSP to limit impact.",
            "evidence": "\"title\": \"<div><img src=x onerror=\\\"this.dataset.e=1\\\">InjectedHTML</div>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"title\": \"<div><img src=x onerror=\\\"this.dataset.e=1\\\">InjectedHTML</div>\"",
              "explanation": "The GraphQL response returns raw HTML in the 'title' field: a <div> containing an <img> tag with an onerror JavaScript handler. If a client (web application) inserts this value into the DOM without HTML-encoding or sanitization, the onerror handler can execute, resulting in XSS (HTML injection). The mutation name (createTodo) indicates this value is likely persisted and then rendered by clients (stored XSS risk). Mitigations: properly HTML-encode or sanitize output before inserting into the DOM, use safe client-side APIs (textContent), implement input validation/whitelisting, and employ a CSP to limit impact."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:03:05.778209",
      "node_name": "createTodo_response_7",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:03:13.294398",
      "node_name": "createTodo_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:03:26.914552",
      "node_name": "createTodo_response_9",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createTodo\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-03T09:03:40.707686",
      "node_name": "createTodo_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"CreateTodoInput.completed\" of required type \"Boolean!\" was not provided.",
            "locations": [
              {
                "line": 3,
                "column": 21
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"tittle\" on type \"Todo\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"titl\" on type \"Todo\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 6,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "safe",
            "category": "Unknown",
            "description": "The GraphQL server returns user-facing validation errors that include field-name suggestions and type information. The messages explicitly reveal a schema field name ('title') and the required input field 'CreateTodoInput.completed' with its type (Boolean!), which discloses internal schema structure. This behavior facilitates schema discovery and automated enumeration by attackers. Recommend suppressing detailed suggestion text in production (return generic validation errors), removing schema suggestion hints, or centralizing error handling to avoid exposing schema details.",
            "evidence": "Error messages: \"Field \\\"CreateTodoInput.completed\\\" of required type \\\"Boolean!\\\" was not provided.\" and \"Cannot query field \\\"tittle\\\" on type \\\"Todo\\\". Did you mean \\\"title\\\"?\" / \"Cannot query field \\\"titl\\\" on type \\\"Todo\\\". Did you mean \\\"title\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "LOW",
              "confidence": 0.95,
              "evidence": "Error messages: \"Field \\\"CreateTodoInput.completed\\\" of required type \\\"Boolean!\\\" was not provided.\" and \"Cannot query field \\\"tittle\\\" on type \\\"Todo\\\". Did you mean \\\"title\\\"?\" / \"Cannot query field \\\"titl\\\" on type \\\"Todo\\\". Did you mean \\\"title\\\"?\"",
              "explanation": "The GraphQL server returns user-facing validation errors that include field-name suggestions and type information. The messages explicitly reveal a schema field name ('title') and the required input field 'CreateTodoInput.completed' with its type (Boolean!), which discloses internal schema structure. This behavior facilitates schema discovery and automated enumeration by attackers. Recommend suppressing detailed suggestion text in production (return generic validation errors), removing schema suggestion hints, or centralizing error handling to avoid exposing schema details."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Unknown"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}