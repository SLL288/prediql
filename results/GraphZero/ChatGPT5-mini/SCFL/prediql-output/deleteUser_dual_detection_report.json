{
  "report_timestamp": "2025-10-06T00:51:36.765910",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.0,
    "simple_detections": 0,
    "llm_detections": 3,
    "consensus_breakdown": {
      "llm_only": 3,
      "no_vulnerabilities": 7
    },
    "detection_ratio": Infinity,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 0,
      "llm_potential_detections": 0,
      "potential_consensus_breakdown": {
        "no_potential": 10
      },
      "potential_detection_ratio": Infinity
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-06T00:49:13.274446",
      "node_name": "deleteUser_response_2",
      "response_status": null,
      "response_body": {
        "error": "HTTPSConnectionPool(host='graphqlzero.almansi.me', port=443): Read timed out. (read timeout=10)"
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Information Disclosure",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains a raw internal exception message (a Python 'requests' HTTPSConnectionPool read timeout) which reveals implementation and infrastructure details (host, port, use of Python requests, and timeout value). While this does not indicate SQLi, XSS, SSRF, or command injection, exposing internal error text is an information disclosure risk that can aid attackers in profiling the service. Severity is low because no sensitive data (credentials, stack traces with file paths, internal IPs) is directly exposed, but the behavior suggests the server may leak additional internal errors and should sanitize error output.",
            "evidence": "Response Body: \"error\": \"HTTPSConnectionPool(host='graphqlzero.almansi.me', port=443): Read timed out. (read timeout=10)\"",
            "confidence": 0.6,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Information Disclosure",
              "severity": "LOW",
              "confidence": 0.6,
              "evidence": "Response Body: \"error\": \"HTTPSConnectionPool(host='graphqlzero.almansi.me', port=443): Read timed out. (read timeout=10)\"",
              "explanation": "The GraphQL response contains a raw internal exception message (a Python 'requests' HTTPSConnectionPool read timeout) which reveals implementation and infrastructure details (host, port, use of Python requests, and timeout value). While this does not indicate SQLi, XSS, SSRF, or command injection, exposing internal error text is an information disclosure risk that can aid attackers in profiling the service. Severity is low because no sensitive data (credentials, stack traces with file paths, internal IPs) is directly exposed, but the behavior suggests the server may leak additional internal errors and should sanitize error output."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:49:25.324776",
      "node_name": "deleteUser_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "deleteUser": true
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:49:42.419780",
      "node_name": "deleteUser_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "deleteUser": true
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:49:55.370806",
      "node_name": "deleteUser_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "deleteUser": true
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:50:13.188464",
      "node_name": "deleteUser_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "deleteUser": true
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:50:33.584582",
      "node_name": "deleteUser_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "deleteUser": true
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:50:49.966749",
      "node_name": "deleteUser_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:51:01.122814",
      "node_name": "deleteUser_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:51:21.829329",
      "node_name": "deleteUser_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"deleteUser\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: introspection",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL endpoint returns detailed validation errors that reveal schema information — specifically that a field named 'deleteUser' does not exist on type 'Query'. While this is not a direct __schema introspection response, it discloses internal type/field names and behavior which can aid an attacker in enumerating the API schema and discovering valid queries or mutations. This is an information disclosure/introspection-style vulnerability. Recommend suppressing or genericizing GraphQL validation errors in production, and/or disabling GraphQL introspection in environments where schema disclosure is not desired.",
            "evidence": "GraphQL error message: \"Cannot query field \\\"deleteUser\\\" on type \\\"Query\\\".\"",
            "confidence": 0.6,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "introspection",
              "severity": "LOW",
              "confidence": 0.6,
              "evidence": "GraphQL error message: \"Cannot query field \\\"deleteUser\\\" on type \\\"Query\\\".\"",
              "explanation": "The GraphQL endpoint returns detailed validation errors that reveal schema information — specifically that a field named 'deleteUser' does not exist on type 'Query'. While this is not a direct __schema introspection response, it discloses internal type/field names and behavior which can aid an attacker in enumerating the API schema and discovering valid queries or mutations. This is an information disclosure/introspection-style vulnerability. Recommend suppressing or genericizing GraphQL validation errors in production, and/or disabling GraphQL introspection in environments where schema disclosure is not desired."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:51:36.759043",
      "node_name": "deleteUser_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"deleteUser\" must not have a selection since type \"Boolean\" has no subfields.",
            "locations": [
              {
                "line": 3,
                "column": 25
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "safe",
            "category": "Unknown",
            "description": "The GraphQL error message reveals schema information (the existence of a deleteUser field and that it returns a Boolean). This is an information disclosure / field suggestion issue: error responses are leaking type and field details that can assist an attacker in mapping the API and crafting further targeted queries or mutations. There is no indication of SQLi, XSS, SSRF, path/OS command injection, or sensitive data disclosure beyond schema details in this response. Impact is generally low but can facilitate reconnaissance. Recommended mitigations: return less-detailed validation errors in production (generic messages), restrict GraphQL introspection in production environments or apply proper authentication/authorization checks, and log detailed errors server-side only.",
            "evidence": "Error message: \"Field \\\"deleteUser\\\" must not have a selection since type \\\"Boolean\\\" has no subfields.\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "Error message: \"Field \\\"deleteUser\\\" must not have a selection since type \\\"Boolean\\\" has no subfields.\"",
              "explanation": "The GraphQL error message reveals schema information (the existence of a deleteUser field and that it returns a Boolean). This is an information disclosure / field suggestion issue: error responses are leaking type and field details that can assist an attacker in mapping the API and crafting further targeted queries or mutations. There is no indication of SQLi, XSS, SSRF, path/OS command injection, or sensitive data disclosure beyond schema details in this response. Impact is generally low but can facilitate reconnaissance. Recommended mitigations: return less-detailed validation errors in production (generic messages), restrict GraphQL introspection in production environments or apply proper authentication/authorization checks, and log detailed errors server-side only."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Unknown"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}