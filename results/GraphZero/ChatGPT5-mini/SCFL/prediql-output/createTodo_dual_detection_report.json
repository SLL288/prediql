{
  "report_timestamp": "2025-10-06T00:24:19.404855",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 6,
    "llm_detections": 5,
    "consensus_breakdown": {
      "simple_only": 3,
      "both_detected": 3,
      "llm_only": 2,
      "no_vulnerabilities": 2
    },
    "detection_ratio": 0.8333333333333334,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 5,
      "llm_potential_detections": 3,
      "potential_consensus_breakdown": {
        "simple_potential_only": 4,
        "both_potential": 1,
        "llm_potential_only": 2,
        "no_potential": 3
      },
      "potential_detection_ratio": 0.6
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-06T00:22:21.821305",
      "node_name": "createTodo_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "Robert'); DROP TABLE todos;--",
            "completed": false,
            "user": {
              "id": null,
              "email": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:22:37.797630",
      "node_name": "createTodo_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "<script>alert('xss')</script>",
            "user": {
              "id": null,
              "name": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns the user-supplied title containing raw <script>...</script> tags. This is clear evidence that the API reflects/stores HTML/JavaScript without sanitization or encoding. If any client or web UI renders this value into the DOM without proper output encoding, it would result in a stored/reflected XSS attack. Risk depends on how clients render the field, but the presence of unescaped script tags in API responses is a direct XSS indicator. Recommendation: validate and sanitize input server-side, apply proper output encoding/HTML-escape when rendering in the browser, and enforce Content Security Policy (CSP).",
            "evidence": "\"title\": \"<script>alert('xss')</script>\" in GraphQL response data.createTodo",
            "confidence": 0.7,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "MEDIUM",
              "confidence": 0.7,
              "evidence": "\"title\": \"<script>alert('xss')</script>\" in GraphQL response data.createTodo",
              "explanation": "The GraphQL response returns the user-supplied title containing raw <script>...</script> tags. This is clear evidence that the API reflects/stores HTML/JavaScript without sanitization or encoding. If any client or web UI renders this value into the DOM without proper output encoding, it would result in a stored/reflected XSS attack. Risk depends on how clients render the field, but the presence of unescaped script tags in API responses is a direct XSS indicator. Recommendation: validate and sanitize input server-side, apply proper output encoding/HTML-escape when rendering in the browser, and enforce Content Security Policy (CSP)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:22:54.071892",
      "node_name": "createTodo_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "http://169.254.169.254/latest/meta-data/iam/security-credentials/",
            "user": {
              "id": null,
              "website": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:23:08.180495",
      "node_name": "createTodo_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "test; cat /etc/passwd",
            "completed": false
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: unknown",
            "detection": "potential",
            "category": "Unknown",
            "description": "{\n    \"is_vulnerable\": false,\n    \"vulnerability_type\": \"\",\n    \"severity\": \"LOW\",\n    \"confidence\": 0.20,\n    \"evidence\": \"\\\"title\\\": \\\"test; cat /etc/passwd\\\"\",\n    \"explanation\": \"The response reflects the submitted string that contains shell metacharacters ('test; cat /etc/passwd') in the 'title' field, but there is no indication the server executed the command (no /etc/passwd contents, no execution artifacts). Reflection of user input alone is not proof of OS command execution. Based on this single response there is no clear evidence of an os_command_injection vulnerability. To confirm/exclude command injection you would need tests that produce observable side effects from execution (for example injecting a command that outputs a unique marker or triggers a detectable change) or server-side error/output that proves execution. Until such evidence is obtained, mark as not vulnerable but consider further safe testing in a controlled environment.\"",
            "evidence": "Found vulnerability indicators in response",
            "confidence": 0.3,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "unknown",
              "severity": "MEDIUM",
              "confidence": 0.3,
              "evidence": "Found vulnerability indicators in response",
              "explanation": "{\n    \"is_vulnerable\": false,\n    \"vulnerability_type\": \"\",\n    \"severity\": \"LOW\",\n    \"confidence\": 0.20,\n    \"evidence\": \"\\\"title\\\": \\\"test; cat /etc/passwd\\\"\",\n    \"explanation\": \"The response reflects the submitted string that contains shell metacharacters ('test; cat /etc/passwd') in the 'title' field, but there is no indication the server executed the command (no /etc/passwd contents, no execution artifacts). Reflection of user input alone is not proof of OS command execution. Based on this single response there is no clear evidence of an os_command_injection vulnerability. To confirm/exclude command injection you would need tests that produce observable side effects from execution (for example injecting a command that outputs a unique marker or triggers a detectable change) or server-side error/output that proves execution. Until such evidence is obtained, mark as not vulnerable but consider further safe testing in a controlled environment.\""
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:23:21.513222",
      "node_name": "createTodo_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "../../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:23:31.947128",
      "node_name": "createTodo_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createTodo": {
            "id": "201",
            "title": "<div><img src=x onerror=alert(1)></div>",
            "user": {
              "id": null,
              "name": null
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns user-controllable content in the title field containing HTML and an executable event attribute (<img src=x onerror=alert(1)>). This is clear evidence of HTML injection / potential stored XSS: the server is reflecting/persisting raw markup rather than sanitizing or encoding it. If a client application inserts this value into the DOM without proper escaping (e.g., using innerHTML), the onerror handler will execute JavaScript. Recommend treating this as a high-risk XSS vector and mitigate by validating/encoding output, sanitizing allowed HTML on the server, enforcing safe rendering practices on the client, and applying appropriate CSP headers.",
            "evidence": "\"title\": \"<div><img src=x onerror=alert(1)></div>\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.95,
              "evidence": "\"title\": \"<div><img src=x onerror=alert(1)></div>\"",
              "explanation": "The GraphQL response returns user-controllable content in the title field containing HTML and an executable event attribute (<img src=x onerror=alert(1)>). This is clear evidence of HTML injection / potential stored XSS: the server is reflecting/persisting raw markup rather than sanitizing or encoding it. If a client application inserts this value into the DOM without proper escaping (e.g., using innerHTML), the onerror handler will execute JavaScript. Recommend treating this as a high-risk XSS vector and mitigate by validating/encoding output, sanitizing allowed HTML on the server, enforcing safe rendering practices on the client, and applying appropriate CSP headers."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:23:43.261097",
      "node_name": "createTodo_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:23:54.096592",
      "node_name": "createTodo_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:24:08.635358",
      "node_name": "createTodo_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createTodo\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL endpoint returns a detailed schema-related validation error that discloses type/field information. Although this is not the __schema introspection query itself, leaking messages that specify whether a field exists on a particular type allows an attacker to enumerate the schema (field and type presence) by probing different names. This is a form of schema introspection/information disclosure. Impact is limited compared to full introspection but still enables reconnaissance; severity is marked LOW and confidence is moderate given the explicit field/type disclosure in the response.",
            "evidence": "Error message: \"Cannot query field \\\"createTodo\\\" on type \\\"Query\\\".\"",
            "confidence": 0.7,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection",
              "severity": "LOW",
              "confidence": 0.7,
              "evidence": "Error message: \"Cannot query field \\\"createTodo\\\" on type \\\"Query\\\".\"",
              "explanation": "The GraphQL endpoint returns a detailed schema-related validation error that discloses type/field information. Although this is not the __schema introspection query itself, leaking messages that specify whether a field exists on a particular type allows an attacker to enumerate the schema (field and type presence) by probing different names. This is a form of schema introspection/information disclosure. Impact is limited compared to full introspection but still enables reconnaissance; severity is marked LOW and confidence is moderate given the explicit field/type disclosure in the response."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T00:24:19.403703",
      "node_name": "createTodo_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"titl\" on type \"Todo\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL error response includes a suggestion revealing a valid field name ('title') when the client requested a misspelled field ('titl'). This behavior leaks schema information (valid field names/types) to clients, enabling an attacker to enumerate the API schema and craft more targeted queries. While this does not directly expose sensitive data, it is an information disclosure vulnerability that can aid further reconnaissance and attacks. The presence of the explicit \"Did you mean \\\"...\\\"?\" suggestion is clear evidence of field-suggestion behavior. Recommended mitigation is to disable or sanitize suggestion/hint messages in error responses or to return generic validation errors that do not leak schema details.",
            "evidence": "Error message: \"Cannot query field \\\"titl\\\" on type \\\"Todo\\\". Did you mean \\\"title\\\"?\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "Error message: \"Cannot query field \\\"titl\\\" on type \\\"Todo\\\". Did you mean \\\"title\\\"?\"",
              "explanation": "The GraphQL error response includes a suggestion revealing a valid field name ('title') when the client requested a misspelled field ('titl'). This behavior leaks schema information (valid field names/types) to clients, enabling an attacker to enumerate the API schema and craft more targeted queries. While this does not directly expose sensitive data, it is an information disclosure vulnerability that can aid further reconnaissance and attacks. The presence of the explicit \"Did you mean \\\"...\\\"?\" suggestion is clear evidence of field-suggestion behavior. Recommended mitigation is to disable or sanitize suggestion/hint messages in error responses or to return generic validation errors that do not leak schema details."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}