{
  "report_timestamp": "2025-09-23T20:18:16.102258",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 4,
    "llm_detections": 3,
    "consensus_breakdown": {
      "simple_only": 1,
      "both_detected": 3,
      "no_vulnerabilities": 6
    },
    "detection_ratio": 0.75,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 3,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 3,
        "no_potential": 6,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 0.3333333333333333
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-09-23T20:16:29.009742",
      "node_name": "createAlbum_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createAlbum": {
            "id": "101",
            "title": "Robert'); DROP TABLE users; --",
            "user": {
              "id": "2",
              "email": "Shanna@melissa.tv"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:16:42.725531",
      "node_name": "createAlbum_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createAlbum": {
            "id": "101",
            "title": "<script>alert('xss')</script>",
            "user": {
              "id": "4",
              "username": "Karianne"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns an unescaped script tag in the 'title' field for the createAlbum mutation. The value \"<script>alert('xss')</script>\" demonstrates that the API accepted and echoed HTML/JavaScript content. Since this is the result of a create operation, it likely represents stored or reflected XSS: if a client renders this title into the DOM without proper output-encoding/sanitization (for example via innerHTML or direct insertion), arbitrary script will execute in users' browsers. This is a clear indicator of potential XSS; to confirm, render the returned title in the target client and observe whether the script executes. Mitigations: validate/encode output, sanitize input on the server, use safe rendering APIs, and deploy CSP.",
            "evidence": "\"title\": \"<script>alert('xss')</script>\" in response to createAlbum",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"title\": \"<script>alert('xss')</script>\" in response to createAlbum",
              "explanation": "The GraphQL response returns an unescaped script tag in the 'title' field for the createAlbum mutation. The value \"<script>alert('xss')</script>\" demonstrates that the API accepted and echoed HTML/JavaScript content. Since this is the result of a create operation, it likely represents stored or reflected XSS: if a client renders this title into the DOM without proper output-encoding/sanitization (for example via innerHTML or direct insertion), arbitrary script will execute in users' browsers. This is a clear indicator of potential XSS; to confirm, render the returned title in the target client and observe whether the script executes. Mitigations: validate/encode output, sanitize input on the server, use safe rendering APIs, and deploy CSP."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:16:54.105061",
      "node_name": "createAlbum_response_4",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"coverUrl\" is not defined by type \"CreateAlbumInput\".",
            "locations": [
              {
                "line": 3,
                "column": 57
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:17:04.328686",
      "node_name": "createAlbum_response_5",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"notes\" is not defined by type \"CreateAlbumInput\".",
            "locations": [
              {
                "line": 3,
                "column": 73
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:17:15.312138",
      "node_name": "createAlbum_response_6",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"filePath\" is not defined by type \"CreateAlbumInput\".",
            "locations": [
              {
                "line": 3,
                "column": 67
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:17:28.908617",
      "node_name": "createAlbum_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createAlbum": {
            "id": "101",
            "title": "<div onclick=\"alert('xss')\">Click me</div>",
            "user": {
              "id": "8",
              "name": "Nicholas Runolfsdottir V"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns a raw HTML fragment with an inline event handler in the 'title' field. This indicates that HTML/JS content is being stored/returned without sanitization or encoding. If a client or web application inserts this value into the DOM without proper escaping or sanitization, the onclick handler (or other injected code) can execute, resulting in cross-site scripting (DOM or stored XSS). Recommend validating and sanitizing user-supplied content server-side, and encoding/escaping values when rendering in HTML contexts (or using a safe renderer) to mitigate this risk. Further testing should confirm where and how this field is rendered to determine actual exploitability.",
            "evidence": "\"title\": \"<div onclick=\\\"alert('xss')\\\">Click me</div>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"title\": \"<div onclick=\\\"alert('xss')\\\">Click me</div>\"",
              "explanation": "The GraphQL response returns a raw HTML fragment with an inline event handler in the 'title' field. This indicates that HTML/JS content is being stored/returned without sanitization or encoding. If a client or web application inserts this value into the DOM without proper escaping or sanitization, the onclick handler (or other injected code) can execute, resulting in cross-site scripting (DOM or stored XSS). Recommend validating and sanitizing user-supplied content server-side, and encoding/escaping values when rendering in HTML contexts (or using a safe renderer) to mitigate this risk. Further testing should confirm where and how this field is rendered to determine actual exploitability."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:17:39.514832",
      "node_name": "createAlbum_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:17:49.230724",
      "node_name": "createAlbum_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:18:05.405319",
      "node_name": "createAlbum_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createAlbum\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:18:16.099213",
      "node_name": "createAlbum_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"titel\" is not defined by type \"CreateAlbumInput\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 3,
                "column": 24
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"tittle\" on type \"Album\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"fullname\" on type \"User\". Did you mean \"name\" or \"username\"?",
            "locations": [
              {
                "line": 9,
                "column": 7
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL error responses are returning helpful 'Did you mean ...?' suggestions that reveal valid field names in the schema (e.g., title, name, username). This constitutes a field_suggestions information-disclosure vulnerability because it allows an attacker to enumerate and discover schema fields and types, making targeted queries and further attacks easier. The responses do not appear to leak sensitive data directly, but they expose schema details that reduce the attacker's effort and increase risk. Recommended mitigations: disable suggestion hints in production error messages, return generic validation errors, and ensure GraphQL debug/info-level error messages are not exposed to untrusted clients.",
            "evidence": "Error messages: \"Field \\\"titel\\\" is not defined by type \\\"CreateAlbumInput\\\". Did you mean \\\"title\\\"?\", \"Cannot query field \\\"tittle\\\" on type \\\"Album\\\". Did you mean \\\"title\\\"?\", \"Cannot query field \\\"fullname\\\" on type \\\"User\\\". Did you mean \\\"name\\\" or \\\"username\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "Error messages: \"Field \\\"titel\\\" is not defined by type \\\"CreateAlbumInput\\\". Did you mean \\\"title\\\"?\", \"Cannot query field \\\"tittle\\\" on type \\\"Album\\\". Did you mean \\\"title\\\"?\", \"Cannot query field \\\"fullname\\\" on type \\\"User\\\". Did you mean \\\"name\\\" or \\\"username\\\"?\"",
              "explanation": "The GraphQL error responses are returning helpful 'Did you mean ...?' suggestions that reveal valid field names in the schema (e.g., title, name, username). This constitutes a field_suggestions information-disclosure vulnerability because it allows an attacker to enumerate and discover schema fields and types, making targeted queries and further attacks easier. The responses do not appear to leak sensitive data directly, but they expose schema details that reduce the attacker's effort and increase risk. Recommended mitigations: disable suggestion hints in production error messages, return generic validation errors, and ensure GraphQL debug/info-level error messages are not exposed to untrusted clients."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}