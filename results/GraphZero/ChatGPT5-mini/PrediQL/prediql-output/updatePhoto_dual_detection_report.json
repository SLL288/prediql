{
  "report_timestamp": "2025-09-23T21:00:04.314836",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.4,
    "simple_detections": 5,
    "llm_detections": 5,
    "consensus_breakdown": {
      "no_vulnerabilities": 5,
      "both_detected": 5
    },
    "detection_ratio": 1.0,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 4,
      "llm_potential_detections": 0,
      "potential_consensus_breakdown": {
        "no_potential": 6,
        "simple_potential_only": 4
      },
      "potential_detection_ratio": 0.0
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-09-23T20:58:05.747952",
      "node_name": "updatePhoto_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "' OR '1'='1",
            "url": "https://example.com/photos/1.jpg"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:58:20.064765",
      "node_name": "updatePhoto_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "<script>alert('xss')</script>",
            "url": "https://example.com/photos/1.jpg"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response for updatePhoto returns the title field containing raw script tags: \"<script>alert('xss')</script>\". This indicates the API is returning unsanitized HTML/JavaScript content. If a client application inserts this value into a web page DOM without proper escaping or sanitization, it would result in a reflected/stored XSS vulnerability. The API should validate or encode HTML input on accept and/or ensure clients encode output before insertion into HTML contexts to prevent script execution.",
            "evidence": "\"title\": \"<script>alert('xss')</script>\"",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "\"title\": \"<script>alert('xss')</script>\"",
              "explanation": "The GraphQL response for updatePhoto returns the title field containing raw script tags: \"<script>alert('xss')</script>\". This indicates the API is returning unsanitized HTML/JavaScript content. If a client application inserts this value into a web page DOM without proper escaping or sanitization, it would result in a reflected/stored XSS vulnerability. The API should validate or encode HTML input on accept and/or ensure clients encode output before insertion into HTML contexts to prevent script execution."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:58:35.795914",
      "node_name": "updatePhoto_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "Profile",
            "url": "http://169.254.169.254/latest/meta-data/iam/security-credentials/"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response for updatePhoto contains a URL pointing to 169.254.169.254, the well-known AWS instance metadata service (IMDS) path for IAM credentials. This strongly indicates that the application accepted and persisted (and likely processed/fetched) a URL that targets an internal-only address. If the application performs server-side requests to user-supplied URLs (common for image-fetching endpoints), an attacker can abuse this to make the server request internal resources (SSRF), potentially retrieving sensitive metadata/credentials. Impact is high because access to IMDS can disclose AWS IAM credentials. Confidence is not absolute because the response could alternatively reflect a user-supplied value that was merely stored/echoed without the server performing a fetch; therefore further active testing is recommended (e.g., submit controlled internal URLs and observe whether the server makes requests or returns fetched content). Mitigations: whitelist allowed hosts/protocols, validate/normalize URLs, block access to 169.254.0.0/16 and other internal ranges from server-side requests, enforce egress controls and metadata service protections (IMDSv2).",
            "evidence": "\"url\": \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"",
            "confidence": 0.7,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "HIGH",
              "confidence": 0.7,
              "evidence": "\"url\": \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"",
              "explanation": "The GraphQL response for updatePhoto contains a URL pointing to 169.254.169.254, the well-known AWS instance metadata service (IMDS) path for IAM credentials. This strongly indicates that the application accepted and persisted (and likely processed/fetched) a URL that targets an internal-only address. If the application performs server-side requests to user-supplied URLs (common for image-fetching endpoints), an attacker can abuse this to make the server request internal resources (SSRF), potentially retrieving sensitive metadata/credentials. Impact is high because access to IMDS can disclose AWS IAM credentials. Confidence is not absolute because the response could alternatively reflect a user-supplied value that was merely stored/echoed without the server performing a fetch; therefore further active testing is recommended (e.g., submit controlled internal URLs and observe whether the server makes requests or returns fetched content). Mitigations: whitelist allowed hosts/protocols, validate/normalize URLs, block access to 169.254.0.0/16 and other internal ranges from server-side requests, enforce egress controls and metadata service protections (IMDSv2)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:58:47.484322",
      "node_name": "updatePhoto_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "test; cat /etc/passwd",
            "url": "https://example.com/photos/1.jpg"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:59:01.814044",
      "node_name": "updatePhoto_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "Backup",
            "thumbnailUrl": "../../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: path_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns a thumbnailUrl containing a directory traversal sequence that points to a sensitive OS file (/etc/passwd). The value \"../../../../../etc/passwd\" is a strong indicator that user-controllable input is being used to construct filesystem paths without proper validation or sanitization, allowing path traversal / path injection. If the server resolves or reads such paths, this can lead to arbitrary local file disclosure. Further testing should confirm whether the application actually reads the referenced file (e.g., by submitting controlled traversal payloads and observing file contents), but the presence of this exact traversal string in the API response is clear evidence of a path injection risk.",
            "evidence": "\"thumbnailUrl\": \"../../../../../etc/passwd\"",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "path_injection",
              "severity": "HIGH",
              "confidence": 0.85,
              "evidence": "\"thumbnailUrl\": \"../../../../../etc/passwd\"",
              "explanation": "The GraphQL response returns a thumbnailUrl containing a directory traversal sequence that points to a sensitive OS file (/etc/passwd). The value \"../../../../../etc/passwd\" is a strong indicator that user-controllable input is being used to construct filesystem paths without proper validation or sanitization, allowing path traversal / path injection. If the server resolves or reads such paths, this can lead to arbitrary local file disclosure. Further testing should confirm whether the application actually reads the referenced file (e.g., by submitting controlled traversal payloads and observing file contents), but the presence of this exact traversal string in the API response is clear evidence of a path injection risk."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:59:18.916309",
      "node_name": "updatePhoto_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "1",
            "title": "<div onclick=\"alert('xss')\">Click me</div>",
            "url": "https://example.com/photos/1.jpg"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns raw HTML markup in the 'title' field: <div onclick=\"alert('xss')\">Click me</div>. This is evidence of HTML content being stored and reflected by the API. If a client (web page or admin UI) inserts this value into the DOM without proper escaping or sanitization, the onclick attribute will execute JavaScript, leading to a cross-site scripting (XSS) attack via HTML injection. Impact is high because XSS can lead to session theft, account takeover, or arbitrary actions as the user. Recommended mitigations: validate/strip or encode HTML on input, treat this field as plain text and HTML-escape on output, apply a strict Content Security Policy, and use an allowlist sanitizer if rich text is required.",
            "evidence": "data.updatePhoto.title = \"<div onclick=\\\"alert('xss')\\\">Click me</div>\"",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.85,
              "evidence": "data.updatePhoto.title = \"<div onclick=\\\"alert('xss')\\\">Click me</div>\"",
              "explanation": "The GraphQL response returns raw HTML markup in the 'title' field: <div onclick=\"alert('xss')\">Click me</div>. This is evidence of HTML content being stored and reflected by the API. If a client (web page or admin UI) inserts this value into the DOM without proper escaping or sanitization, the onclick attribute will execute JavaScript, leading to a cross-site scripting (XSS) attack via HTML injection. Impact is high because XSS can lead to session theft, account takeover, or arbitrary actions as the user. Recommended mitigations: validate/strip or encode HTML on input, treat this field as plain text and HTML-escape on output, apply a strict Content Security Policy, and use an allowlist sanitizer if rich text is required."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:59:27.893465",
      "node_name": "updatePhoto_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:59:35.930657",
      "node_name": "updatePhoto_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T20:59:51.954924",
      "node_name": "updatePhoto_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updatePhoto\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-09-23T21:00:04.310333",
      "node_name": "updatePhoto_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"titel\" on type \"Photo\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"urll\" on type \"Photo\". Did you mean \"url\"?",
            "locations": [
              {
                "line": 6,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "safe",
            "category": "Unknown",
            "description": "The GraphQL error responses include automated 'Did you mean ...?' suggestions that reveal valid field names on the Photo type (e.g., 'title' and 'url'). This behavior discloses schema details to unauthenticated or unauthorized requesters, enabling an attacker to enumerate field names and better understand the API structure. While this does not directly expose sensitive data or execute commands, it is an information disclosure vulnerability that can aid further targeted attacks (e.g., more precise queries, discovery of sensitive fields). Recommended mitigation: disable or sanitize field suggestions in error messages in production, return generic validation errors, and implement rate-limiting and proper access controls on schema introspection.",
            "evidence": "Error messages: \"Cannot query field \\\"titel\\\" on type \\\"Photo\\\". Did you mean \\\"title\\\"?\" and \"Cannot query field \\\"urll\\\" on type \\\"Photo\\\". Did you mean \\\"url\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "LOW",
              "confidence": 0.95,
              "evidence": "Error messages: \"Cannot query field \\\"titel\\\" on type \\\"Photo\\\". Did you mean \\\"title\\\"?\" and \"Cannot query field \\\"urll\\\" on type \\\"Photo\\\". Did you mean \\\"url\\\"?\"",
              "explanation": "The GraphQL error responses include automated 'Did you mean ...?' suggestions that reveal valid field names on the Photo type (e.g., 'title' and 'url'). This behavior discloses schema details to unauthenticated or unauthorized requesters, enabling an attacker to enumerate field names and better understand the API structure. While this does not directly expose sensitive data or execute commands, it is an information disclosure vulnerability that can aid further targeted attacks (e.g., more precise queries, discovery of sensitive fields). Recommended mitigation: disable or sanitize field suggestions in error messages in production, return generic validation errors, and implement rate-limiting and proper access controls on schema introspection."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Unknown"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}