{
  "report_timestamp": "2025-10-06T03:12:54.444816",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.3,
    "simple_detections": 6,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 2,
      "both_detected": 4,
      "no_vulnerabilities": 4
    },
    "detection_ratio": 0.6666666666666666,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 5,
      "llm_potential_detections": 2,
      "potential_consensus_breakdown": {
        "simple_potential_only": 4,
        "no_potential": 4,
        "both_potential": 1,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 0.4
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-06T03:10:22.442487",
      "node_name": "updatePhoto_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "102",
            "title": "Nice photo'); DROP TABLE users; --",
            "url": "https://example.com/photos/102.jpg",
            "album": {
              "id": "3",
              "title": "omnis laborum odio"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:10:40.593950",
      "node_name": "updatePhoto_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "103",
            "title": "<script>alert('xss')</script>",
            "url": "https://example.com/photos/103.jpg",
            "album": {
              "id": "3",
              "title": "omnis laborum odio"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns the title field containing raw script tags: \"<script>alert('xss')</script>\". This indicates the backend is returning unsanitized/unsafely-encoded HTML/script content. If a client (web page or admin UI) renders this value into the DOM using innerHTML or otherwise injects it without proper output-encoding or sanitization, it will result in XSS (stored/reflected depending on persistence). I cannot confirm client-side rendering behavior from this response alone, so confidence is not absolute, but the presence of executable script in API output is a clear XSS risk. Recommended mitigations: validate/sanitize input on write, encode/escape output on render, apply a strict Content Security Policy, and enforce schema-level constraints that disallow HTML/script where not expected.",
            "evidence": "\"title\": \"<script>alert('xss')</script>\"",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "\"title\": \"<script>alert('xss')</script>\"",
              "explanation": "The GraphQL response returns the title field containing raw script tags: \"<script>alert('xss')</script>\". This indicates the backend is returning unsanitized/unsafely-encoded HTML/script content. If a client (web page or admin UI) renders this value into the DOM using innerHTML or otherwise injects it without proper output-encoding or sanitization, it will result in XSS (stored/reflected depending on persistence). I cannot confirm client-side rendering behavior from this response alone, so confidence is not absolute, but the presence of executable script in API output is a clear XSS risk. Recommended mitigations: validate/sanitize input on write, encode/escape output on render, apply a strict Content Security Policy, and enforce schema-level constraints that disallow HTML/script where not expected."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:11:01.472979",
      "node_name": "updatePhoto_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "104",
            "title": "Instance metadata probe",
            "url": "http://169.254.169.254/latest/meta-data/iam/security-credentials/",
            "album": {
              "id": "3",
              "title": "omnis laborum odio"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:11:14.332973",
      "node_name": "updatePhoto_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "105",
            "title": "image-`/bin/sh -c \"cat /etc/passwd\"`",
            "url": "https://example.com/photos/105.jpg",
            "album": {
              "id": "3",
              "title": "omnis laborum odio"
            }
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:11:36.498235",
      "node_name": "updatePhoto_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "106",
            "title": "Local file include test",
            "thumbnailUrl": "../../../../etc/passwd",
            "album": {
              "id": "3",
              "title": "omnis laborum odio"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: path_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL response for updatePhoto contains a directory-traversal style path (\"../../../../etc/passwd\") in the thumbnailUrl field. This indicates the API accepts and returns raw path-like input that includes '..' segments targeting /etc/passwd. While the response does not contain file contents, the presence of such payloads strongly suggests a path-manipulation/local-file-include vector: if the backend ever uses this field to resolve or fetch files from the filesystem without proper canonicalization and sanitization, an attacker could traverse directories and access sensitive files. Recommended next steps: verify whether the server uses thumbnailUrl to read files, attempt to retrieve file contents via crafted payloads, and remediate by canonicalizing paths, rejecting or normalizing '..' segments, enforcing allowlists and sandboxed directories, and avoiding exposing server-local filesystem paths in responses.",
            "evidence": "\"thumbnailUrl\": \"../../../../etc/passwd\"",
            "confidence": 0.6,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "path_injection",
              "severity": "MEDIUM",
              "confidence": 0.6,
              "evidence": "\"thumbnailUrl\": \"../../../../etc/passwd\"",
              "explanation": "The GraphQL response for updatePhoto contains a directory-traversal style path (\"../../../../etc/passwd\") in the thumbnailUrl field. This indicates the API accepts and returns raw path-like input that includes '..' segments targeting /etc/passwd. While the response does not contain file contents, the presence of such payloads strongly suggests a path-manipulation/local-file-include vector: if the backend ever uses this field to resolve or fetch files from the filesystem without proper canonicalization and sanitization, an attacker could traverse directories and access sensitive files. Recommended next steps: verify whether the server uses thumbnailUrl to read files, attempt to retrieve file contents via crafted payloads, and remediate by canonicalizing paths, rejecting or normalizing '..' segments, enforcing allowlists and sandboxed directories, and avoiding exposing server-local filesystem paths in responses."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:11:54.502077",
      "node_name": "updatePhoto_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updatePhoto": {
            "id": "107",
            "title": "<div onclick=\"alert('pwn')\">InjectedHTML</div>",
            "url": "https://example.com/photos/107.jpg",
            "album": {
              "id": "3",
              "title": "omnis laborum odio"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response for updatePhoto returns the title field containing raw HTML with an event handler: <div onclick=\"alert('pwn')\">InjectedHTML</div>. This is clear HTML injection. If a client application inserts this title into the DOM without proper escaping or sanitization, the onclick handler (or other injected markup) can execute, resulting in a client-side XSS vulnerability. Because this appears in the response to an update operation, it may represent a stored injection (data persisted and later rendered to users). Remediation: enforce input validation and/or strip or encode HTML on the server, apply context-appropriate output encoding on the client, and implement a Content Security Policy (CSP) to mitigate execution of injected scripts.",
            "evidence": "\"title\": \"<div onclick=\\\"alert('pwn')\\\">InjectedHTML</div>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"title\": \"<div onclick=\\\"alert('pwn')\\\">InjectedHTML</div>\"",
              "explanation": "The GraphQL response for updatePhoto returns the title field containing raw HTML with an event handler: <div onclick=\"alert('pwn')\">InjectedHTML</div>. This is clear HTML injection. If a client application inserts this title into the DOM without proper escaping or sanitization, the onclick handler (or other injected markup) can execute, resulting in a client-side XSS vulnerability. Because this appears in the response to an update operation, it may represent a stored injection (data persisted and later rendered to users). Remediation: enforce input validation and/or strip or encode HTML on the server, apply context-appropriate output encoding on the client, and implement a Content Security Policy (CSP) to mitigate execution of injected scripts."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:12:06.658705",
      "node_name": "updatePhoto_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:12:17.372600",
      "node_name": "updatePhoto_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:12:35.689546",
      "node_name": "updatePhoto_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updatePhoto\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T03:12:54.443212",
      "node_name": "updatePhoto_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Field \"titel\" is not defined by type \"UpdatePhotoInput\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 3,
                "column": 35
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"titel\" on type \"Photo\". Did you mean \"title\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL error responses include explicit field-name suggestions (\"Did you mean 'title'?\"), which leak schema metadata by revealing valid field names/types. This is a field_suggestions information-disclosure issue: an attacker can use such suggestions to enumerate the schema and discover valid fields/inputs, facilitating targeted queries or further exploitation. While this does not directly expose sensitive data, it lowers the effort required for reconnaissance and can enable more serious attacks.\n\nRecommended mitigations: disable or suppress suggestion/hint text in production error messages (do not return detailed validation hints), run the server with debug features off, return generic error messages for client-facing responses, and apply proper access controls/authorization on schema fields. Consider restricting GraphQL introspection in production if appropriate.",
            "evidence": "Error messages: \"Field \\\"titel\\\" is not defined by type \\\"UpdatePhotoInput\\\". Did you mean \\\"title\\\"?\" and \"Cannot query field \\\"titel\\\" on type \\\"Photo\\\". Did you mean \\\"title\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "Error messages: \"Field \\\"titel\\\" is not defined by type \\\"UpdatePhotoInput\\\". Did you mean \\\"title\\\"?\" and \"Cannot query field \\\"titel\\\" on type \\\"Photo\\\". Did you mean \\\"title\\\"?\"",
              "explanation": "The GraphQL error responses include explicit field-name suggestions (\"Did you mean 'title'?\"), which leak schema metadata by revealing valid field names/types. This is a field_suggestions information-disclosure issue: an attacker can use such suggestions to enumerate the schema and discover valid fields/inputs, facilitating targeted queries or further exploitation. While this does not directly expose sensitive data, it lowers the effort required for reconnaissance and can enable more serious attacks.\n\nRecommended mitigations: disable or suppress suggestion/hint text in production error messages (do not return detailed validation hints), run the server with debug features off, return generic error messages for client-facing responses, and apply proper access controls/authorization on schema fields. Consider restricting GraphQL introspection in production if appropriate."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}