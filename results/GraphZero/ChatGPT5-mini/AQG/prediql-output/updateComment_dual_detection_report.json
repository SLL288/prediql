{
  "report_timestamp": "2025-10-06T02:10:52.745719",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.2,
    "simple_detections": 6,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 3,
      "both_detected": 3,
      "no_vulnerabilities": 3,
      "llm_only": 1
    },
    "detection_ratio": 0.6666666666666666,
    "potential_analysis": {
      "potential_agreement_rate": 0.0,
      "simple_potential_detections": 5,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 5,
        "no_potential": 4,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 0.2
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-06T02:09:08.747297",
      "node_name": "updateComment_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "2",
            "name": "Robert'); DROP TABLE comments; --",
            "email": "robert@example.com",
            "body": "Nice post"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:09:21.590520",
      "node_name": "updateComment_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "3",
            "name": "Mallory",
            "email": "mallory@example.com",
            "body": "<script>alert('xss')</script>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL mutation response contains an unescaped <script> tag in the 'body' field: the API echoed back \"<script>alert('xss')</script>\". This indicates the server accepted and returned raw HTML/JS content (likely stored or reflected) without sanitization or escaping. If a client (web application) inserts this 'body' value into the DOM using innerHTML or otherwise renders it as HTML, it would execute the script and result in a cross-site scripting vulnerability. Exploitability depends on how the client consumes this field, but the presence of raw script tags in the API response is clear evidence of an XSS injection risk. Recommended mitigations: validate and sanitize input server-side, HTML-escape output, and apply a content security policy (CSP) on the client.",
            "evidence": "\"body\": \"<script>alert('xss')</script>\"",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.85,
              "evidence": "\"body\": \"<script>alert('xss')</script>\"",
              "explanation": "The GraphQL mutation response contains an unescaped <script> tag in the 'body' field: the API echoed back \"<script>alert('xss')</script>\". This indicates the server accepted and returned raw HTML/JS content (likely stored or reflected) without sanitization or escaping. If a client (web application) inserts this 'body' value into the DOM using innerHTML or otherwise renders it as HTML, it would execute the script and result in a cross-site scripting vulnerability. Exploitability depends on how the client consumes this field, but the presence of raw script tags in the API response is clear evidence of an XSS injection risk. Recommended mitigations: validate and sanitize input server-side, HTML-escape output, and apply a content security policy (CSP) on the client."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:09:34.602665",
      "node_name": "updateComment_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "4",
            "name": "Scanner",
            "email": "scanner@example.com",
            "body": "http://169.254.169.254/latest/meta-data/iam/security-credentials/"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:09:48.447662",
      "node_name": "updateComment_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "5",
            "name": "Operator",
            "email": "ops@example.com",
            "body": "test; cat /etc/passwd; #"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:10:00.387645",
      "node_name": "updateComment_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "6",
            "name": "PathTester",
            "email": "path@example.com",
            "body": "../../../../etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:10:12.537482",
      "node_name": "updateComment_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateComment": {
            "id": "7",
            "name": "Designer",
            "email": "design@example.com",
            "body": "<div onclick=\"alert(1)\">Click me</div>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains unescaped HTML in the 'body' field including an inline event handler (onclick=\"alert(1)\"). If this value is rendered into a web page without proper sanitization or encoding, the HTML and JavaScript can execute in users' browsers (classic HTML injection / stored XSS scenario). The operation name (updateComment) suggests this content may be user-controlled and stored/reflected to other clients, increasing impact. Recommend treating user content as untrusted: perform output encoding, sanitize or strip dangerous HTML/attributes on input or before rendering, and adopt CSP to mitigate execution of injected scripts.",
            "evidence": "\"body\": \"<div onclick=\\\"alert(1)\\\">Click me</div>\"",
            "confidence": 0.8,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.8,
              "evidence": "\"body\": \"<div onclick=\\\"alert(1)\\\">Click me</div>\"",
              "explanation": "The GraphQL response contains unescaped HTML in the 'body' field including an inline event handler (onclick=\"alert(1)\"). If this value is rendered into a web page without proper sanitization or encoding, the HTML and JavaScript can execute in users' browsers (classic HTML injection / stored XSS scenario). The operation name (updateComment) suggests this content may be user-controlled and stored/reflected to other clients, increasing impact. Recommend treating user content as untrusted: perform output encoding, sanitize or strip dangerous HTML/attributes on input or before rendering, and adopt CSP to mitigate execution of injected scripts."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:10:20.924101",
      "node_name": "updateComment_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:10:30.161257",
      "node_name": "updateComment_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:10:40.018012",
      "node_name": "updateComment_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updateComment\" on type \"Query\". Did you mean \"comment\"?",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: Introspection",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL server returns a validation error that includes a suggested field name from the schema (\"Did you mean 'comment'?\"). This reveals internal schema information (available field names) to an unauthenticated requester, which is a form of schema introspection/information disclosure. While this is not a full introspection query response, the error-based disclosure can aid attackers in enumerating schema fields and crafting targeted queries. The issue is lower severity because no actual data is returned, but it still weakens security posture by exposing schema details. Recommend suppressing detailed schema hints in error messages or restricting introspection and verbose errors in production.",
            "evidence": "Error message: \"Cannot query field \\\"updateComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\" with code \"GRAPHQL_VALIDATION_FAILED\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "Introspection",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "Error message: \"Cannot query field \\\"updateComment\\\" on type \\\"Query\\\". Did you mean \\\"comment\\\"?\" with code \"GRAPHQL_VALIDATION_FAILED\"",
              "explanation": "The GraphQL server returns a validation error that includes a suggested field name from the schema (\"Did you mean 'comment'?\"). This reveals internal schema information (available field names) to an unauthenticated requester, which is a form of schema introspection/information disclosure. While this is not a full introspection query response, the error-based disclosure can aid attackers in enumerating schema fields and crafting targeted queries. The issue is lower severity because no actual data is returned, but it still weakens security posture by exposing schema details. Recommend suppressing detailed schema hints in error messages or restricting introspection and verbose errors in production."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T02:10:52.743812",
      "node_name": "updateComment_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"emial\" on type \"Comment\". Did you mean \"email\"?",
            "locations": [
              {
                "line": 5,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"boddy\" on type \"Comment\". Did you mean \"body\"?",
            "locations": [
              {
                "line": 6,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL response returns 'Did you mean' suggestions for misspelled fields, explicitly revealing valid field names on the Comment type (email, body). This is a field_suggestions information disclosure vulnerability: it leaks schema details that can be used to enumerate fields and map the API more easily, which can aid targeted attacks or data discovery. Mitigation: disable or sanitize suggestion output in errors (avoid returning 'Did you mean' hints to unauthenticated/low-privilege clients), turn off verbose/debug error messages in production, and implement error masking or a custom error formatter to return generic validation errors. Additionally, apply proper authentication, authorization, and rate limiting to reduce misuse.",
            "evidence": "errors[0].message: \"Cannot query field \\\"emial\\\" on type \\\"Comment\\\". Did you mean \\\"email\\\"?\"; errors[1].message: \"Cannot query field \\\"boddy\\\" on type \\\"Comment\\\". Did you mean \\\"body\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "errors[0].message: \"Cannot query field \\\"emial\\\" on type \\\"Comment\\\". Did you mean \\\"email\\\"?\"; errors[1].message: \"Cannot query field \\\"boddy\\\" on type \\\"Comment\\\". Did you mean \\\"body\\\"?\"",
              "explanation": "The GraphQL response returns 'Did you mean' suggestions for misspelled fields, explicitly revealing valid field names on the Comment type (email, body). This is a field_suggestions information disclosure vulnerability: it leaks schema details that can be used to enumerate fields and map the API more easily, which can aid targeted attacks or data discovery. Mitigation: disable or sanitize suggestion output in errors (avoid returning 'Did you mean' hints to unauthenticated/low-privilege clients), turn off verbose/debug error messages in production, and implement error masking or a custom error formatter to return generic validation errors. Additionally, apply proper authentication, authorization, and rate limiting to reduce misuse."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}