{
  "report_timestamp": "2025-10-06T06:00:18.234079",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.3,
    "simple_detections": 6,
    "llm_detections": 4,
    "consensus_breakdown": {
      "simple_only": 2,
      "both_detected": 4,
      "no_vulnerabilities": 4
    },
    "detection_ratio": 0.6666666666666666,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 5,
      "llm_potential_detections": 2,
      "potential_consensus_breakdown": {
        "simple_potential_only": 4,
        "no_potential": 4,
        "both_potential": 1,
        "llm_potential_only": 1
      },
      "potential_detection_ratio": 0.4
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-06T05:58:28.420369",
      "node_name": "createUser_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "username": "robert'); DROP TABLE users; --",
            "email": "sqlvictim@example.com"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T05:58:37.880000",
      "node_name": "createUser_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "name": "<script>alert('xss')</script>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains an unescaped script tag in the 'name' field. This indicates the API is reflecting (and likely storing) raw HTML/JS provided by the client. If a web application renders this 'name' value into a page without proper encoding or sanitization, it will execute arbitrary JavaScript in users' browsers (reflected or stored XSS). Recommended mitigations: output-encode/escape data when inserting into HTML contexts, validate and sanitize input on the server, apply a strict Content Security Policy, and enforce schema-level constraints (e.g., reject HTML/script characters) where appropriate.",
            "evidence": "\"name\": \"<script>alert('xss')</script>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "\"name\": \"<script>alert('xss')</script>\"",
              "explanation": "The GraphQL response contains an unescaped script tag in the 'name' field. This indicates the API is reflecting (and likely storing) raw HTML/JS provided by the client. If a web application renders this 'name' value into a page without proper encoding or sanitization, it will execute arbitrary JavaScript in users' browsers (reflected or stored XSS). Recommended mitigations: output-encode/escape data when inserting into HTML contexts, validate and sanitize input on the server, apply a strict Content Security Policy, and enforce schema-level constraints (e.g., reject HTML/script characters) where appropriate."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T05:58:59.471930",
      "node_name": "createUser_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "website": "http://169.254.169.254/latest/meta-data/iam/security-credentials/",
            "phone": "http://127.0.0.1:8080/health"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T05:59:09.906666",
      "node_name": "createUser_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "phone": "127.0.0.1; cat /etc/passwd"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T05:59:24.089995",
      "node_name": "createUser_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "address": {
              "suite": "../../../../etc/passwd",
              "street": "/var/www/html"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: path_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL response reflects user/address fields containing directory-traversal sequences (\"../../../../etc/passwd\") and an absolute filesystem path (\"/var/www/html\"). This indicates that path-like input is accepted and stored/returned by the API without obvious sanitization or normalization. If those fields are later used by server-side file operations (read/write/include), an attacker could exploit them to traverse directories or access sensitive files. There is no direct proof of file reads/execution in the response, so the issue is not confirmed; however the reflected traversal payload is a strong indicator of potential path injection vulnerability. Recommended next steps: attempt controlled requests that reference known sensitive files, test server behavior when such paths are used in file operations, and verify server-side validation, canonicalization, and use of whitelists to mitigate any file path usage.",
            "evidence": "Response contains address.suite = \"../../../../etc/passwd\" and address.street = \"/var/www/html\"",
            "confidence": 0.6,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "path_injection",
              "severity": "MEDIUM",
              "confidence": 0.6,
              "evidence": "Response contains address.suite = \"../../../../etc/passwd\" and address.street = \"/var/www/html\"",
              "explanation": "The GraphQL response reflects user/address fields containing directory-traversal sequences (\"../../../../etc/passwd\") and an absolute filesystem path (\"/var/www/html\"). This indicates that path-like input is accepted and stored/returned by the API without obvious sanitization or normalization. If those fields are later used by server-side file operations (read/write/include), an attacker could exploit them to traverse directories or access sensitive files. There is no direct proof of file reads/execution in the response, so the issue is not confirmed; however the reflected traversal payload is a strong indicator of potential path injection vulnerability. Recommended next steps: attempt controlled requests that reference known sensitive files, test server behavior when such paths are used in file operations, and verify server-side validation, canonicalization, and use of whitelists to mitigate any file path usage."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T05:59:36.829200",
      "node_name": "createUser_response_7",
      "response_status": 200,
      "response_body": {
        "data": {
          "createUser": {
            "id": "11",
            "name": "<div onclick='alert(1)'>Click me</div>"
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns the user 'name' field containing raw HTML with an inline event handler: <div onclick='alert(1)'>Click me</div>. This is clear evidence of HTML being stored/returned unsanitized. If any client renders this value into the DOM as HTML (for example via innerHTML, dangerouslySetInnerHTML, or similar), the inline JavaScript (onclick) will execute, causing a cross-site scripting (XSS) / HTML injection vulnerability. We cannot confirm from this response whether the frontend sanitizes or encodes the value before rendering, but the presence of executable markup in server responses is a dangerous indicator and should be treated as a vulnerability. Recommend treating all user-controlled fields as untrusted: perform server-side input validation/sanitization, encode output for HTML context (escape special characters), avoid inserting raw HTML into the DOM, or use a robust HTML sanitizer / Content Security Policy to mitigate execution.",
            "evidence": "\"name\": \"<div onclick='alert(1)'>Click me</div>\"",
            "confidence": 0.85,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.85,
              "evidence": "\"name\": \"<div onclick='alert(1)'>Click me</div>\"",
              "explanation": "The GraphQL response returns the user 'name' field containing raw HTML with an inline event handler: <div onclick='alert(1)'>Click me</div>. This is clear evidence of HTML being stored/returned unsanitized. If any client renders this value into the DOM as HTML (for example via innerHTML, dangerouslySetInnerHTML, or similar), the inline JavaScript (onclick) will execute, causing a cross-site scripting (XSS) / HTML injection vulnerability. We cannot confirm from this response whether the frontend sanitizes or encodes the value before rendering, but the presence of executable markup in server responses is a dangerous indicator and should be treated as a vulnerability. Recommend treating all user-controlled fields as untrusted: perform server-side input validation/sanitization, encode output for HTML context (escape special characters), avoid inserting raw HTML into the DOM, or use a robust HTML sanitizer / Content Security Policy to mitigate execution."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T05:59:47.774990",
      "node_name": "createUser_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T05:59:55.678575",
      "node_name": "createUser_response_9",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:00:09.249716",
      "node_name": "createUser_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"createUser\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:00:18.233091",
      "node_name": "createUser_response_11",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"nam\" on type \"User\". Did you mean \"name\"?",
            "locations": [
              {
                "line": 9,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"emal\" on type \"User\". Did you mean \"email\"?",
            "locations": [
              {
                "line": 10,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          },
          {
            "message": "Cannot query field \"usernme\" on type \"User\". Did you mean \"username\"?",
            "locations": [
              {
                "line": 11,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "potential",
            "category": "Unknown",
            "description": "The GraphQL API returns validation errors that explicitly suggest correct field names when a client queries non-existent fields. These \"Did you mean \\\"...\\\"?\" suggestions reveal parts of the schema (e.g., field names: name, email, username), which constitutes information disclosure (field_suggestions vulnerability). An attacker can use this behavior to enumerate schema details, discover available fields, and tailor queries for further probing or data exfiltration. While this does not itself indicate data has been leaked, it reduces the difficulty of deeper attacks and should be mitigated (e.g., disable suggestion output or return generic validation errors).",
            "evidence": "Error messages: \"Cannot query field \\\"nam\\\" on type \\\"User\\\". Did you mean \\\"name\\\"?\", \"Cannot query field \\\"emal\\\" on type \\\"User\\\". Did you mean \\\"email\\\"?\", \"Cannot query field \\\"usernme\\\" on type \\\"User\\\". Did you mean \\\"username\\\"?\"",
            "confidence": 0.95,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "MEDIUM",
              "confidence": 0.95,
              "evidence": "Error messages: \"Cannot query field \\\"nam\\\" on type \\\"User\\\". Did you mean \\\"name\\\"?\", \"Cannot query field \\\"emal\\\" on type \\\"User\\\". Did you mean \\\"email\\\"?\", \"Cannot query field \\\"usernme\\\" on type \\\"User\\\". Did you mean \\\"username\\\"?\"",
              "explanation": "The GraphQL API returns validation errors that explicitly suggest correct field names when a client queries non-existent fields. These \"Did you mean \\\"...\\\"?\" suggestions reveal parts of the schema (e.g., field names: name, email, username), which constitutes information disclosure (field_suggestions vulnerability). An attacker can use this behavior to enumerate schema details, discover available fields, and tailor queries for further probing or data exfiltration. While this does not itself indicate data has been leaked, it reduces the difficulty of deeper attacks and should be mitigated (e.g., disable suggestion output or return generic validation errors)."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Unknown"
        ],
        "potential_categories": [
          "Unknown"
        ]
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Unknown"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [
            "Unknown"
          ],
          "potential_agreement_score": 0.0,
          "potential_consensus": "llm_potential_only"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}