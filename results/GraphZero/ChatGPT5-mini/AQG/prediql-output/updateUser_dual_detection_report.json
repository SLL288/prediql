{
  "report_timestamp": "2025-10-06T06:04:18.260068",
  "api_url": "https://graphqlzero.almansi.me/api",
  "summary": {
    "total_comparisons": 10,
    "agreement_rate": 0.4,
    "simple_detections": 6,
    "llm_detections": 6,
    "consensus_breakdown": {
      "simple_only": 1,
      "both_detected": 5,
      "no_vulnerabilities": 3,
      "llm_only": 1
    },
    "detection_ratio": 1.0,
    "potential_analysis": {
      "potential_agreement_rate": 0.1,
      "simple_potential_detections": 5,
      "llm_potential_detections": 1,
      "potential_consensus_breakdown": {
        "simple_potential_only": 4,
        "no_potential": 5,
        "both_potential": 1
      },
      "potential_detection_ratio": 0.2
    }
  },
  "detailed_comparisons": [
    {
      "timestamp": "2025-10-06T06:02:11.046258",
      "node_name": "updateUser_response_1",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "3",
            "name": "Robert'); DROP TABLE users; --",
            "username": "admin' OR '1'='1",
            "email": "sql-injector@example.com",
            "address": {
              "city": "McKenziehaven",
              "zipcode": "59590-4157"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "SQL Injection (SQLi) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SQL injection vulnerability detected - malicious SQL patterns found in response",
            "evidence": "Response status: 200, SQL patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Injection Attacks"
        ],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "simple_only",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:02:26.123285",
      "node_name": "updateUser_response_2",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "4",
            "name": "<script>alert(\"xss\")</script>",
            "company": {
              "catchPhrase": "<img src=x onerror=alert(1)>"
            },
            "address": {
              "street": "Hoeger Mall"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Cross-Site Scripting (XSS) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "XSS injection vulnerability detected - malicious script patterns found in response",
            "evidence": "Response status: 200, XSS patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: xss_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response returns user-controllable fields containing un-escaped HTML and JavaScript (a <script> tag in 'name' and an <img onerror> payload in 'company.catchPhrase'). If a web client takes these values and inserts them into the DOM without proper output encoding/escaping (for example via innerHTML or unsafe templating), these payloads will execute in victims' browsers, leading to XSS. This is a clear reflected/stored XSS risk depending on how the data is saved and reused. Recommended mitigations: ensure server-side and client-side output encoding (HTML-encode values before inserting into the DOM), sanitize or strip dangerous tags/attributes on input or output, prefer safe DOM APIs (textContent, innerText) rather than innerHTML, and deploy a strong Content Security Policy (CSP) as a defense-in-depth measure.",
            "evidence": "Response fields contain raw HTML/JS: name = \"<script>alert(\\\"xss\\\")</script>\", company.catchPhrase = \"<img src=x onerror=alert(1)>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "xss_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "Response fields contain raw HTML/JS: name = \"<script>alert(\\\"xss\\\")</script>\", company.catchPhrase = \"<img src=x onerror=alert(1)>\"",
              "explanation": "The GraphQL response returns user-controllable fields containing un-escaped HTML and JavaScript (a <script> tag in 'name' and an <img onerror> payload in 'company.catchPhrase'). If a web client takes these values and inserts them into the DOM without proper output encoding/escaping (for example via innerHTML or unsafe templating), these payloads will execute in victims' browsers, leading to XSS. This is a clear reflected/stored XSS risk depending on how the data is saved and reused. Recommended mitigations: ensure server-side and client-side output encoding (HTML-encode values before inserting into the DOM), sanitize or strip dangerous tags/attributes on input or output, prefer safe DOM APIs (textContent, innerText) rather than innerHTML, and deploy a strong Content Security Policy (CSP) as a defense-in-depth measure."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:02:50.332282",
      "node_name": "updateUser_response_3",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "5",
            "website": "http://169.254.169.254/latest/meta-data/iam/security-credentials/",
            "address": {
              "street": "1 SSRF Way",
              "city": "Localhost"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Server-Side Request Forgery (SSRF) Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "SSRF injection vulnerability detected - internal network access patterns found",
            "evidence": "Response status: 200, SSRF keywords detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: ssrf_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL updateUser response contains the internal AWS metadata service URL (169.254.169.254) in the website field. This is a strong indicator that the application accepted an attacker-controlled URL pointing to an internal-only address — a common SSRF vector. Access to the EC2 metadata endpoint can allow retrieval of instance IAM credentials and other sensitive data, which is high impact. Although the response shows the URL rather than returned metadata (so it could be a reflected/stored value), the presence of a private metadata endpoint URL in a field that likely accepts/follows URLs suggests SSRF risk. Recommend active verification: provide a controllable URL (e.g., a web service you control) to confirm the server performs outbound requests, attempt to retrieve known metadata paths and observe whether the server fetches/returns their content, and implement server-side allowlisting/validation, network egress restrictions, and request timeouts to mitigate SSRF.",
            "evidence": "response.data.updateUser.website = \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"",
            "confidence": 0.75,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "ssrf_injection",
              "severity": "HIGH",
              "confidence": 0.75,
              "evidence": "response.data.updateUser.website = \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"",
              "explanation": "The GraphQL updateUser response contains the internal AWS metadata service URL (169.254.169.254) in the website field. This is a strong indicator that the application accepted an attacker-controlled URL pointing to an internal-only address — a common SSRF vector. Access to the EC2 metadata endpoint can allow retrieval of instance IAM credentials and other sensitive data, which is high impact. Although the response shows the URL rather than returned metadata (so it could be a reflected/stored value), the presence of a private metadata endpoint URL in a field that likely accepts/follows URLs suggests SSRF risk. Recommend active verification: provide a controllable URL (e.g., a web service you control) to confirm the server performs outbound requests, attempt to retrieve known metadata paths and observe whether the server fetches/returns their content, and implement server-side allowlisting/validation, network egress restrictions, and request timeouts to mitigate SSRF."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:03:00.840844",
      "node_name": "updateUser_response_4",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "6",
            "name": "cmd; cat /etc/passwd",
            "username": "shell; ls -la /"
          }
        }
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:03:17.822209",
      "node_name": "updateUser_response_5",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "7",
            "name": "PathTraversalTester",
            "address": {
              "suite": "../../../../etc/passwd",
              "street": "/var/www/../../../etc/passwd"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Path Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "Path injection vulnerability detected - file system access patterns found",
            "evidence": "Response status: 200, Path injection patterns detected in response"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: path_injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "The GraphQL updateUser response echoes values that contain directory-traversal sequences (e.g. '../../../.. /etc/passwd'). While the response does not show file contents or explicit file access errors, the presence and acceptance of these traversal-style paths in address fields indicates the API accepts path-like input and may be vulnerable to path injection/directory traversal if those values are later used in filesystem operations without proper sanitization. This is a likely security issue because an attacker could craft similar inputs to manipulate file paths and potentially read or overwrite sensitive files. Recommended next steps: attempt to use the API (or other endpoints that consume these fields) to retrieve actual file contents or trigger file operations, check server-side handling/escaping of path inputs, and implement validation/whitelisting or canonicalization to prevent traversal sequences.",
            "evidence": "Response contains directory-traversal patterns in returned fields: address.suite = \"../../../../etc/passwd\", address.street = \"/var/www/../../../etc/passwd\"",
            "confidence": 0.6,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "path_injection",
              "severity": "MEDIUM",
              "confidence": 0.6,
              "evidence": "Response contains directory-traversal patterns in returned fields: address.suite = \"../../../../etc/passwd\", address.street = \"/var/www/../../../etc/passwd\"",
              "explanation": "The GraphQL updateUser response echoes values that contain directory-traversal sequences (e.g. '../../../.. /etc/passwd'). While the response does not show file contents or explicit file access errors, the presence and acceptance of these traversal-style paths in address fields indicates the API accepts path-like input and may be vulnerable to path injection/directory traversal if those values are later used in filesystem operations without proper sanitization. This is a likely security issue because an attacker could craft similar inputs to manipulate file paths and potentially read or overwrite sensitive files. Recommended next steps: attempt to use the API (or other endpoints that consume these fields) to retrieve actual file contents or trigger file operations, check server-side handling/escaping of path inputs, and implement validation/whitelisting or canonicalization to prevent traversal sequences."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [
            "Injection Attacks"
          ],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 1.0,
          "potential_consensus": "both_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:03:32.946445",
      "node_name": "updateUser_response_6",
      "response_status": 200,
      "response_body": {
        "data": {
          "updateUser": {
            "id": "8",
            "name": "<div onclick=\"alert('xss')\">Click me</div>",
            "company": {
              "name": "<b>BoldCorp</b>",
              "catchPhrase": "<i>Italic</i>"
            }
          }
        }
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "HTML Injection",
            "detection": "potential",
            "category": "Injection Attacks",
            "description": "HTML injection vulnerability detected - HTML markup found in response",
            "evidence": "Response status: 200, HTML patterns detected in response data"
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 1,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": [
          "Injection Attacks"
        ]
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: html_injection",
            "detection": "vulnerable",
            "category": "Injection Attacks",
            "description": "The GraphQL response contains raw HTML markup and an inline event handler in user-controlled fields. The name field returns \"<div onclick=\\\"alert('xss')\\\">Click me</div>\", which includes an active onclick attribute (JavaScript). If a client application inserts these values into the DOM without proper encoding/sanitization (for example using innerHTML), this will result in execution of attacker-supplied script (stored/reflected XSS). The presence of simple markup (<b>, <i>) indicates the API returns unescaped HTML generally, increasing risk. Recommended mitigations: treat these fields as data, not markup — escape/HTML-encode values before rendering, or sanitize server-side to strip dangerous tags/attributes, enforce a strict Content Security Policy, and validate/normalize input on write operations so stored content cannot include executable attributes.",
            "evidence": "data.updateUser.name = \"<div onclick=\\\"alert('xss')\\\">Click me</div>\", data.updateUser.company.name = \"<b>BoldCorp</b>\", data.updateUser.company.catchPhrase = \"<i>Italic</i>\"",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "html_injection",
              "severity": "HIGH",
              "confidence": 0.9,
              "evidence": "data.updateUser.name = \"<div onclick=\\\"alert('xss')\\\">Click me</div>\", data.updateUser.company.name = \"<b>BoldCorp</b>\", data.updateUser.company.catchPhrase = \"<i>Italic</i>\"",
              "explanation": "The GraphQL response contains raw HTML markup and an inline event handler in user-controlled fields. The name field returns \"<div onclick=\\\"alert('xss')\\\">Click me</div>\", which includes an active onclick attribute (JavaScript). If a client application inserts these values into the DOM without proper encoding/sanitization (for example using innerHTML), this will result in execution of attacker-supplied script (stored/reflected XSS). The presence of simple markup (<b>, <i>) indicates the API returns unescaped HTML generally, increasing risk. Recommended mitigations: treat these fields as data, not markup — escape/HTML-encode values before rendering, or sanitize server-side to strip dangerous tags/attributes, enforce a strict Content Security Policy, and validate/normalize input on write operations so stored content cannot include executable attributes."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [
          "Injection Attacks"
        ],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 1.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [
            "Injection Attacks"
          ],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [
            "Injection Attacks"
          ],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "simple_potential_only"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:03:41.012843",
      "node_name": "updateUser_response_7",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:03:49.275610",
      "node_name": "updateUser_response_8",
      "response_status": null,
      "response_body": null,
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [],
        "agreement_score": 0.0,
        "consensus": "no_vulnerabilities",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:04:06.696221",
      "node_name": "updateUser_response_9",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"updateUser\" on type \"Query\".",
            "locations": [
              {
                "line": 3,
                "column": 3
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [],
        "count": 0,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: introspection",
            "detection": "safe",
            "category": "Injection Attacks",
            "description": "The GraphQL endpoint returns detailed validation errors that reveal schema information (type name 'Query' and that 'updateUser' is not a field on it). While this response is not a direct __schema introspection result, the verbose error discloses type/field details which can be used by an attacker to map the schema and craft further queries. This constitutes an information disclosure / introspection-related issue. It's not proof that the __schema introspection query is allowed, but it shows the API leaks schema structure via error messages. Recommended mitigations: suppress detailed GraphQL errors in production, disable or restrict introspection queries, and return generic error messages or codes instead of schema-specific text.",
            "evidence": "GraphQL error message: \"Cannot query field \\\"updateUser\\\" on type \\\"Query\\\".\"",
            "confidence": 0.6,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "introspection",
              "severity": "LOW",
              "confidence": 0.6,
              "evidence": "GraphQL error message: \"Cannot query field \\\"updateUser\\\" on type \\\"Query\\\".\"",
              "explanation": "The GraphQL endpoint returns detailed validation errors that reveal schema information (type name 'Query' and that 'updateUser' is not a field on it). While this response is not a direct __schema introspection result, the verbose error discloses type/field details which can be used by an attacker to map the schema and craft further queries. This constitutes an information disclosure / introspection-related issue. It's not proof that the __schema introspection query is allowed, but it shows the API leaks schema structure via error messages. Recommended mitigations: suppress detailed GraphQL errors in production, disable or restrict introspection queries, and return generic error messages or codes instead of schema-specific text."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Injection Attacks"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Injection Attacks"
        ],
        "common_categories": [],
        "simple_unique_categories": [],
        "llm_unique_categories": [
          "Injection Attacks"
        ],
        "agreement_score": 0.0,
        "consensus": "llm_only",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    },
    {
      "timestamp": "2025-10-06T06:04:18.254722",
      "node_name": "updateUser_response_10",
      "response_status": 400,
      "response_body": {
        "errors": [
          {
            "message": "Cannot query field \"usrname\" on type \"User\". Did you mean \"username\" or \"name\"?",
            "locations": [
              {
                "line": 9,
                "column": 5
              }
            ],
            "extensions": {
              "code": "GRAPHQL_VALIDATION_FAILED"
            }
          }
        ]
      },
      "simple_detector": {
        "results": [
          {
            "detection_name": "Field Suggestions Enabled",
            "detection": "vulnerable",
            "category": "Information Disclosure",
            "description": "Field suggestions enabled - potential information disclosure",
            "evidence": "Found \"did you mean\" in error message - field suggestions are enabled"
          }
        ],
        "count": 1,
        "vulnerable_count": 1,
        "potential_count": 0,
        "safe_count": 0,
        "categories": [
          "Information Disclosure"
        ],
        "potential_categories": []
      },
      "llm_detector": {
        "results": [
          {
            "detection_name": "LLM: field_suggestions",
            "detection": "safe",
            "category": "Unknown",
            "description": "The GraphQL error response returns suggested field names ('username' and 'name') when an invalid field ('usrname') is queried. This behavior leaks schema information (valid field names) which can aid attackers in schema/field enumeration. While not a direct code-execution or data-leak vulnerability by itself, it discloses internal API structure and should be treated as information disclosure. Recommended mitigations: disable or sanitize suggestion messages in errors, return generic validation errors, and avoid exposing schema hints in production.",
            "evidence": "\"Cannot query field \\\"usrname\\\" on type \\\"User\\\". Did you mean \\\"username\\\" or \\\"name\\\"?\" (errors[0].message)",
            "confidence": 0.9,
            "llm_analysis": {
              "is_vulnerable": true,
              "vulnerability_type": "field_suggestions",
              "severity": "LOW",
              "confidence": 0.9,
              "evidence": "\"Cannot query field \\\"usrname\\\" on type \\\"User\\\". Did you mean \\\"username\\\" or \\\"name\\\"?\" (errors[0].message)",
              "explanation": "The GraphQL error response returns suggested field names ('username' and 'name') when an invalid field ('usrname') is queried. This behavior leaks schema information (valid field names) which can aid attackers in schema/field enumeration. While not a direct code-execution or data-leak vulnerability by itself, it discloses internal API structure and should be treated as information disclosure. Recommended mitigations: disable or sanitize suggestion messages in errors, return generic validation errors, and avoid exposing schema hints in production."
            }
          }
        ],
        "count": 1,
        "vulnerable_count": 0,
        "potential_count": 0,
        "safe_count": 1,
        "categories": [
          "Unknown"
        ],
        "potential_categories": []
      },
      "comparison": {
        "total_categories": [
          "Unknown",
          "Information Disclosure"
        ],
        "common_categories": [],
        "simple_unique_categories": [
          "Information Disclosure"
        ],
        "llm_unique_categories": [
          "Unknown"
        ],
        "agreement_score": 0.0,
        "consensus": "both_detected",
        "potential_analysis": {
          "total_potential_categories": [],
          "common_potential_categories": [],
          "simple_unique_potential_categories": [],
          "llm_unique_potential_categories": [],
          "potential_agreement_score": 0.0,
          "potential_consensus": "no_potential"
        }
      }
    }
  ],
  "detector_analysis": {
    "simple_detector": {
      "description": "Rule-based detector using predefined patterns",
      "strengths": [
        "Fast execution",
        "Consistent results",
        "Low resource usage"
      ],
      "weaknesses": [
        "Limited to known patterns",
        "May miss novel attacks",
        "False negatives possible"
      ]
    },
    "llm_detector": {
      "description": "AI-powered detector using language model analysis",
      "strengths": [
        "Contextual understanding",
        "Novel attack detection",
        "Detailed analysis"
      ],
      "weaknesses": [
        "Slower execution",
        "Resource intensive",
        "Potential false positives"
      ]
    }
  }
}