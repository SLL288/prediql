"""
Dual vulnerability detector that runs both the simple rule-based detector
and the LLM-based detector, then compares their results.
"""

import json
import csv
import os
from typing import Dict, List, Any, Tuple
from datetime import datetime

from simple_vulnerability_detector import SimpleVulnerabilityDetector
from simple_llm_detector import SimpleLLMDetector

class DualVulnerabilityDetector:
    """Dual vulnerability detector that runs both simple and LLM-based detection"""
    
    def __init__(self, api_url: str):
        self.api_url = api_url
        self.simple_detector = SimpleVulnerabilityDetector()
        self.llm_detector = SimpleLLMDetector()
        self.comparison_results = []
        
    def detect_vulnerabilities(self, response_data: Dict[str, Any], node_name: str) -> Dict[str, Any]:
        """
        Run both detectors on the response data and compare results
        
        Args:
            response_data: The GraphQL response data
            node_name: Name of the node being tested
            
        Returns:
            Dictionary containing results from both detectors and comparison
        """
        print(f"ðŸ” Running dual vulnerability detection on {node_name}...")
        
        # Run simple detector
        print("  ðŸ“Š Running simple rule-based detector...")
        simple_results = self.simple_detector.detect_vulnerabilities(response_data, node_name)
        
        # Run LLM detector
        print("  ðŸ¤– Running LLM-based detector...")
        llm_results = self.llm_detector.detect_vulnerabilities(response_data, node_name)
        
        # Compare results
        comparison = self._compare_detection_results(
            simple_results, 
            llm_results, 
            node_name, 
            response_data
        )
        
        # Store comparison results
        self.comparison_results.append(comparison)
        
        return comparison
    
    def _compare_detection_results(self, simple_results: List[Dict[str, Any]], 
                                 llm_results: List[Dict[str, Any]], 
                                 node_name: str, 
                                 response_data: Dict[str, Any]) -> Dict[str, Any]:
        """Compare results from both detectors"""
        
        # Count total detections
        simple_count = len(simple_results)
        llm_count = len(llm_results)
        
        # Separate by detection type
        simple_vulnerable = [r for r in simple_results if r['detection'] == 'vulnerable']
        simple_potential = [r for r in simple_results if r['detection'] == 'potential']
        simple_safe = [r for r in simple_results if r['detection'] == 'safe']
        
        llm_vulnerable = [r for r in llm_results if r['detection'] == 'vulnerable']
        llm_potential = [r for r in llm_results if r['detection'] == 'potential']
        llm_safe = [r for r in llm_results if r['detection'] == 'safe']
        
        # Count by detection type
        simple_vulnerable_count = len(simple_vulnerable)
        simple_potential_count = len(simple_potential)
        simple_safe_count = len(simple_safe)
        
        llm_vulnerable_count = len(llm_vulnerable)
        llm_potential_count = len(llm_potential)
        llm_safe_count = len(llm_safe)
        
        # Find common vulnerabilities (by category)
        simple_categories = set(r['category'] for r in simple_results)
        llm_categories = set(r['category'] for r in llm_results)
        common_categories = simple_categories.intersection(llm_categories)
        
        # Find common potential detections (by category)
        simple_potential_categories = set(r['category'] for r in simple_potential)
        llm_potential_categories = set(r['category'] for r in llm_potential)
        common_potential_categories = simple_potential_categories.intersection(llm_potential_categories)
        
        # Find unique to each detector
        simple_unique = simple_categories - llm_categories
        llm_unique = llm_categories - simple_categories
        
        # Find unique potential detections
        simple_unique_potential = simple_potential_categories - llm_potential_categories
        llm_unique_potential = llm_potential_categories - simple_potential_categories
        
        # Calculate agreement scores
        total_categories = simple_categories.union(llm_categories)
        agreement_score = len(common_categories) / len(total_categories) if total_categories else 0.0
        
        total_potential_categories = simple_potential_categories.union(llm_potential_categories)
        potential_agreement_score = len(common_potential_categories) / len(total_potential_categories) if total_potential_categories else 0.0
        
        # Determine consensus
        consensus = "agreement" if agreement_score > 0.5 else "disagreement"
        if simple_count == 0 and llm_count == 0:
            consensus = "no_vulnerabilities"
        elif simple_count > 0 and llm_count > 0:
            consensus = "both_detected"
        elif simple_count > 0:
            consensus = "simple_only"
        elif llm_count > 0:
            consensus = "llm_only"
        
        # Determine potential consensus
        potential_consensus = "agreement" if potential_agreement_score > 0.5 else "disagreement"
        if simple_potential_count == 0 and llm_potential_count == 0:
            potential_consensus = "no_potential"
        elif simple_potential_count > 0 and llm_potential_count > 0:
            potential_consensus = "both_potential"
        elif simple_potential_count > 0:
            potential_consensus = "simple_potential_only"
        elif llm_potential_count > 0:
            potential_consensus = "llm_potential_only"
        
        comparison = {
            'timestamp': datetime.now().isoformat(),
            'node_name': node_name,
            'response_status': response_data.get('response_status'),
            'response_body': response_data.get('response_body'),
            'simple_detector': {
                'results': simple_results,
                'count': simple_count,
                'vulnerable_count': simple_vulnerable_count,
                'potential_count': simple_potential_count,
                'safe_count': simple_safe_count,
                'categories': list(simple_categories),
                'potential_categories': list(simple_potential_categories)
            },
            'llm_detector': {
                'results': llm_results,
                'count': llm_count,
                'vulnerable_count': llm_vulnerable_count,
                'potential_count': llm_potential_count,
                'safe_count': llm_safe_count,
                'categories': list(llm_categories),
                'potential_categories': list(llm_potential_categories)
            },
            'comparison': {
                'total_categories': list(total_categories),
                'common_categories': list(common_categories),
                'simple_unique_categories': list(simple_unique),
                'llm_unique_categories': list(llm_unique),
                'agreement_score': agreement_score,
                'consensus': consensus,
                'potential_analysis': {
                    'total_potential_categories': list(total_potential_categories),
                    'common_potential_categories': list(common_potential_categories),
                    'simple_unique_potential_categories': list(simple_unique_potential),
                    'llm_unique_potential_categories': list(llm_unique_potential),
                    'potential_agreement_score': potential_agreement_score,
                    'potential_consensus': potential_consensus
                }
            }
        }
        
        return comparison
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """Get summary statistics comparing both detectors"""
        if not self.comparison_results:
            return {
                'total_comparisons': 0,
                'agreement_rate': 0.0,
                'simple_detections': 0,
                'llm_detections': 0,
                'consensus_breakdown': {},
                'potential_analysis': {
                    'potential_agreement_rate': 0.0,
                    'simple_potential_detections': 0,
                    'llm_potential_detections': 0,
                    'potential_consensus_breakdown': {}
                }
            }
        
        total_comparisons = len(self.comparison_results)
        agreement_scores = [r['comparison']['agreement_score'] for r in self.comparison_results]
        avg_agreement = sum(agreement_scores) / len(agreement_scores) if agreement_scores else 0.0
        
        simple_detections = sum(r['simple_detector']['count'] for r in self.comparison_results)
        llm_detections = sum(r['llm_detector']['count'] for r in self.comparison_results)
        
        # Potential detection statistics
        potential_agreement_scores = [r['comparison']['potential_analysis']['potential_agreement_score'] for r in self.comparison_results]
        avg_potential_agreement = sum(potential_agreement_scores) / len(potential_agreement_scores) if potential_agreement_scores else 0.0
        
        simple_potential_detections = sum(r['simple_detector']['potential_count'] for r in self.comparison_results)
        llm_potential_detections = sum(r['llm_detector']['potential_count'] for r in self.comparison_results)
        
        # Consensus breakdown
        consensus_counts = {}
        potential_consensus_counts = {}
        for result in self.comparison_results:
            consensus = result['comparison']['consensus']
            consensus_counts[consensus] = consensus_counts.get(consensus, 0) + 1
            
            potential_consensus = result['comparison']['potential_analysis']['potential_consensus']
            potential_consensus_counts[potential_consensus] = potential_consensus_counts.get(potential_consensus, 0) + 1
        
        return {
            'total_comparisons': total_comparisons,
            'agreement_rate': avg_agreement,
            'simple_detections': simple_detections,
            'llm_detections': llm_detections,
            'consensus_breakdown': consensus_counts,
            'detection_ratio': llm_detections / simple_detections if simple_detections > 0 else float('inf'),
            'potential_analysis': {
                'potential_agreement_rate': avg_potential_agreement,
                'simple_potential_detections': simple_potential_detections,
                'llm_potential_detections': llm_potential_detections,
                'potential_consensus_breakdown': potential_consensus_counts,
                'potential_detection_ratio': llm_potential_detections / simple_potential_detections if simple_potential_detections > 0 else float('inf')
            }
        }
    
    def save_comparison_results_to_csv(self, filepath: str):
        """Save comparison results to CSV file"""
        if not self.comparison_results:
            return
        
        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                'timestamp', 'node_name', 'response_status',
                'simple_count', 'llm_count', 'agreement_score', 'consensus',
                'common_categories', 'simple_unique', 'llm_unique',
                'simple_vulnerable_count', 'simple_potential_count', 'simple_safe_count',
                'llm_vulnerable_count', 'llm_potential_count', 'llm_safe_count',
                'potential_agreement_score', 'potential_consensus',
                'common_potential_categories', 'simple_unique_potential', 'llm_unique_potential',
                'simple_results', 'llm_results'
            ]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for result in self.comparison_results:
                writer.writerow({
                    'timestamp': result['timestamp'],
                    'node_name': result['node_name'],
                    'response_status': result['response_status'],
                    'simple_count': result['simple_detector']['count'],
                    'llm_count': result['llm_detector']['count'],
                    'agreement_score': result['comparison']['agreement_score'],
                    'consensus': result['comparison']['consensus'],
                    'common_categories': ', '.join(result['comparison']['common_categories']),
                    'simple_unique': ', '.join(result['comparison']['simple_unique_categories']),
                    'llm_unique': ', '.join(result['comparison']['llm_unique_categories']),
                    'simple_vulnerable_count': result['simple_detector']['vulnerable_count'],
                    'simple_potential_count': result['simple_detector']['potential_count'],
                    'simple_safe_count': result['simple_detector']['safe_count'],
                    'llm_vulnerable_count': result['llm_detector']['vulnerable_count'],
                    'llm_potential_count': result['llm_detector']['potential_count'],
                    'llm_safe_count': result['llm_detector']['safe_count'],
                    'potential_agreement_score': result['comparison']['potential_analysis']['potential_agreement_score'],
                    'potential_consensus': result['comparison']['potential_analysis']['potential_consensus'],
                    'common_potential_categories': ', '.join(result['comparison']['potential_analysis']['common_potential_categories']),
                    'simple_unique_potential': ', '.join(result['comparison']['potential_analysis']['simple_unique_potential_categories']),
                    'llm_unique_potential': ', '.join(result['comparison']['potential_analysis']['llm_unique_potential_categories']),
                    'simple_results': json.dumps(result['simple_detector']['results']),
                    'llm_results': json.dumps(result['llm_detector']['results'])
                })
    
    def generate_comparison_report(self, filepath: str):
        """Generate a detailed comparison report"""
        summary = self.get_summary_stats()
        
        report = {
            'report_timestamp': datetime.now().isoformat(),
            'api_url': self.api_url,
            'summary': summary,
            'detailed_comparisons': self.comparison_results,
            'detector_analysis': {
                'simple_detector': {
                    'description': 'Rule-based detector using predefined patterns',
                    'strengths': ['Fast execution', 'Consistent results', 'Low resource usage'],
                    'weaknesses': ['Limited to known patterns', 'May miss novel attacks', 'False negatives possible']
                },
                'llm_detector': {
                    'description': 'AI-powered detector using language model analysis',
                    'strengths': ['Contextual understanding', 'Novel attack detection', 'Detailed analysis'],
                    'weaknesses': ['Slower execution', 'Resource intensive', 'Potential false positives']
                }
            }
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Dual detector comparison report saved to {filepath}")
        return filepath
