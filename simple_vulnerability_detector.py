"""
Simplified vulnerability detector that uses existing detector patterns
from the detectors folder instead of writing new detection logic.
"""

import json
import csv
import os
from typing import Dict, List, Any, Tuple
from datetime import datetime

class SimpleVulnerabilityDetector:
    """Simplified vulnerability detector that uses existing detector patterns"""
    
    def __init__(self):
        self.detection_results = []
        
    def detect_vulnerabilities(self, response_data: Dict[str, Any], node_name: str) -> List[Dict[str, Any]]:
        """
        Detect vulnerabilities using existing detector patterns based on query vulnerability type
        
        Args:
            response_data: The GraphQL response data
            node_name: Name of the node being tested
            
        Returns:
            List of vulnerability detection results
        """
        vulnerabilities = []
        
        # Extract response data for detector analysis
        response_status = response_data.get('response_status', 'unknown')
        response_body = response_data.get('response_body', {})
        vulnerability_type = response_data.get('vulnerability_type', 'unknown')
        
        # Create a mock response object for detectors
        class MockResponse:
            def __init__(self, status_code, text):
                self.status_code = status_code
                self.text = text
        
        mock_response = MockResponse(response_status, json.dumps(response_body) if isinstance(response_body, dict) else str(response_body))
        
        # Map vulnerability types to detection methods
        vulnerability_mapping = {
            'sql_injection': self._check_sql_injection,
            'xss_injection': self._check_xss_injection,
            'ssrf_injection': self._check_ssrf_injection,
            'path_injection': self._check_path_injection,
            'os_command_injection': self._check_os_command_injection,
            'html_injection': self._check_html_injection,
            'introspection': self._check_introspection,
            'field_suggestions': self._check_field_suggestion,
            'query_deny_bypass': self._check_query_deny_bypass,
            'basic_call': self._check_basic_call
        }
        
        # Special handling for query deny bypass with two queries
        if vulnerability_type == 'query_deny_bypass' and 'query_deny_bypass_responses' in response_data:
            try:
                result = self._check_query_deny_bypass_two_queries(response_data)
                if result:
                    vulnerabilities.append(result)
            except Exception as e:
                print(f"⚠️ Error in query deny bypass two-query detection: {e}")
            return vulnerabilities
        
        # Run only the appropriate detection method based on vulnerability type
        if vulnerability_type in vulnerability_mapping:
            try:
                result = vulnerability_mapping[vulnerability_type](response_body, mock_response)
                if result:
                    vulnerabilities.append(result)
            except Exception as e:
                print(f"⚠️ Error in {vulnerability_mapping[vulnerability_type].__name__}: {e}")
        else:
            # If vulnerability type is unknown, run all checks
            print(f"⚠️ Unknown vulnerability type '{vulnerability_type}', running all checks")
            detection_checks = [
                self._check_sql_injection,
                self._check_xss_injection,
                self._check_ssrf_injection,
                self._check_path_injection,
                self._check_os_command_injection,
                self._check_html_injection,
                self._check_introspection,
                self._check_field_suggestion,
                self._check_query_deny_bypass
            ]
            
            for check_func in detection_checks:
                try:
                    result = check_func(response_body, mock_response)
                    if result:
                        vulnerabilities.append(result)
                except Exception as e:
                    print(f"⚠️ Error in {check_func.__name__}: {e}")
        
        # Store results
        for vuln in vulnerabilities:
            self.detection_results.append({
                'timestamp': datetime.now().isoformat(),
                'node': node_name,
                'detection_name': vuln['detection_name'],
                'detection': vuln['detection'],
                'category': vuln['category'],
                'description': vuln['description'],
                'evidence': vuln['evidence']
            })
        
        return vulnerabilities
    
    def _check_sql_injection(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for SQL injection based on actual detector logic"""
        # Based on SQLInjectionDetector._is_potentially_vulnerable
        if graphql_response is None or 'data' not in graphql_response or graphql_response['data'] is None:
            return None
        
        # Check if response is successful and contains SQL injection patterns
        sql_patterns = ['"aaa \' OR 1=1--"', 'OR 1=1', 'UNION SELECT', 'DROP TABLE', '--', ';']
        response_text = str(graphql_response['data']) + ' ' + str(request_response.text)
        
        if (request_response.status_code == 200 and 
            graphql_response['data'] and 
            any(pattern in response_text for pattern in sql_patterns)):
            return {
                'detection_name': 'SQL Injection (SQLi) Injection',
                'detection': 'potential',
                'category': 'Injection Attacks',
                'description': 'SQL injection vulnerability detected - malicious SQL patterns found in response',
                'evidence': f'Response status: {request_response.status_code}, SQL patterns detected in response'
            }
        return None
    
    def _check_xss_injection(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for XSS injection based on actual detector logic"""
        # Based on XSSInjectionDetector._is_potentially_vulnerable
        if graphql_response is None or 'data' not in graphql_response or graphql_response['data'] is None:
            return None
        
        # Check for XSS patterns in response data
        xss_patterns = ['<script>alert(1)</script>', '<script>', 'javascript:', 'onerror=', 'onload=']
        response_text = str(graphql_response['data'])
        
        if (request_response.status_code == 200 and 
            any(pattern in response_text for pattern in xss_patterns)):
            return {
                'detection_name': 'Cross-Site Scripting (XSS) Injection',
                'detection': 'potential',
                'category': 'Injection Attacks',
                'description': 'XSS injection vulnerability detected - malicious script patterns found in response',
                'evidence': f'Response status: {request_response.status_code}, XSS patterns detected in response data'
            }
        return None
    
    def _check_ssrf_injection(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for SSRF injection based on actual detector logic"""
        # Based on SSRFInjectionDetector._is_potentially_vulnerable
        if graphql_response is None or 'data' not in graphql_response or graphql_response['data'] is None:
            return None
        
        # Check for SSRF patterns in response
        ssrf_keywords = ["http", "localhost", "3000", "127.0.0.1", "internal", "metadata"]
        response_text = str(graphql_response['data']) + ' ' + str(request_response.text)
        
        if (request_response.status_code == 200 and 
            any(keyword in response_text for keyword in ssrf_keywords)):
            return {
                'detection_name': 'Server-Side Request Forgery (SSRF) Injection',
                'detection': 'potential',
                'category': 'Injection Attacks',
                'description': 'SSRF injection vulnerability detected - internal network access patterns found',
                'evidence': f'Response status: {request_response.status_code}, SSRF keywords detected in response'
            }
        return None
    
    def _check_path_injection(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for path injection based on actual detector logic"""
        # Based on PathInjectionDetector._is_vulnerable and _is_potentially_vulnerable
        if graphql_response is None or 'data' not in graphql_response or graphql_response['data'] is None:
            return None
        
        response_text = str(graphql_response['data']) + ' ' + str(request_response.text)
        
        # Check for path injection patterns
        path_patterns = [
            "root:x:0:0:root:",  # /etc/passwd content
            "Permission denied",
            "../../../../etc/passwd",
            "/etc/passwd",
            "C:\\windows\\system32"
        ]
        
        if any(pattern in response_text for pattern in path_patterns):
            detection = 'vulnerable' if "root:x:0:0:root:" in response_text else 'potential'
            return {
                'detection_name': 'Path Injection',
                'detection': detection,
                'category': 'Injection Attacks',
                'description': 'Path injection vulnerability detected - file system access patterns found',
                'evidence': f'Response status: {request_response.status_code}, Path injection patterns detected in response'
            }
        return None
    
    def _check_os_command_injection(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for OS command injection based on actual detector logic"""
        # Based on OSCommandInjectionDetector._is_vulnerable
        if graphql_response is None or 'data' not in graphql_response or graphql_response['data'] is None:
            return None
        
        response_text = str(graphql_response['data']) + ' ' + str(request_response.text)
        
        # Check for OS command injection patterns
        os_patterns = [
            "root:x:0:0:root:",  # /etc/passwd content
            "uid=", "gid=",  # id command output
            "total ",  # ls command output
            "Permission denied",
            "command not found",
            "sh: ", "bash: "  # Shell error messages
        ]
        
        if any(pattern in response_text for pattern in os_patterns):
            return {
                'detection_name': 'OS Command Injection',
                'detection': 'vulnerable',
                'category': 'Injection Attacks',
                'description': 'OS command injection vulnerability detected - system command output found in response',
                'evidence': f'Response status: {request_response.status_code}, OS command patterns detected in response'
            }
        return None
    
    def _check_html_injection(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for HTML injection based on actual detector logic"""
        # Based on HTMLInjectionDetector._is_potentially_vulnerable
        if graphql_response is None or 'data' not in graphql_response or graphql_response['data'] is None:
            return None
        
        response_text = str(graphql_response['data'])
        
        # Check for HTML injection patterns
        html_patterns = [
            '"<h1>Hello world!</h1>"',  # Specific pattern from detector
            '<h1>', '<h2>', '<h3>',  # HTML headers
            '<div>', '<span>', '<p>',  # HTML elements
            '<script>', '<style>',  # Script/style tags
            'onclick=', 'onload=', 'onerror='  # Event handlers
        ]
        
        if (request_response.status_code == 200 and 
            any(pattern in response_text for pattern in html_patterns)):
            return {
                'detection_name': 'HTML Injection',
                'detection': 'potential',
                'category': 'Injection Attacks',
                'description': 'HTML injection vulnerability detected - HTML markup found in response',
                'evidence': f'Response status: {request_response.status_code}, HTML patterns detected in response data'
            }
        return None
    
    def _check_introspection(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for introspection based on actual detector logic"""
        # Based on IntrospectionDetector._is_vulnerable
        if graphql_response is None or 'errors' in graphql_response:
            return None
        
        if ("__schema" in graphql_response.get('data', {}) and 
            request_response.status_code == 200):
            return {
                'detection_name': 'Introspection Enabled',
                'detection': 'vulnerable',
                'category': 'Information Disclosure',
                'description': 'GraphQL introspection enabled - potential information disclosure',
                'evidence': 'Found __schema in response data - introspection queries are allowed'
            }
        return None
    
    def _check_field_suggestion(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for field suggestions based on actual detector logic"""
        # Based on FieldSuggestionsDetector._is_vulnerable
        if graphql_response is None or 'errors' not in graphql_response:
            return None
        
        error_message = str(graphql_response['errors'][0]['message']).lower()
        response_text = request_response.text.lower()
        
        if ("did you mean" in error_message or 
            "did you mean" in response_text):
            return {
                'detection_name': 'Field Suggestions Enabled',
                'detection': 'vulnerable',
                'category': 'Information Disclosure',
                'description': 'Field suggestions enabled - potential information disclosure',
                'evidence': 'Found "did you mean" in error message - field suggestions are enabled'
            }
        return None
    
    def _check_query_deny_bypass(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for query deny bypass based on actual detector logic"""
        # This function now expects response_data with query_deny_bypass_responses
        # The actual logic is handled in detect_vulnerabilities method
        return None
    
    def _check_query_deny_bypass_two_queries(self, response_data: Dict[str, Any]) -> Dict[str, Any]:
        """Check for query deny bypass using two queries (non-aliased and aliased)"""
        # Check if we have the special query deny bypass responses
        if 'query_deny_bypass_responses' not in response_data:
            return None
            
        responses = response_data['query_deny_bypass_responses']
        non_aliased = responses.get('non_aliased', {})
        aliased = responses.get('aliased', {})
        
        if not non_aliased or not aliased:
            return None
        
        # Extract response data
        non_aliased_status = non_aliased.get('response_status', 0)
        non_aliased_body = non_aliased.get('response_body', {})
        aliased_status = aliased.get('response_status', 0)
        aliased_body = aliased.get('response_body', {})
        
        # Create mock response objects for compatibility
        class MockResponse:
            def __init__(self, status_code, text):
                self.status_code = status_code
                self.text = text
        
        non_aliased_response = MockResponse(non_aliased_status, str(non_aliased_body))
        aliased_response = MockResponse(aliased_status, str(aliased_body))
        
        # Apply the detection logic from the sample code
        if (("400" in str(non_aliased_body) and 'errors' in non_aliased_body)
                or non_aliased_status == 400):
            if (aliased_status == 200 and 'data' in aliased_body and aliased_body['data']):
                if 'errors' in aliased_body and aliased_body['errors'] and len(aliased_body) != 0:
                    return {
                        'detection_name': 'Query Deny Bypass',
                        'detection': 'potential',
                        'category': 'Access Control',
                        'description': 'Query deny bypass vulnerability detected - non-aliased query blocked but aliased query succeeded with errors',
                        'evidence': f'Non-aliased: {non_aliased_status}, Aliased: {aliased_status}, Aliased has errors: {bool(aliased_body.get("errors"))}'
                    }
                else:
                    return {
                        'detection_name': 'Query Deny Bypass',
                        'detection': 'vulnerable',
                        'category': 'Access Control',
                        'description': 'Query deny bypass vulnerability confirmed - non-aliased query blocked but aliased query succeeded without errors',
                        'evidence': f'Non-aliased: {non_aliased_status}, Aliased: {aliased_status}, Aliased clean success: {not bool(aliased_body.get("errors"))}'
                    }
        
        return None
    
    def _check_basic_call(self, graphql_response: dict, request_response) -> Dict[str, Any]:
        """Check for basic call success - no vulnerabilities expected"""
        if graphql_response is None or 'data' not in graphql_response or graphql_response['data'] is None:
            return None
        if request_response.status_code == 200 and graphql_response['data']:
            return {
                'detection_name': 'Basic Call Success',
                'detection': 'safe',
                'category': 'Normal Operation',
                'description': 'Basic GraphQL query executed successfully',
                'evidence': f'Response status: {request_response.status_code}, Data present: {bool(graphql_response["data"])}'
            }
        return None
    
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """Get summary statistics of detected vulnerabilities"""
        if not self.detection_results:
            return {
                'total_detections': 0,
                'confirmed_vulnerabilities': 0,
                'potential_vulnerabilities': 0,
                'category_breakdown': {},
                'response_breakdown': {}
            }
        
        total_detections = len(self.detection_results)
        confirmed_vulnerabilities = len([r for r in self.detection_results if r['detection'] == 'vulnerable'])
        potential_vulnerabilities = len([r for r in self.detection_results if r['detection'] == 'potential'])
        
        category_breakdown = {}
        response_breakdown = {}
        
        for result in self.detection_results:
            category = result['category']
            node = result['node']
            
            # Category breakdown
            category_breakdown[category] = category_breakdown.get(category, 0) + 1
            
            # Response breakdown
            if node not in response_breakdown:
                response_breakdown[node] = 0
            response_breakdown[node] += 1
        
        return {
            'total_detections': total_detections,
            'confirmed_vulnerabilities': confirmed_vulnerabilities,
            'potential_vulnerabilities': potential_vulnerabilities,
            'category_breakdown': category_breakdown,
            'response_breakdown': response_breakdown
        }
    
    def save_results_to_csv(self, filepath: str):
        """Save detection results to CSV file"""
        if not self.detection_results:
            return
        
        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['timestamp', 'node', 'detection_name', 'detection', 'category', 'description', 'evidence']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.detection_results)
    
    def generate_classification_report(self, filepath: str):
        """Generate a classification report"""
        summary = self.get_summary_stats()
        
        report = {
            'report_timestamp': datetime.now().isoformat(),
            'summary': summary,
            'detailed_results': self.detection_results
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
